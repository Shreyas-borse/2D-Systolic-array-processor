{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d314707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "VGG_quant(\n",
      "  (features): Sequential(\n",
      "    (0): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): QuantConv2d(\n",
      "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): QuantConv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): QuantConv2d(\n",
      "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): QuantConv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): QuantConv2d(\n",
      "      256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (25): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): QuantConv2d(\n",
      "      8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (28): ReLU(inplace=True)\n",
      "    (29): QuantConv2d(\n",
      "      8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (33): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (41): ReLU(inplace=True)\n",
      "    (42): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (43): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "     \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "device = torch.device(\"cuda\")   \n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"VGG16_quant_project\"\n",
    "model = VGG16_quant_project()\n",
    "\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0b32171",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_freq = 100\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch,adjust_list):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    \n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e94f8c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 0.412 (0.412)\tData 0.251 (0.251)\tLoss 2.4524 (2.4524)\tPrec 10.938% (10.938%)\n",
      "Epoch: [0][100/391]\tTime 0.054 (0.058)\tData 0.002 (0.004)\tLoss 2.2622 (3.4320)\tPrec 8.594% (10.582%)\n",
      "Epoch: [0][200/391]\tTime 0.055 (0.057)\tData 0.002 (0.003)\tLoss 2.0569 (2.8186)\tPrec 17.188% (13.254%)\n",
      "Epoch: [0][300/391]\tTime 0.060 (0.056)\tData 0.002 (0.003)\tLoss 2.0206 (2.5567)\tPrec 21.875% (15.695%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.205 (0.205)\tLoss 1.9066 (1.9066)\tPrec 29.688% (29.688%)\n",
      " * Prec 24.470% \n",
      "best acc: 24.470000\n",
      "Epoch: [1][0/391]\tTime 0.308 (0.308)\tData 0.257 (0.257)\tLoss 1.9837 (1.9837)\tPrec 21.094% (21.094%)\n",
      "Epoch: [1][100/391]\tTime 0.058 (0.057)\tData 0.002 (0.004)\tLoss 1.9341 (1.9230)\tPrec 18.750% (22.741%)\n",
      "Epoch: [1][200/391]\tTime 0.054 (0.056)\tData 0.003 (0.003)\tLoss 1.8041 (1.9032)\tPrec 31.250% (23.865%)\n",
      "Epoch: [1][300/391]\tTime 0.053 (0.056)\tData 0.001 (0.002)\tLoss 1.9593 (1.8844)\tPrec 17.969% (24.886%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.235 (0.235)\tLoss 1.9639 (1.9639)\tPrec 25.781% (25.781%)\n",
      " * Prec 29.070% \n",
      "best acc: 29.070000\n",
      "Epoch: [2][0/391]\tTime 0.297 (0.297)\tData 0.255 (0.255)\tLoss 1.8296 (1.8296)\tPrec 32.812% (32.812%)\n",
      "Epoch: [2][100/391]\tTime 0.049 (0.057)\tData 0.001 (0.004)\tLoss 1.7276 (1.8146)\tPrec 34.375% (29.061%)\n",
      "Epoch: [2][200/391]\tTime 0.056 (0.056)\tData 0.001 (0.003)\tLoss 1.7497 (1.7968)\tPrec 32.812% (30.092%)\n",
      "Epoch: [2][300/391]\tTime 0.058 (0.056)\tData 0.002 (0.002)\tLoss 1.8450 (1.7774)\tPrec 32.031% (31.157%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.234 (0.234)\tLoss 1.6269 (1.6269)\tPrec 40.625% (40.625%)\n",
      " * Prec 35.490% \n",
      "best acc: 35.490000\n",
      "Epoch: [3][0/391]\tTime 0.319 (0.319)\tData 0.264 (0.264)\tLoss 1.6004 (1.6004)\tPrec 35.938% (35.938%)\n",
      "Epoch: [3][100/391]\tTime 0.056 (0.057)\tData 0.001 (0.004)\tLoss 1.6629 (1.6449)\tPrec 39.062% (36.781%)\n",
      "Epoch: [3][200/391]\tTime 0.052 (0.056)\tData 0.002 (0.003)\tLoss 1.4720 (1.6014)\tPrec 49.219% (38.930%)\n",
      "Epoch: [3][300/391]\tTime 0.061 (0.056)\tData 0.001 (0.002)\tLoss 1.4026 (1.5702)\tPrec 50.000% (40.503%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.243 (0.243)\tLoss 1.4099 (1.4099)\tPrec 46.094% (46.094%)\n",
      " * Prec 46.430% \n",
      "best acc: 46.430000\n",
      "Epoch: [4][0/391]\tTime 0.303 (0.303)\tData 0.258 (0.258)\tLoss 1.4986 (1.4986)\tPrec 45.312% (45.312%)\n",
      "Epoch: [4][100/391]\tTime 0.053 (0.057)\tData 0.001 (0.004)\tLoss 1.3995 (1.4259)\tPrec 50.000% (46.782%)\n",
      "Epoch: [4][200/391]\tTime 0.056 (0.056)\tData 0.002 (0.003)\tLoss 1.3926 (1.3982)\tPrec 50.000% (47.936%)\n",
      "Epoch: [4][300/391]\tTime 0.060 (0.056)\tData 0.001 (0.002)\tLoss 1.3221 (1.3802)\tPrec 48.438% (48.816%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.243 (0.243)\tLoss 1.3974 (1.3974)\tPrec 45.312% (45.312%)\n",
      " * Prec 48.850% \n",
      "best acc: 48.850000\n",
      "Epoch: [5][0/391]\tTime 0.328 (0.328)\tData 0.282 (0.282)\tLoss 1.3581 (1.3581)\tPrec 52.344% (52.344%)\n",
      "Epoch: [5][100/391]\tTime 0.054 (0.058)\tData 0.001 (0.004)\tLoss 1.0712 (1.2298)\tPrec 65.625% (54.680%)\n",
      "Epoch: [5][200/391]\tTime 0.058 (0.056)\tData 0.001 (0.003)\tLoss 1.1835 (1.2244)\tPrec 55.469% (54.936%)\n",
      "Epoch: [5][300/391]\tTime 0.053 (0.056)\tData 0.001 (0.002)\tLoss 1.1784 (1.2124)\tPrec 55.469% (55.383%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.205 (0.205)\tLoss 1.3428 (1.3428)\tPrec 57.031% (57.031%)\n",
      " * Prec 51.820% \n",
      "best acc: 51.820000\n",
      "Epoch: [6][0/391]\tTime 0.290 (0.290)\tData 0.242 (0.242)\tLoss 1.2816 (1.2816)\tPrec 60.938% (60.938%)\n",
      "Epoch: [6][100/391]\tTime 0.054 (0.057)\tData 0.001 (0.004)\tLoss 1.1514 (1.1086)\tPrec 57.031% (59.723%)\n",
      "Epoch: [6][200/391]\tTime 0.050 (0.056)\tData 0.002 (0.003)\tLoss 1.0208 (1.0889)\tPrec 64.844% (60.421%)\n",
      "Epoch: [6][300/391]\tTime 0.054 (0.056)\tData 0.001 (0.002)\tLoss 1.1456 (1.0790)\tPrec 57.812% (60.800%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.231 (0.231)\tLoss 0.9607 (0.9607)\tPrec 64.062% (64.062%)\n",
      " * Prec 62.770% \n",
      "best acc: 62.770000\n",
      "Epoch: [7][0/391]\tTime 0.307 (0.307)\tData 0.255 (0.255)\tLoss 1.0684 (1.0684)\tPrec 62.500% (62.500%)\n",
      "Epoch: [7][100/391]\tTime 0.050 (0.058)\tData 0.001 (0.004)\tLoss 0.9600 (0.9873)\tPrec 71.875% (64.140%)\n",
      "Epoch: [7][200/391]\tTime 0.051 (0.057)\tData 0.002 (0.003)\tLoss 1.1038 (0.9836)\tPrec 59.375% (64.307%)\n",
      "Epoch: [7][300/391]\tTime 0.050 (0.057)\tData 0.001 (0.002)\tLoss 0.7966 (0.9731)\tPrec 69.531% (64.685%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.236 (0.236)\tLoss 0.9273 (0.9273)\tPrec 64.062% (64.062%)\n",
      " * Prec 64.210% \n",
      "best acc: 64.210000\n",
      "Epoch: [8][0/391]\tTime 0.278 (0.278)\tData 0.236 (0.236)\tLoss 1.2173 (1.2173)\tPrec 62.500% (62.500%)\n",
      "Epoch: [8][100/391]\tTime 0.055 (0.060)\tData 0.001 (0.004)\tLoss 1.1647 (0.9021)\tPrec 56.250% (67.567%)\n",
      "Epoch: [8][200/391]\tTime 0.054 (0.057)\tData 0.001 (0.003)\tLoss 0.8566 (0.9000)\tPrec 71.875% (67.716%)\n",
      "Epoch: [8][300/391]\tTime 0.050 (0.057)\tData 0.002 (0.002)\tLoss 0.8749 (0.8899)\tPrec 70.312% (68.236%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.257 (0.257)\tLoss 0.7249 (0.7249)\tPrec 75.781% (75.781%)\n",
      " * Prec 67.000% \n",
      "best acc: 67.000000\n",
      "Epoch: [9][0/391]\tTime 0.313 (0.313)\tData 0.266 (0.266)\tLoss 0.8011 (0.8011)\tPrec 71.875% (71.875%)\n",
      "Epoch: [9][100/391]\tTime 0.055 (0.058)\tData 0.001 (0.004)\tLoss 0.9520 (0.8259)\tPrec 63.281% (70.568%)\n",
      "Epoch: [9][200/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.8286 (0.8244)\tPrec 71.094% (70.721%)\n",
      "Epoch: [9][300/391]\tTime 0.054 (0.056)\tData 0.001 (0.002)\tLoss 0.8589 (0.8209)\tPrec 67.969% (70.878%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.221 (0.221)\tLoss 1.0047 (1.0047)\tPrec 64.844% (64.844%)\n",
      " * Prec 61.930% \n",
      "best acc: 67.000000\n",
      "Epoch: [10][0/391]\tTime 0.275 (0.275)\tData 0.235 (0.235)\tLoss 0.7420 (0.7420)\tPrec 74.219% (74.219%)\n",
      "Epoch: [10][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.004)\tLoss 0.7695 (0.7629)\tPrec 69.531% (73.329%)\n",
      "Epoch: [10][200/391]\tTime 0.059 (0.057)\tData 0.002 (0.003)\tLoss 0.8913 (0.7705)\tPrec 66.406% (73.002%)\n",
      "Epoch: [10][300/391]\tTime 0.058 (0.056)\tData 0.001 (0.002)\tLoss 0.7936 (0.7678)\tPrec 71.094% (73.144%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.243 (0.243)\tLoss 0.7571 (0.7571)\tPrec 77.344% (77.344%)\n",
      " * Prec 71.550% \n",
      "best acc: 71.550000\n",
      "Epoch: [11][0/391]\tTime 0.276 (0.276)\tData 0.230 (0.230)\tLoss 0.6766 (0.6766)\tPrec 76.562% (76.562%)\n",
      "Epoch: [11][100/391]\tTime 0.051 (0.058)\tData 0.001 (0.004)\tLoss 0.7478 (0.7299)\tPrec 72.656% (74.776%)\n",
      "Epoch: [11][200/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.6359 (0.7215)\tPrec 77.344% (75.051%)\n",
      "Epoch: [11][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.002)\tLoss 0.5976 (0.7135)\tPrec 78.125% (75.392%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.7488 (0.7488)\tPrec 71.094% (71.094%)\n",
      " * Prec 74.360% \n",
      "best acc: 74.360000\n",
      "Epoch: [12][0/391]\tTime 0.289 (0.289)\tData 0.242 (0.242)\tLoss 0.6230 (0.6230)\tPrec 78.125% (78.125%)\n",
      "Epoch: [12][100/391]\tTime 0.052 (0.058)\tData 0.001 (0.004)\tLoss 0.5143 (0.6707)\tPrec 84.375% (77.073%)\n",
      "Epoch: [12][200/391]\tTime 0.059 (0.057)\tData 0.001 (0.003)\tLoss 0.7863 (0.6661)\tPrec 73.438% (76.998%)\n",
      "Epoch: [12][300/391]\tTime 0.056 (0.056)\tData 0.001 (0.003)\tLoss 0.7007 (0.6657)\tPrec 76.562% (77.100%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.222 (0.222)\tLoss 0.7022 (0.7022)\tPrec 75.781% (75.781%)\n",
      " * Prec 74.370% \n",
      "best acc: 74.370000\n",
      "Epoch: [13][0/391]\tTime 0.313 (0.313)\tData 0.266 (0.266)\tLoss 0.5199 (0.5199)\tPrec 82.031% (82.031%)\n",
      "Epoch: [13][100/391]\tTime 0.052 (0.058)\tData 0.003 (0.004)\tLoss 0.7801 (0.6298)\tPrec 77.344% (78.434%)\n",
      "Epoch: [13][200/391]\tTime 0.068 (0.057)\tData 0.002 (0.003)\tLoss 0.6878 (0.6310)\tPrec 74.219% (78.172%)\n",
      "Epoch: [13][300/391]\tTime 0.056 (0.056)\tData 0.001 (0.003)\tLoss 0.6724 (0.6257)\tPrec 76.562% (78.307%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.236 (0.236)\tLoss 0.7516 (0.7516)\tPrec 71.875% (71.875%)\n",
      " * Prec 75.800% \n",
      "best acc: 75.800000\n",
      "Epoch: [14][0/391]\tTime 0.262 (0.262)\tData 0.220 (0.220)\tLoss 0.6366 (0.6366)\tPrec 78.906% (78.906%)\n",
      "Epoch: [14][100/391]\tTime 0.048 (0.057)\tData 0.002 (0.004)\tLoss 0.5546 (0.5854)\tPrec 82.031% (79.827%)\n",
      "Epoch: [14][200/391]\tTime 0.051 (0.056)\tData 0.001 (0.003)\tLoss 0.5106 (0.5856)\tPrec 84.375% (80.061%)\n",
      "Epoch: [14][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.5514 (0.5886)\tPrec 79.688% (79.880%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.233 (0.233)\tLoss 0.6609 (0.6609)\tPrec 80.469% (80.469%)\n",
      " * Prec 76.290% \n",
      "best acc: 76.290000\n",
      "Epoch: [15][0/391]\tTime 0.258 (0.258)\tData 0.211 (0.211)\tLoss 0.4898 (0.4898)\tPrec 88.281% (88.281%)\n",
      "Epoch: [15][100/391]\tTime 0.059 (0.057)\tData 0.002 (0.004)\tLoss 0.4130 (0.5532)\tPrec 82.031% (81.343%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][200/391]\tTime 0.053 (0.057)\tData 0.002 (0.003)\tLoss 0.6900 (0.5536)\tPrec 76.562% (81.207%)\n",
      "Epoch: [15][300/391]\tTime 0.054 (0.057)\tData 0.001 (0.002)\tLoss 0.5596 (0.5621)\tPrec 78.125% (80.915%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.229 (0.229)\tLoss 0.5778 (0.5778)\tPrec 80.469% (80.469%)\n",
      " * Prec 78.930% \n",
      "best acc: 78.930000\n",
      "Epoch: [16][0/391]\tTime 0.308 (0.308)\tData 0.260 (0.260)\tLoss 0.6491 (0.6491)\tPrec 78.125% (78.125%)\n",
      "Epoch: [16][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.004)\tLoss 0.4911 (0.5290)\tPrec 81.250% (81.915%)\n",
      "Epoch: [16][200/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 0.5030 (0.5356)\tPrec 82.812% (81.573%)\n",
      "Epoch: [16][300/391]\tTime 0.064 (0.056)\tData 0.002 (0.003)\tLoss 0.5472 (0.5347)\tPrec 80.469% (81.689%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.220 (0.220)\tLoss 0.6140 (0.6140)\tPrec 79.688% (79.688%)\n",
      " * Prec 78.650% \n",
      "best acc: 78.930000\n",
      "Epoch: [17][0/391]\tTime 0.288 (0.288)\tData 0.239 (0.239)\tLoss 0.4693 (0.4693)\tPrec 84.375% (84.375%)\n",
      "Epoch: [17][100/391]\tTime 0.055 (0.058)\tData 0.002 (0.004)\tLoss 0.4789 (0.5159)\tPrec 84.375% (82.387%)\n",
      "Epoch: [17][200/391]\tTime 0.055 (0.057)\tData 0.002 (0.003)\tLoss 0.2796 (0.5146)\tPrec 89.062% (82.280%)\n",
      "Epoch: [17][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.002)\tLoss 0.6301 (0.5128)\tPrec 81.250% (82.460%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.238 (0.238)\tLoss 0.5777 (0.5777)\tPrec 82.812% (82.812%)\n",
      " * Prec 80.090% \n",
      "best acc: 80.090000\n",
      "Epoch: [18][0/391]\tTime 0.278 (0.278)\tData 0.232 (0.232)\tLoss 0.4675 (0.4675)\tPrec 82.812% (82.812%)\n",
      "Epoch: [18][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.4296 (0.4729)\tPrec 82.031% (84.189%)\n",
      "Epoch: [18][200/391]\tTime 0.055 (0.057)\tData 0.002 (0.003)\tLoss 0.4280 (0.4844)\tPrec 88.281% (83.773%)\n",
      "Epoch: [18][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.002)\tLoss 0.6612 (0.4837)\tPrec 75.781% (83.711%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.221 (0.221)\tLoss 0.5731 (0.5731)\tPrec 79.688% (79.688%)\n",
      " * Prec 79.990% \n",
      "best acc: 80.090000\n",
      "Epoch: [19][0/391]\tTime 0.312 (0.312)\tData 0.265 (0.265)\tLoss 0.4987 (0.4987)\tPrec 82.812% (82.812%)\n",
      "Epoch: [19][100/391]\tTime 0.051 (0.058)\tData 0.003 (0.004)\tLoss 0.4900 (0.4619)\tPrec 85.938% (84.112%)\n",
      "Epoch: [19][200/391]\tTime 0.058 (0.056)\tData 0.001 (0.003)\tLoss 0.5233 (0.4733)\tPrec 80.469% (83.788%)\n",
      "Epoch: [19][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.5465 (0.4721)\tPrec 85.938% (84.025%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.8041 (0.8041)\tPrec 72.656% (72.656%)\n",
      " * Prec 77.030% \n",
      "best acc: 80.090000\n",
      "Epoch: [20][0/391]\tTime 0.314 (0.314)\tData 0.274 (0.274)\tLoss 0.4098 (0.4098)\tPrec 86.719% (86.719%)\n",
      "Epoch: [20][100/391]\tTime 0.053 (0.058)\tData 0.001 (0.004)\tLoss 0.6044 (0.4395)\tPrec 80.469% (85.102%)\n",
      "Epoch: [20][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.003)\tLoss 0.3906 (0.4492)\tPrec 85.938% (84.643%)\n",
      "Epoch: [20][300/391]\tTime 0.056 (0.056)\tData 0.001 (0.002)\tLoss 0.5448 (0.4474)\tPrec 80.469% (84.738%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.238 (0.238)\tLoss 0.5606 (0.5606)\tPrec 81.250% (81.250%)\n",
      " * Prec 80.420% \n",
      "best acc: 80.420000\n",
      "Epoch: [21][0/391]\tTime 0.305 (0.305)\tData 0.256 (0.256)\tLoss 0.3029 (0.3029)\tPrec 92.969% (92.969%)\n",
      "Epoch: [21][100/391]\tTime 0.058 (0.059)\tData 0.002 (0.004)\tLoss 0.3994 (0.4313)\tPrec 86.719% (85.574%)\n",
      "Epoch: [21][200/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.4682 (0.4309)\tPrec 83.594% (85.242%)\n",
      "Epoch: [21][300/391]\tTime 0.053 (0.057)\tData 0.001 (0.002)\tLoss 0.5610 (0.4361)\tPrec 82.812% (85.208%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 0.4311 (0.4311)\tPrec 85.938% (85.938%)\n",
      " * Prec 83.150% \n",
      "best acc: 83.150000\n",
      "Epoch: [22][0/391]\tTime 0.315 (0.315)\tData 0.266 (0.266)\tLoss 0.3743 (0.3743)\tPrec 86.719% (86.719%)\n",
      "Epoch: [22][100/391]\tTime 0.054 (0.058)\tData 0.001 (0.004)\tLoss 0.4179 (0.4104)\tPrec 86.719% (85.999%)\n",
      "Epoch: [22][200/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.4948 (0.4137)\tPrec 85.156% (85.926%)\n",
      "Epoch: [22][300/391]\tTime 0.053 (0.056)\tData 0.001 (0.002)\tLoss 0.4352 (0.4143)\tPrec 82.031% (85.909%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.249 (0.249)\tLoss 0.5266 (0.5266)\tPrec 82.812% (82.812%)\n",
      " * Prec 82.170% \n",
      "best acc: 83.150000\n",
      "Epoch: [23][0/391]\tTime 0.303 (0.303)\tData 0.257 (0.257)\tLoss 0.2009 (0.2009)\tPrec 94.531% (94.531%)\n",
      "Epoch: [23][100/391]\tTime 0.056 (0.058)\tData 0.002 (0.004)\tLoss 0.3400 (0.3766)\tPrec 88.281% (87.299%)\n",
      "Epoch: [23][200/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.2960 (0.3815)\tPrec 89.062% (87.034%)\n",
      "Epoch: [23][300/391]\tTime 0.058 (0.056)\tData 0.001 (0.002)\tLoss 0.3805 (0.3883)\tPrec 84.375% (86.911%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.264 (0.264)\tLoss 0.5492 (0.5492)\tPrec 84.375% (84.375%)\n",
      " * Prec 81.850% \n",
      "best acc: 83.150000\n",
      "Epoch: [24][0/391]\tTime 0.287 (0.287)\tData 0.244 (0.244)\tLoss 0.3930 (0.3930)\tPrec 85.938% (85.938%)\n",
      "Epoch: [24][100/391]\tTime 0.060 (0.058)\tData 0.002 (0.004)\tLoss 0.3227 (0.3758)\tPrec 89.844% (87.260%)\n",
      "Epoch: [24][200/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 0.4895 (0.3834)\tPrec 82.812% (86.968%)\n",
      "Epoch: [24][300/391]\tTime 0.059 (0.056)\tData 0.002 (0.002)\tLoss 0.4819 (0.3854)\tPrec 84.375% (86.869%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.227 (0.227)\tLoss 0.4969 (0.4969)\tPrec 84.375% (84.375%)\n",
      " * Prec 84.400% \n",
      "best acc: 84.400000\n",
      "Epoch: [25][0/391]\tTime 0.298 (0.298)\tData 0.254 (0.254)\tLoss 0.3934 (0.3934)\tPrec 87.500% (87.500%)\n",
      "Epoch: [25][100/391]\tTime 0.055 (0.057)\tData 0.001 (0.004)\tLoss 0.5359 (0.3674)\tPrec 80.469% (87.577%)\n",
      "Epoch: [25][200/391]\tTime 0.053 (0.056)\tData 0.001 (0.003)\tLoss 0.3100 (0.3659)\tPrec 89.844% (87.488%)\n",
      "Epoch: [25][300/391]\tTime 0.051 (0.056)\tData 0.002 (0.002)\tLoss 0.4745 (0.3724)\tPrec 82.812% (87.370%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.241 (0.241)\tLoss 0.4263 (0.4263)\tPrec 85.156% (85.156%)\n",
      " * Prec 82.950% \n",
      "best acc: 84.400000\n",
      "Epoch: [26][0/391]\tTime 0.294 (0.294)\tData 0.249 (0.249)\tLoss 0.2791 (0.2791)\tPrec 88.281% (88.281%)\n",
      "Epoch: [26][100/391]\tTime 0.056 (0.058)\tData 0.002 (0.004)\tLoss 0.3177 (0.3473)\tPrec 89.062% (87.964%)\n",
      "Epoch: [26][200/391]\tTime 0.055 (0.057)\tData 0.002 (0.003)\tLoss 0.4085 (0.3525)\tPrec 85.938% (88.064%)\n",
      "Epoch: [26][300/391]\tTime 0.062 (0.056)\tData 0.001 (0.003)\tLoss 0.2845 (0.3566)\tPrec 91.406% (87.920%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.251 (0.251)\tLoss 0.4616 (0.4616)\tPrec 82.031% (82.031%)\n",
      " * Prec 83.830% \n",
      "best acc: 84.400000\n",
      "Epoch: [27][0/391]\tTime 0.271 (0.271)\tData 0.230 (0.230)\tLoss 0.2215 (0.2215)\tPrec 91.406% (91.406%)\n",
      "Epoch: [27][100/391]\tTime 0.056 (0.058)\tData 0.001 (0.004)\tLoss 0.1674 (0.3217)\tPrec 94.531% (89.233%)\n",
      "Epoch: [27][200/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 0.1803 (0.3330)\tPrec 95.312% (88.697%)\n",
      "Epoch: [27][300/391]\tTime 0.058 (0.056)\tData 0.002 (0.002)\tLoss 0.3084 (0.3386)\tPrec 89.062% (88.486%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.238 (0.238)\tLoss 0.4120 (0.4120)\tPrec 87.500% (87.500%)\n",
      " * Prec 84.470% \n",
      "best acc: 84.470000\n",
      "Epoch: [28][0/391]\tTime 0.285 (0.285)\tData 0.240 (0.240)\tLoss 0.2873 (0.2873)\tPrec 92.188% (92.188%)\n",
      "Epoch: [28][100/391]\tTime 0.055 (0.058)\tData 0.001 (0.004)\tLoss 0.3800 (0.3211)\tPrec 86.719% (89.310%)\n",
      "Epoch: [28][200/391]\tTime 0.049 (0.057)\tData 0.002 (0.003)\tLoss 0.2520 (0.3219)\tPrec 90.625% (89.175%)\n",
      "Epoch: [28][300/391]\tTime 0.062 (0.056)\tData 0.001 (0.003)\tLoss 0.4851 (0.3291)\tPrec 82.812% (88.876%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.215 (0.215)\tLoss 0.3923 (0.3923)\tPrec 89.062% (89.062%)\n",
      " * Prec 83.970% \n",
      "best acc: 84.470000\n",
      "Epoch: [29][0/391]\tTime 0.286 (0.286)\tData 0.239 (0.239)\tLoss 0.4689 (0.4689)\tPrec 82.031% (82.031%)\n",
      "Epoch: [29][100/391]\tTime 0.058 (0.058)\tData 0.001 (0.004)\tLoss 0.1427 (0.3062)\tPrec 96.875% (89.643%)\n",
      "Epoch: [29][200/391]\tTime 0.053 (0.057)\tData 0.002 (0.003)\tLoss 0.3308 (0.3154)\tPrec 88.281% (89.300%)\n",
      "Epoch: [29][300/391]\tTime 0.056 (0.056)\tData 0.002 (0.003)\tLoss 0.2776 (0.3204)\tPrec 90.625% (89.104%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.265 (0.265)\tLoss 0.5007 (0.5007)\tPrec 85.156% (85.156%)\n",
      " * Prec 83.520% \n",
      "best acc: 84.470000\n",
      "Epoch: [30][0/391]\tTime 0.272 (0.272)\tData 0.225 (0.225)\tLoss 0.1515 (0.1515)\tPrec 96.094% (96.094%)\n",
      "Epoch: [30][100/391]\tTime 0.059 (0.057)\tData 0.002 (0.004)\tLoss 0.3969 (0.3042)\tPrec 85.156% (89.712%)\n",
      "Epoch: [30][200/391]\tTime 0.058 (0.056)\tData 0.002 (0.003)\tLoss 0.3082 (0.3144)\tPrec 89.844% (89.354%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30][300/391]\tTime 0.058 (0.056)\tData 0.002 (0.002)\tLoss 0.3177 (0.3149)\tPrec 85.938% (89.348%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.194 (0.194)\tLoss 0.3138 (0.3138)\tPrec 89.844% (89.844%)\n",
      " * Prec 84.310% \n",
      "best acc: 84.470000\n",
      "Epoch: [31][0/391]\tTime 0.312 (0.312)\tData 0.263 (0.263)\tLoss 0.1730 (0.1730)\tPrec 93.750% (93.750%)\n",
      "Epoch: [31][100/391]\tTime 0.056 (0.058)\tData 0.001 (0.004)\tLoss 0.2912 (0.2980)\tPrec 90.625% (90.231%)\n",
      "Epoch: [31][200/391]\tTime 0.066 (0.057)\tData 0.002 (0.003)\tLoss 0.3191 (0.3014)\tPrec 91.406% (89.887%)\n",
      "Epoch: [31][300/391]\tTime 0.053 (0.057)\tData 0.002 (0.003)\tLoss 0.4346 (0.3064)\tPrec 86.719% (89.693%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.247 (0.247)\tLoss 0.3946 (0.3946)\tPrec 87.500% (87.500%)\n",
      " * Prec 84.860% \n",
      "best acc: 84.860000\n",
      "Epoch: [32][0/391]\tTime 0.305 (0.305)\tData 0.261 (0.261)\tLoss 0.3022 (0.3022)\tPrec 90.625% (90.625%)\n",
      "Epoch: [32][100/391]\tTime 0.056 (0.058)\tData 0.002 (0.004)\tLoss 0.3824 (0.2789)\tPrec 89.062% (90.416%)\n",
      "Epoch: [32][200/391]\tTime 0.052 (0.057)\tData 0.002 (0.003)\tLoss 0.1973 (0.2926)\tPrec 93.750% (90.108%)\n",
      "Epoch: [32][300/391]\tTime 0.052 (0.056)\tData 0.001 (0.002)\tLoss 0.3149 (0.2921)\tPrec 89.062% (90.090%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.248 (0.248)\tLoss 0.3584 (0.3584)\tPrec 85.156% (85.156%)\n",
      " * Prec 85.450% \n",
      "best acc: 85.450000\n",
      "Epoch: [33][0/391]\tTime 0.291 (0.291)\tData 0.242 (0.242)\tLoss 0.2092 (0.2092)\tPrec 93.750% (93.750%)\n",
      "Epoch: [33][100/391]\tTime 0.054 (0.058)\tData 0.001 (0.004)\tLoss 0.1712 (0.2726)\tPrec 91.406% (90.888%)\n",
      "Epoch: [33][200/391]\tTime 0.052 (0.057)\tData 0.002 (0.003)\tLoss 0.2241 (0.2774)\tPrec 92.188% (90.641%)\n",
      "Epoch: [33][300/391]\tTime 0.049 (0.056)\tData 0.002 (0.002)\tLoss 0.1724 (0.2817)\tPrec 93.750% (90.436%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.3363 (0.3363)\tPrec 92.188% (92.188%)\n",
      " * Prec 85.690% \n",
      "best acc: 85.690000\n",
      "Epoch: [34][0/391]\tTime 0.337 (0.337)\tData 0.295 (0.295)\tLoss 0.2481 (0.2481)\tPrec 92.969% (92.969%)\n",
      "Epoch: [34][100/391]\tTime 0.050 (0.058)\tData 0.001 (0.005)\tLoss 0.1935 (0.2614)\tPrec 93.750% (91.074%)\n",
      "Epoch: [34][200/391]\tTime 0.052 (0.057)\tData 0.001 (0.003)\tLoss 0.3491 (0.2689)\tPrec 86.719% (90.765%)\n",
      "Epoch: [34][300/391]\tTime 0.056 (0.056)\tData 0.002 (0.003)\tLoss 0.3100 (0.2692)\tPrec 90.625% (90.859%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.3819 (0.3819)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.120% \n",
      "best acc: 86.120000\n",
      "Epoch: [35][0/391]\tTime 0.278 (0.278)\tData 0.230 (0.230)\tLoss 0.2992 (0.2992)\tPrec 88.281% (88.281%)\n",
      "Epoch: [35][100/391]\tTime 0.055 (0.058)\tData 0.001 (0.004)\tLoss 0.1528 (0.2572)\tPrec 93.750% (91.166%)\n",
      "Epoch: [35][200/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 0.2080 (0.2714)\tPrec 91.406% (90.769%)\n",
      "Epoch: [35][300/391]\tTime 0.054 (0.056)\tData 0.001 (0.002)\tLoss 0.2866 (0.2746)\tPrec 90.625% (90.690%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.233 (0.233)\tLoss 0.3601 (0.3601)\tPrec 89.062% (89.062%)\n",
      " * Prec 85.940% \n",
      "best acc: 86.120000\n",
      "Epoch: [36][0/391]\tTime 0.290 (0.290)\tData 0.247 (0.247)\tLoss 0.2230 (0.2230)\tPrec 90.625% (90.625%)\n",
      "Epoch: [36][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.004)\tLoss 0.2726 (0.2411)\tPrec 92.969% (91.770%)\n",
      "Epoch: [36][200/391]\tTime 0.056 (0.057)\tData 0.001 (0.003)\tLoss 0.2912 (0.2562)\tPrec 90.625% (91.212%)\n",
      "Epoch: [36][300/391]\tTime 0.059 (0.056)\tData 0.002 (0.002)\tLoss 0.3717 (0.2599)\tPrec 85.938% (91.040%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.2782 (0.2782)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.490% \n",
      "best acc: 86.490000\n",
      "Epoch: [37][0/391]\tTime 0.288 (0.288)\tData 0.237 (0.237)\tLoss 0.2222 (0.2222)\tPrec 92.969% (92.969%)\n",
      "Epoch: [37][100/391]\tTime 0.057 (0.058)\tData 0.004 (0.004)\tLoss 0.2642 (0.2360)\tPrec 90.625% (92.071%)\n",
      "Epoch: [37][200/391]\tTime 0.057 (0.057)\tData 0.001 (0.003)\tLoss 0.2132 (0.2437)\tPrec 91.406% (91.810%)\n",
      "Epoch: [37][300/391]\tTime 0.058 (0.057)\tData 0.001 (0.003)\tLoss 0.1908 (0.2499)\tPrec 90.625% (91.549%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.192 (0.192)\tLoss 0.3635 (0.3635)\tPrec 85.938% (85.938%)\n",
      " * Prec 85.880% \n",
      "best acc: 86.490000\n",
      "Epoch: [38][0/391]\tTime 0.280 (0.280)\tData 0.241 (0.241)\tLoss 0.3278 (0.3278)\tPrec 88.281% (88.281%)\n",
      "Epoch: [38][100/391]\tTime 0.052 (0.058)\tData 0.002 (0.004)\tLoss 0.2117 (0.2395)\tPrec 90.625% (91.491%)\n",
      "Epoch: [38][200/391]\tTime 0.061 (0.057)\tData 0.001 (0.003)\tLoss 0.2350 (0.2413)\tPrec 92.188% (91.531%)\n",
      "Epoch: [38][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.002)\tLoss 0.2857 (0.2474)\tPrec 88.281% (91.409%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.217 (0.217)\tLoss 0.4327 (0.4327)\tPrec 85.938% (85.938%)\n",
      " * Prec 85.200% \n",
      "best acc: 86.490000\n",
      "Epoch: [39][0/391]\tTime 0.272 (0.272)\tData 0.224 (0.224)\tLoss 0.2212 (0.2212)\tPrec 93.750% (93.750%)\n",
      "Epoch: [39][100/391]\tTime 0.055 (0.058)\tData 0.001 (0.004)\tLoss 0.2369 (0.2385)\tPrec 87.500% (91.754%)\n",
      "Epoch: [39][200/391]\tTime 0.053 (0.057)\tData 0.002 (0.003)\tLoss 0.1847 (0.2421)\tPrec 91.406% (91.717%)\n",
      "Epoch: [39][300/391]\tTime 0.060 (0.056)\tData 0.003 (0.002)\tLoss 0.2771 (0.2427)\tPrec 87.500% (91.616%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.267 (0.267)\tLoss 0.3195 (0.3195)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.090% \n",
      "best acc: 87.090000\n",
      "Epoch: [40][0/391]\tTime 0.285 (0.285)\tData 0.236 (0.236)\tLoss 0.2626 (0.2626)\tPrec 91.406% (91.406%)\n",
      "Epoch: [40][100/391]\tTime 0.053 (0.058)\tData 0.001 (0.004)\tLoss 0.1840 (0.2239)\tPrec 92.188% (92.381%)\n",
      "Epoch: [40][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.003)\tLoss 0.2696 (0.2254)\tPrec 89.062% (92.234%)\n",
      "Epoch: [40][300/391]\tTime 0.058 (0.056)\tData 0.001 (0.002)\tLoss 0.1695 (0.2346)\tPrec 94.531% (91.972%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.232 (0.232)\tLoss 0.3097 (0.3097)\tPrec 89.062% (89.062%)\n",
      " * Prec 83.610% \n",
      "best acc: 87.090000\n",
      "Epoch: [41][0/391]\tTime 0.275 (0.275)\tData 0.228 (0.228)\tLoss 0.2205 (0.2205)\tPrec 93.750% (93.750%)\n",
      "Epoch: [41][100/391]\tTime 0.056 (0.058)\tData 0.002 (0.004)\tLoss 0.1915 (0.2193)\tPrec 95.312% (92.327%)\n",
      "Epoch: [41][200/391]\tTime 0.059 (0.057)\tData 0.002 (0.003)\tLoss 0.2071 (0.2240)\tPrec 92.188% (92.339%)\n",
      "Epoch: [41][300/391]\tTime 0.056 (0.056)\tData 0.003 (0.002)\tLoss 0.3847 (0.2297)\tPrec 88.281% (92.190%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.231 (0.231)\tLoss 0.3599 (0.3599)\tPrec 88.281% (88.281%)\n",
      " * Prec 85.990% \n",
      "best acc: 87.090000\n",
      "Epoch: [42][0/391]\tTime 0.296 (0.296)\tData 0.244 (0.244)\tLoss 0.1269 (0.1269)\tPrec 96.094% (96.094%)\n",
      "Epoch: [42][100/391]\tTime 0.055 (0.058)\tData 0.002 (0.004)\tLoss 0.2062 (0.2405)\tPrec 92.969% (91.793%)\n",
      "Epoch: [42][200/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 0.2028 (0.2302)\tPrec 92.969% (92.137%)\n",
      "Epoch: [42][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.002)\tLoss 0.3650 (0.2297)\tPrec 87.500% (92.172%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.217 (0.217)\tLoss 0.3222 (0.3222)\tPrec 87.500% (87.500%)\n",
      " * Prec 86.280% \n",
      "best acc: 87.090000\n",
      "Epoch: [43][0/391]\tTime 0.304 (0.304)\tData 0.254 (0.254)\tLoss 0.2030 (0.2030)\tPrec 92.188% (92.188%)\n",
      "Epoch: [43][100/391]\tTime 0.056 (0.058)\tData 0.001 (0.004)\tLoss 0.1199 (0.2050)\tPrec 93.750% (92.922%)\n",
      "Epoch: [43][200/391]\tTime 0.053 (0.057)\tData 0.002 (0.003)\tLoss 0.1501 (0.2114)\tPrec 95.312% (92.716%)\n",
      "Epoch: [43][300/391]\tTime 0.055 (0.057)\tData 0.002 (0.003)\tLoss 0.1489 (0.2140)\tPrec 96.875% (92.683%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.242 (0.242)\tLoss 0.2368 (0.2368)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.210% \n",
      "best acc: 87.210000\n",
      "Epoch: [44][0/391]\tTime 0.303 (0.303)\tData 0.252 (0.252)\tLoss 0.1307 (0.1307)\tPrec 94.531% (94.531%)\n",
      "Epoch: [44][100/391]\tTime 0.052 (0.058)\tData 0.004 (0.004)\tLoss 0.1698 (0.2035)\tPrec 95.312% (92.969%)\n",
      "Epoch: [44][200/391]\tTime 0.060 (0.057)\tData 0.002 (0.003)\tLoss 0.1628 (0.2137)\tPrec 95.312% (92.662%)\n",
      "Epoch: [44][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.2380 (0.2156)\tPrec 92.188% (92.694%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.236 (0.236)\tLoss 0.3560 (0.3560)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.300% \n",
      "best acc: 87.210000\n",
      "Epoch: [45][0/391]\tTime 0.285 (0.285)\tData 0.239 (0.239)\tLoss 0.1260 (0.1260)\tPrec 95.312% (95.312%)\n",
      "Epoch: [45][100/391]\tTime 0.070 (0.058)\tData 0.001 (0.004)\tLoss 0.1973 (0.1900)\tPrec 94.531% (93.603%)\n",
      "Epoch: [45][200/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.1932 (0.1964)\tPrec 93.750% (93.256%)\n",
      "Epoch: [45][300/391]\tTime 0.060 (0.057)\tData 0.002 (0.003)\tLoss 0.2032 (0.2009)\tPrec 93.750% (93.080%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 0.3133 (0.3133)\tPrec 90.625% (90.625%)\n",
      " * Prec 86.920% \n",
      "best acc: 87.210000\n",
      "Epoch: [46][0/391]\tTime 0.265 (0.265)\tData 0.218 (0.218)\tLoss 0.1727 (0.1727)\tPrec 94.531% (94.531%)\n",
      "Epoch: [46][100/391]\tTime 0.051 (0.057)\tData 0.002 (0.004)\tLoss 0.1823 (0.1945)\tPrec 92.969% (93.394%)\n",
      "Epoch: [46][200/391]\tTime 0.061 (0.057)\tData 0.001 (0.003)\tLoss 0.1787 (0.1937)\tPrec 92.188% (93.342%)\n",
      "Epoch: [46][300/391]\tTime 0.064 (0.056)\tData 0.001 (0.002)\tLoss 0.2201 (0.2019)\tPrec 89.844% (93.062%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.245 (0.245)\tLoss 0.3573 (0.3573)\tPrec 87.500% (87.500%)\n",
      " * Prec 85.060% \n",
      "best acc: 87.210000\n",
      "Epoch: [47][0/391]\tTime 0.289 (0.289)\tData 0.242 (0.242)\tLoss 0.2177 (0.2177)\tPrec 91.406% (91.406%)\n",
      "Epoch: [47][100/391]\tTime 0.056 (0.058)\tData 0.001 (0.004)\tLoss 0.1460 (0.1930)\tPrec 94.531% (93.557%)\n",
      "Epoch: [47][200/391]\tTime 0.056 (0.057)\tData 0.001 (0.003)\tLoss 0.1566 (0.1956)\tPrec 92.969% (93.369%)\n",
      "Epoch: [47][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.002)\tLoss 0.2015 (0.1987)\tPrec 92.188% (93.223%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.3023 (0.3023)\tPrec 90.625% (90.625%)\n",
      " * Prec 86.790% \n",
      "best acc: 87.210000\n",
      "Epoch: [48][0/391]\tTime 0.315 (0.315)\tData 0.264 (0.264)\tLoss 0.1537 (0.1537)\tPrec 94.531% (94.531%)\n",
      "Epoch: [48][100/391]\tTime 0.053 (0.058)\tData 0.001 (0.004)\tLoss 0.2074 (0.1799)\tPrec 92.969% (94.013%)\n",
      "Epoch: [48][200/391]\tTime 0.055 (0.057)\tData 0.002 (0.003)\tLoss 0.1530 (0.1906)\tPrec 96.094% (93.560%)\n",
      "Epoch: [48][300/391]\tTime 0.057 (0.056)\tData 0.001 (0.002)\tLoss 0.1977 (0.1940)\tPrec 92.969% (93.355%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 0.2220 (0.2220)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.140% \n",
      "best acc: 88.140000\n",
      "Epoch: [49][0/391]\tTime 0.268 (0.268)\tData 0.221 (0.221)\tLoss 0.1763 (0.1763)\tPrec 93.750% (93.750%)\n",
      "Epoch: [49][100/391]\tTime 0.055 (0.058)\tData 0.001 (0.004)\tLoss 0.1851 (0.1815)\tPrec 93.750% (93.742%)\n",
      "Epoch: [49][200/391]\tTime 0.052 (0.057)\tData 0.002 (0.003)\tLoss 0.1861 (0.1835)\tPrec 92.969% (93.696%)\n",
      "Epoch: [49][300/391]\tTime 0.054 (0.056)\tData 0.001 (0.002)\tLoss 0.1506 (0.1893)\tPrec 96.094% (93.550%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.1614 (0.1614)\tPrec 94.531% (94.531%)\n",
      " * Prec 87.540% \n",
      "best acc: 88.140000\n",
      "Epoch: [50][0/391]\tTime 0.268 (0.268)\tData 0.220 (0.220)\tLoss 0.0797 (0.0797)\tPrec 97.656% (97.656%)\n",
      "Epoch: [50][100/391]\tTime 0.056 (0.057)\tData 0.002 (0.004)\tLoss 0.1913 (0.1729)\tPrec 92.969% (93.990%)\n",
      "Epoch: [50][200/391]\tTime 0.056 (0.056)\tData 0.003 (0.003)\tLoss 0.1338 (0.1789)\tPrec 94.531% (93.766%)\n",
      "Epoch: [50][300/391]\tTime 0.056 (0.056)\tData 0.001 (0.002)\tLoss 0.1505 (0.1825)\tPrec 96.094% (93.695%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.246 (0.246)\tLoss 0.2810 (0.2810)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.320% \n",
      "best acc: 88.140000\n",
      "Epoch: [51][0/391]\tTime 0.273 (0.273)\tData 0.232 (0.232)\tLoss 0.1065 (0.1065)\tPrec 96.875% (96.875%)\n",
      "Epoch: [51][100/391]\tTime 0.055 (0.058)\tData 0.002 (0.004)\tLoss 0.1885 (0.1833)\tPrec 93.750% (93.704%)\n",
      "Epoch: [51][200/391]\tTime 0.054 (0.057)\tData 0.001 (0.003)\tLoss 0.2415 (0.1845)\tPrec 92.188% (93.731%)\n",
      "Epoch: [51][300/391]\tTime 0.057 (0.056)\tData 0.001 (0.002)\tLoss 0.1429 (0.1815)\tPrec 96.875% (93.877%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.234 (0.234)\tLoss 0.3303 (0.3303)\tPrec 90.625% (90.625%)\n",
      " * Prec 86.120% \n",
      "best acc: 88.140000\n",
      "Epoch: [52][0/391]\tTime 0.283 (0.283)\tData 0.242 (0.242)\tLoss 0.1348 (0.1348)\tPrec 95.312% (95.312%)\n",
      "Epoch: [52][100/391]\tTime 0.071 (0.058)\tData 0.001 (0.004)\tLoss 0.1662 (0.1658)\tPrec 92.188% (94.330%)\n",
      "Epoch: [52][200/391]\tTime 0.061 (0.057)\tData 0.002 (0.003)\tLoss 0.1964 (0.1704)\tPrec 92.969% (94.189%)\n",
      "Epoch: [52][300/391]\tTime 0.063 (0.056)\tData 0.002 (0.002)\tLoss 0.1225 (0.1701)\tPrec 96.094% (94.204%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.226 (0.226)\tLoss 0.4285 (0.4285)\tPrec 86.719% (86.719%)\n",
      " * Prec 86.560% \n",
      "best acc: 88.140000\n",
      "Epoch: [53][0/391]\tTime 0.278 (0.278)\tData 0.227 (0.227)\tLoss 0.1629 (0.1629)\tPrec 94.531% (94.531%)\n",
      "Epoch: [53][100/391]\tTime 0.052 (0.057)\tData 0.004 (0.004)\tLoss 0.1540 (0.1606)\tPrec 96.094% (94.485%)\n",
      "Epoch: [53][200/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.3587 (0.1718)\tPrec 87.500% (94.022%)\n",
      "Epoch: [53][300/391]\tTime 0.061 (0.056)\tData 0.002 (0.002)\tLoss 0.3081 (0.1775)\tPrec 90.625% (93.888%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.254 (0.254)\tLoss 0.3578 (0.3578)\tPrec 86.719% (86.719%)\n",
      " * Prec 86.960% \n",
      "best acc: 88.140000\n",
      "Epoch: [54][0/391]\tTime 0.273 (0.273)\tData 0.226 (0.226)\tLoss 0.0926 (0.0926)\tPrec 97.656% (97.656%)\n",
      "Epoch: [54][100/391]\tTime 0.063 (0.058)\tData 0.001 (0.004)\tLoss 0.2125 (0.1630)\tPrec 92.969% (94.268%)\n",
      "Epoch: [54][200/391]\tTime 0.065 (0.057)\tData 0.002 (0.003)\tLoss 0.1723 (0.1712)\tPrec 96.094% (94.045%)\n",
      "Epoch: [54][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.002)\tLoss 0.1594 (0.1727)\tPrec 93.750% (94.064%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.227 (0.227)\tLoss 0.4193 (0.4193)\tPrec 85.938% (85.938%)\n",
      " * Prec 86.690% \n",
      "best acc: 88.140000\n",
      "Epoch: [55][0/391]\tTime 0.326 (0.326)\tData 0.286 (0.286)\tLoss 0.1431 (0.1431)\tPrec 96.094% (96.094%)\n",
      "Epoch: [55][100/391]\tTime 0.056 (0.058)\tData 0.001 (0.004)\tLoss 0.1005 (0.1603)\tPrec 96.875% (94.524%)\n",
      "Epoch: [55][200/391]\tTime 0.054 (0.057)\tData 0.001 (0.003)\tLoss 0.2057 (0.1626)\tPrec 92.188% (94.488%)\n",
      "Epoch: [55][300/391]\tTime 0.057 (0.056)\tData 0.002 (0.003)\tLoss 0.2630 (0.1668)\tPrec 91.406% (94.256%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 0.1924 (0.1924)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.350% \n",
      "best acc: 88.140000\n",
      "Epoch: [56][0/391]\tTime 0.274 (0.274)\tData 0.229 (0.229)\tLoss 0.0521 (0.0521)\tPrec 99.219% (99.219%)\n",
      "Epoch: [56][100/391]\tTime 0.057 (0.058)\tData 0.003 (0.004)\tLoss 0.1541 (0.1514)\tPrec 92.969% (94.771%)\n",
      "Epoch: [56][200/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.2161 (0.1576)\tPrec 89.844% (94.562%)\n",
      "Epoch: [56][300/391]\tTime 0.054 (0.057)\tData 0.001 (0.002)\tLoss 0.2075 (0.1612)\tPrec 93.750% (94.456%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.2591 (0.2591)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.810% \n",
      "best acc: 88.140000\n",
      "Epoch: [57][0/391]\tTime 0.273 (0.273)\tData 0.230 (0.230)\tLoss 0.0767 (0.0767)\tPrec 97.656% (97.656%)\n",
      "Epoch: [57][100/391]\tTime 0.054 (0.058)\tData 0.002 (0.004)\tLoss 0.0927 (0.1479)\tPrec 96.875% (95.088%)\n",
      "Epoch: [57][200/391]\tTime 0.059 (0.057)\tData 0.001 (0.003)\tLoss 0.1660 (0.1518)\tPrec 91.406% (94.939%)\n",
      "Epoch: [57][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.002)\tLoss 0.1710 (0.1571)\tPrec 94.531% (94.723%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.1943 (0.1943)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.510% \n",
      "best acc: 88.140000\n",
      "Epoch: [58][0/391]\tTime 0.315 (0.315)\tData 0.267 (0.267)\tLoss 0.0856 (0.0856)\tPrec 96.094% (96.094%)\n",
      "Epoch: [58][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.004)\tLoss 0.2058 (0.1539)\tPrec 94.531% (94.640%)\n",
      "Epoch: [58][200/391]\tTime 0.053 (0.057)\tData 0.002 (0.003)\tLoss 0.1569 (0.1497)\tPrec 91.406% (94.838%)\n",
      "Epoch: [58][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.002)\tLoss 0.2331 (0.1534)\tPrec 90.625% (94.661%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.3154 (0.3154)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.170% \n",
      "best acc: 88.140000\n",
      "Epoch: [59][0/391]\tTime 0.272 (0.272)\tData 0.224 (0.224)\tLoss 0.2159 (0.2159)\tPrec 92.969% (92.969%)\n",
      "Epoch: [59][100/391]\tTime 0.055 (0.058)\tData 0.001 (0.004)\tLoss 0.1545 (0.1559)\tPrec 96.875% (94.609%)\n",
      "Epoch: [59][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.003)\tLoss 0.1323 (0.1508)\tPrec 95.312% (94.881%)\n",
      "Epoch: [59][300/391]\tTime 0.057 (0.057)\tData 0.001 (0.002)\tLoss 0.1391 (0.1587)\tPrec 94.531% (94.562%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.345 (0.345)\tLoss 0.3938 (0.3938)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.670% \n",
      "best acc: 88.140000\n",
      "Epoch: [60][0/391]\tTime 0.271 (0.271)\tData 0.225 (0.225)\tLoss 0.2015 (0.2015)\tPrec 92.969% (92.969%)\n",
      "Epoch: [60][100/391]\tTime 0.055 (0.057)\tData 0.001 (0.004)\tLoss 0.1456 (0.1397)\tPrec 94.531% (95.119%)\n",
      "Epoch: [60][200/391]\tTime 0.056 (0.056)\tData 0.002 (0.003)\tLoss 0.1555 (0.1463)\tPrec 95.312% (94.819%)\n",
      "Epoch: [60][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.002)\tLoss 0.1114 (0.1489)\tPrec 96.875% (94.791%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.224 (0.224)\tLoss 0.4133 (0.4133)\tPrec 86.719% (86.719%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec 86.080% \n",
      "best acc: 88.140000\n",
      "Epoch: [61][0/391]\tTime 0.299 (0.299)\tData 0.247 (0.247)\tLoss 0.0937 (0.0937)\tPrec 97.656% (97.656%)\n",
      "Epoch: [61][100/391]\tTime 0.059 (0.058)\tData 0.001 (0.004)\tLoss 0.1269 (0.1482)\tPrec 95.312% (94.964%)\n",
      "Epoch: [61][200/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 0.1110 (0.1423)\tPrec 96.875% (95.145%)\n",
      "Epoch: [61][300/391]\tTime 0.056 (0.056)\tData 0.002 (0.002)\tLoss 0.0617 (0.1459)\tPrec 97.656% (95.043%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.229 (0.229)\tLoss 0.2397 (0.2397)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.100% \n",
      "best acc: 88.140000\n",
      "Epoch: [62][0/391]\tTime 0.302 (0.302)\tData 0.253 (0.253)\tLoss 0.1530 (0.1530)\tPrec 95.312% (95.312%)\n",
      "Epoch: [62][100/391]\tTime 0.058 (0.058)\tData 0.002 (0.004)\tLoss 0.1306 (0.1343)\tPrec 96.875% (95.359%)\n",
      "Epoch: [62][200/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 0.0606 (0.1377)\tPrec 97.656% (95.285%)\n",
      "Epoch: [62][300/391]\tTime 0.058 (0.057)\tData 0.002 (0.003)\tLoss 0.1315 (0.1432)\tPrec 96.094% (95.063%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.222 (0.222)\tLoss 0.3128 (0.3128)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.650% \n",
      "best acc: 88.140000\n",
      "Epoch: [63][0/391]\tTime 0.273 (0.273)\tData 0.228 (0.228)\tLoss 0.1102 (0.1102)\tPrec 94.531% (94.531%)\n",
      "Epoch: [63][100/391]\tTime 0.055 (0.057)\tData 0.002 (0.004)\tLoss 0.0728 (0.1348)\tPrec 96.094% (95.452%)\n",
      "Epoch: [63][200/391]\tTime 0.057 (0.057)\tData 0.001 (0.003)\tLoss 0.2077 (0.1408)\tPrec 92.969% (95.266%)\n",
      "Epoch: [63][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.0969 (0.1442)\tPrec 96.875% (95.105%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.273 (0.273)\tLoss 0.4675 (0.4675)\tPrec 85.938% (85.938%)\n",
      " * Prec 85.720% \n",
      "best acc: 88.140000\n",
      "Epoch: [64][0/391]\tTime 0.294 (0.294)\tData 0.247 (0.247)\tLoss 0.1204 (0.1204)\tPrec 95.312% (95.312%)\n",
      "Epoch: [64][100/391]\tTime 0.057 (0.058)\tData 0.002 (0.004)\tLoss 0.2016 (0.1250)\tPrec 92.188% (95.614%)\n",
      "Epoch: [64][200/391]\tTime 0.059 (0.057)\tData 0.002 (0.003)\tLoss 0.0938 (0.1312)\tPrec 96.094% (95.487%)\n",
      "Epoch: [64][300/391]\tTime 0.056 (0.057)\tData 0.001 (0.002)\tLoss 0.1890 (0.1352)\tPrec 95.312% (95.380%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.3814 (0.3814)\tPrec 86.719% (86.719%)\n",
      " * Prec 87.950% \n",
      "best acc: 88.140000\n",
      "Epoch: [65][0/391]\tTime 0.287 (0.287)\tData 0.239 (0.239)\tLoss 0.0954 (0.0954)\tPrec 96.875% (96.875%)\n",
      "Epoch: [65][100/391]\tTime 0.050 (0.058)\tData 0.001 (0.004)\tLoss 0.2069 (0.1393)\tPrec 92.188% (95.336%)\n",
      "Epoch: [65][200/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.1180 (0.1449)\tPrec 96.094% (95.126%)\n",
      "Epoch: [65][300/391]\tTime 0.050 (0.056)\tData 0.002 (0.002)\tLoss 0.1513 (0.1434)\tPrec 96.094% (95.128%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.236 (0.236)\tLoss 0.3535 (0.3535)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.800% \n",
      "best acc: 88.140000\n",
      "Epoch: [66][0/391]\tTime 0.297 (0.297)\tData 0.250 (0.250)\tLoss 0.1536 (0.1536)\tPrec 92.969% (92.969%)\n",
      "Epoch: [66][100/391]\tTime 0.055 (0.057)\tData 0.001 (0.004)\tLoss 0.1921 (0.1328)\tPrec 93.750% (95.521%)\n",
      "Epoch: [66][200/391]\tTime 0.054 (0.056)\tData 0.002 (0.003)\tLoss 0.1971 (0.1329)\tPrec 92.188% (95.491%)\n",
      "Epoch: [66][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.1569 (0.1339)\tPrec 95.312% (95.460%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.226 (0.226)\tLoss 0.3051 (0.3051)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.390% \n",
      "best acc: 88.140000\n",
      "Epoch: [67][0/391]\tTime 0.298 (0.298)\tData 0.243 (0.243)\tLoss 0.1145 (0.1145)\tPrec 96.094% (96.094%)\n",
      "Epoch: [67][100/391]\tTime 0.060 (0.058)\tData 0.001 (0.004)\tLoss 0.1130 (0.1298)\tPrec 96.875% (95.699%)\n",
      "Epoch: [67][200/391]\tTime 0.050 (0.057)\tData 0.002 (0.003)\tLoss 0.1081 (0.1325)\tPrec 96.094% (95.600%)\n",
      "Epoch: [67][300/391]\tTime 0.052 (0.056)\tData 0.002 (0.002)\tLoss 0.1847 (0.1333)\tPrec 90.625% (95.523%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.3055 (0.3055)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.740% \n",
      "best acc: 88.740000\n",
      "Epoch: [68][0/391]\tTime 0.298 (0.298)\tData 0.252 (0.252)\tLoss 0.1845 (0.1845)\tPrec 93.750% (93.750%)\n",
      "Epoch: [68][100/391]\tTime 0.055 (0.058)\tData 0.002 (0.004)\tLoss 0.1128 (0.1289)\tPrec 96.094% (95.738%)\n",
      "Epoch: [68][200/391]\tTime 0.064 (0.057)\tData 0.002 (0.003)\tLoss 0.1257 (0.1316)\tPrec 94.531% (95.499%)\n",
      "Epoch: [68][300/391]\tTime 0.059 (0.057)\tData 0.001 (0.003)\tLoss 0.1046 (0.1349)\tPrec 96.875% (95.466%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.254 (0.254)\tLoss 0.4792 (0.4792)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.100% \n",
      "best acc: 88.740000\n",
      "Epoch: [69][0/391]\tTime 0.269 (0.269)\tData 0.224 (0.224)\tLoss 0.1117 (0.1117)\tPrec 96.094% (96.094%)\n",
      "Epoch: [69][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.004)\tLoss 0.1306 (0.1205)\tPrec 92.188% (95.815%)\n",
      "Epoch: [69][200/391]\tTime 0.063 (0.057)\tData 0.001 (0.003)\tLoss 0.1340 (0.1274)\tPrec 96.875% (95.674%)\n",
      "Epoch: [69][300/391]\tTime 0.059 (0.056)\tData 0.002 (0.002)\tLoss 0.1431 (0.1314)\tPrec 95.312% (95.562%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.240 (0.240)\tLoss 0.2813 (0.2813)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.300% \n",
      "best acc: 88.740000\n",
      "Epoch: [70][0/391]\tTime 0.242 (0.242)\tData 0.193 (0.193)\tLoss 0.1011 (0.1011)\tPrec 94.531% (94.531%)\n",
      "Epoch: [70][100/391]\tTime 0.055 (0.058)\tData 0.001 (0.004)\tLoss 0.1480 (0.1288)\tPrec 96.094% (95.552%)\n",
      "Epoch: [70][200/391]\tTime 0.051 (0.057)\tData 0.003 (0.003)\tLoss 0.0880 (0.1282)\tPrec 96.875% (95.678%)\n",
      "Epoch: [70][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.1368 (0.1288)\tPrec 95.312% (95.671%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.235 (0.235)\tLoss 0.3531 (0.3531)\tPrec 90.625% (90.625%)\n",
      " * Prec 86.350% \n",
      "best acc: 88.740000\n",
      "Epoch: [71][0/391]\tTime 0.273 (0.273)\tData 0.229 (0.229)\tLoss 0.0895 (0.0895)\tPrec 97.656% (97.656%)\n",
      "Epoch: [71][100/391]\tTime 0.065 (0.058)\tData 0.002 (0.004)\tLoss 0.1004 (0.1211)\tPrec 95.312% (95.777%)\n",
      "Epoch: [71][200/391]\tTime 0.049 (0.056)\tData 0.003 (0.003)\tLoss 0.1453 (0.1299)\tPrec 96.875% (95.557%)\n",
      "Epoch: [71][300/391]\tTime 0.056 (0.056)\tData 0.001 (0.002)\tLoss 0.1687 (0.1296)\tPrec 96.094% (95.546%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.236 (0.236)\tLoss 0.3855 (0.3855)\tPrec 87.500% (87.500%)\n",
      " * Prec 87.650% \n",
      "best acc: 88.740000\n",
      "Epoch: [72][0/391]\tTime 0.296 (0.296)\tData 0.246 (0.246)\tLoss 0.0877 (0.0877)\tPrec 98.438% (98.438%)\n",
      "Epoch: [72][100/391]\tTime 0.059 (0.058)\tData 0.002 (0.004)\tLoss 0.0990 (0.1290)\tPrec 95.312% (95.637%)\n",
      "Epoch: [72][200/391]\tTime 0.058 (0.057)\tData 0.002 (0.003)\tLoss 0.2168 (0.1301)\tPrec 93.750% (95.623%)\n",
      "Epoch: [72][300/391]\tTime 0.052 (0.057)\tData 0.001 (0.003)\tLoss 0.1653 (0.1304)\tPrec 94.531% (95.580%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.221 (0.221)\tLoss 0.2881 (0.2881)\tPrec 90.625% (90.625%)\n",
      " * Prec 86.800% \n",
      "best acc: 88.740000\n",
      "Epoch: [73][0/391]\tTime 0.272 (0.272)\tData 0.222 (0.222)\tLoss 0.1463 (0.1463)\tPrec 93.750% (93.750%)\n",
      "Epoch: [73][100/391]\tTime 0.060 (0.058)\tData 0.001 (0.004)\tLoss 0.1619 (0.1201)\tPrec 92.969% (95.823%)\n",
      "Epoch: [73][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.003)\tLoss 0.1411 (0.1224)\tPrec 96.094% (95.771%)\n",
      "Epoch: [73][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.1530 (0.1224)\tPrec 94.531% (95.790%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.3841 (0.3841)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.860% \n",
      "best acc: 88.740000\n",
      "Epoch: [74][0/391]\tTime 0.283 (0.283)\tData 0.242 (0.242)\tLoss 0.0445 (0.0445)\tPrec 99.219% (99.219%)\n",
      "Epoch: [74][100/391]\tTime 0.053 (0.058)\tData 0.001 (0.004)\tLoss 0.0772 (0.1149)\tPrec 97.656% (96.009%)\n",
      "Epoch: [74][200/391]\tTime 0.057 (0.057)\tData 0.001 (0.003)\tLoss 0.1759 (0.1196)\tPrec 95.312% (95.911%)\n",
      "Epoch: [74][300/391]\tTime 0.056 (0.056)\tData 0.001 (0.002)\tLoss 0.0605 (0.1270)\tPrec 98.438% (95.665%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.221 (0.221)\tLoss 0.2868 (0.2868)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.270% \n",
      "best acc: 88.740000\n",
      "Epoch: [75][0/391]\tTime 0.260 (0.260)\tData 0.213 (0.213)\tLoss 0.1210 (0.1210)\tPrec 96.094% (96.094%)\n",
      "Epoch: [75][100/391]\tTime 0.060 (0.057)\tData 0.002 (0.004)\tLoss 0.1328 (0.1046)\tPrec 96.875% (96.573%)\n",
      "Epoch: [75][200/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.1259 (0.1171)\tPrec 93.750% (96.105%)\n",
      "Epoch: [75][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.1329 (0.1221)\tPrec 93.750% (95.847%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.226 (0.226)\tLoss 0.1898 (0.1898)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.470% \n",
      "best acc: 88.740000\n",
      "Epoch: [76][0/391]\tTime 0.269 (0.269)\tData 0.221 (0.221)\tLoss 0.0483 (0.0483)\tPrec 97.656% (97.656%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [76][100/391]\tTime 0.055 (0.058)\tData 0.002 (0.004)\tLoss 0.0898 (0.1089)\tPrec 96.875% (96.310%)\n",
      "Epoch: [76][200/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.0978 (0.1118)\tPrec 98.438% (96.226%)\n",
      "Epoch: [76][300/391]\tTime 0.056 (0.056)\tData 0.001 (0.002)\tLoss 0.0760 (0.1169)\tPrec 96.875% (96.140%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.233 (0.233)\tLoss 0.3449 (0.3449)\tPrec 92.188% (92.188%)\n",
      " * Prec 86.700% \n",
      "best acc: 88.740000\n",
      "Epoch: [77][0/391]\tTime 0.279 (0.279)\tData 0.232 (0.232)\tLoss 0.1696 (0.1696)\tPrec 94.531% (94.531%)\n",
      "Epoch: [77][100/391]\tTime 0.053 (0.057)\tData 0.001 (0.004)\tLoss 0.1624 (0.1200)\tPrec 93.750% (96.040%)\n",
      "Epoch: [77][200/391]\tTime 0.056 (0.056)\tData 0.001 (0.003)\tLoss 0.1407 (0.1219)\tPrec 95.312% (95.927%)\n",
      "Epoch: [77][300/391]\tTime 0.053 (0.056)\tData 0.001 (0.002)\tLoss 0.1175 (0.1209)\tPrec 95.312% (95.948%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.252 (0.252)\tLoss 0.1998 (0.1998)\tPrec 92.188% (92.188%)\n",
      " * Prec 86.050% \n",
      "best acc: 88.740000\n",
      "Epoch: [78][0/391]\tTime 0.281 (0.281)\tData 0.232 (0.232)\tLoss 0.1439 (0.1439)\tPrec 96.094% (96.094%)\n",
      "Epoch: [78][100/391]\tTime 0.054 (0.057)\tData 0.001 (0.004)\tLoss 0.1353 (0.1088)\tPrec 93.750% (96.457%)\n",
      "Epoch: [78][200/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.1391 (0.1134)\tPrec 94.531% (96.191%)\n",
      "Epoch: [78][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.002)\tLoss 0.1496 (0.1167)\tPrec 95.312% (96.065%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.221 (0.221)\tLoss 0.2815 (0.2815)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.920% \n",
      "best acc: 88.740000\n",
      "Epoch: [79][0/391]\tTime 0.292 (0.292)\tData 0.247 (0.247)\tLoss 0.1242 (0.1242)\tPrec 94.531% (94.531%)\n",
      "Epoch: [79][100/391]\tTime 0.056 (0.057)\tData 0.002 (0.004)\tLoss 0.1523 (0.1077)\tPrec 96.094% (96.395%)\n",
      "Epoch: [79][200/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.0771 (0.1132)\tPrec 97.656% (96.140%)\n",
      "Epoch: [79][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.0680 (0.1133)\tPrec 97.656% (96.078%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.239 (0.239)\tLoss 0.3236 (0.3236)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.900% \n",
      "best acc: 88.740000\n",
      "Epoch: [80][0/391]\tTime 0.281 (0.281)\tData 0.234 (0.234)\tLoss 0.0890 (0.0890)\tPrec 96.875% (96.875%)\n",
      "Epoch: [80][100/391]\tTime 0.057 (0.058)\tData 0.001 (0.004)\tLoss 0.0697 (0.0730)\tPrec 96.875% (97.703%)\n",
      "Epoch: [80][200/391]\tTime 0.061 (0.057)\tData 0.001 (0.003)\tLoss 0.1069 (0.0639)\tPrec 95.312% (97.913%)\n",
      "Epoch: [80][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.0371 (0.0603)\tPrec 99.219% (98.051%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.2292 (0.2292)\tPrec 92.969% (92.969%)\n",
      " * Prec 90.920% \n",
      "best acc: 90.920000\n",
      "Epoch: [81][0/391]\tTime 0.286 (0.286)\tData 0.239 (0.239)\tLoss 0.0844 (0.0844)\tPrec 97.656% (97.656%)\n",
      "Epoch: [81][100/391]\tTime 0.055 (0.057)\tData 0.002 (0.004)\tLoss 0.0196 (0.0422)\tPrec 99.219% (98.708%)\n",
      "Epoch: [81][200/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.0081 (0.0402)\tPrec 100.000% (98.748%)\n",
      "Epoch: [81][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.0852 (0.0408)\tPrec 96.875% (98.718%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.259 (0.259)\tLoss 0.1943 (0.1943)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.280% \n",
      "best acc: 91.280000\n",
      "Epoch: [82][0/391]\tTime 0.290 (0.290)\tData 0.241 (0.241)\tLoss 0.0227 (0.0227)\tPrec 100.000% (100.000%)\n",
      "Epoch: [82][100/391]\tTime 0.054 (0.058)\tData 0.001 (0.004)\tLoss 0.0562 (0.0347)\tPrec 98.438% (99.002%)\n",
      "Epoch: [82][200/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.0038 (0.0343)\tPrec 100.000% (98.982%)\n",
      "Epoch: [82][300/391]\tTime 0.054 (0.056)\tData 0.001 (0.002)\tLoss 0.0214 (0.0349)\tPrec 99.219% (98.933%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.233 (0.233)\tLoss 0.1684 (0.1684)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.880% \n",
      "best acc: 91.280000\n",
      "Epoch: [83][0/391]\tTime 0.290 (0.290)\tData 0.238 (0.238)\tLoss 0.0581 (0.0581)\tPrec 96.875% (96.875%)\n",
      "Epoch: [83][100/391]\tTime 0.054 (0.058)\tData 0.001 (0.004)\tLoss 0.0353 (0.0324)\tPrec 99.219% (98.917%)\n",
      "Epoch: [83][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.003)\tLoss 0.0206 (0.0321)\tPrec 99.219% (98.927%)\n",
      "Epoch: [83][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.0123 (0.0317)\tPrec 99.219% (98.941%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 0.2055 (0.2055)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.110% \n",
      "best acc: 91.280000\n",
      "Epoch: [84][0/391]\tTime 0.256 (0.256)\tData 0.211 (0.211)\tLoss 0.0217 (0.0217)\tPrec 99.219% (99.219%)\n",
      "Epoch: [84][100/391]\tTime 0.055 (0.057)\tData 0.001 (0.004)\tLoss 0.0101 (0.0277)\tPrec 100.000% (99.165%)\n",
      "Epoch: [84][200/391]\tTime 0.054 (0.056)\tData 0.001 (0.002)\tLoss 0.0666 (0.0273)\tPrec 97.656% (99.188%)\n",
      "Epoch: [84][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.0230 (0.0274)\tPrec 99.219% (99.164%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.231 (0.231)\tLoss 0.1926 (0.1926)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.220% \n",
      "best acc: 91.280000\n",
      "Epoch: [85][0/391]\tTime 0.266 (0.266)\tData 0.226 (0.226)\tLoss 0.0138 (0.0138)\tPrec 100.000% (100.000%)\n",
      "Epoch: [85][100/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.0402 (0.0241)\tPrec 99.219% (99.211%)\n",
      "Epoch: [85][200/391]\tTime 0.060 (0.056)\tData 0.001 (0.002)\tLoss 0.0239 (0.0238)\tPrec 99.219% (99.227%)\n",
      "Epoch: [85][300/391]\tTime 0.050 (0.056)\tData 0.001 (0.002)\tLoss 0.0140 (0.0241)\tPrec 99.219% (99.190%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 0.2357 (0.2357)\tPrec 92.969% (92.969%)\n",
      " * Prec 90.850% \n",
      "best acc: 91.280000\n",
      "Epoch: [86][0/391]\tTime 0.267 (0.267)\tData 0.225 (0.225)\tLoss 0.0101 (0.0101)\tPrec 100.000% (100.000%)\n",
      "Epoch: [86][100/391]\tTime 0.058 (0.058)\tData 0.001 (0.004)\tLoss 0.0053 (0.0228)\tPrec 100.000% (99.281%)\n",
      "Epoch: [86][200/391]\tTime 0.055 (0.057)\tData 0.001 (0.002)\tLoss 0.0083 (0.0214)\tPrec 100.000% (99.308%)\n",
      "Epoch: [86][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.0046 (0.0213)\tPrec 100.000% (99.289%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.233 (0.233)\tLoss 0.1956 (0.1956)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.320% \n",
      "best acc: 91.320000\n",
      "Epoch: [87][0/391]\tTime 0.313 (0.313)\tData 0.270 (0.270)\tLoss 0.0038 (0.0038)\tPrec 100.000% (100.000%)\n",
      "Epoch: [87][100/391]\tTime 0.055 (0.057)\tData 0.001 (0.004)\tLoss 0.0131 (0.0249)\tPrec 99.219% (99.165%)\n",
      "Epoch: [87][200/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.0126 (0.0235)\tPrec 100.000% (99.219%)\n",
      "Epoch: [87][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.0129 (0.0229)\tPrec 99.219% (99.252%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.1839 (0.1839)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.040% \n",
      "best acc: 91.320000\n",
      "Epoch: [88][0/391]\tTime 0.272 (0.272)\tData 0.232 (0.232)\tLoss 0.0105 (0.0105)\tPrec 100.000% (100.000%)\n",
      "Epoch: [88][100/391]\tTime 0.058 (0.057)\tData 0.001 (0.004)\tLoss 0.0327 (0.0201)\tPrec 99.219% (99.319%)\n",
      "Epoch: [88][200/391]\tTime 0.056 (0.056)\tData 0.001 (0.003)\tLoss 0.0167 (0.0202)\tPrec 99.219% (99.335%)\n",
      "Epoch: [88][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.0117 (0.0202)\tPrec 100.000% (99.328%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.241 (0.241)\tLoss 0.2084 (0.2084)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.200% \n",
      "best acc: 91.320000\n",
      "Epoch: [89][0/391]\tTime 0.271 (0.271)\tData 0.224 (0.224)\tLoss 0.0149 (0.0149)\tPrec 100.000% (100.000%)\n",
      "Epoch: [89][100/391]\tTime 0.055 (0.057)\tData 0.001 (0.004)\tLoss 0.0074 (0.0197)\tPrec 100.000% (99.381%)\n",
      "Epoch: [89][200/391]\tTime 0.054 (0.056)\tData 0.001 (0.003)\tLoss 0.0209 (0.0196)\tPrec 99.219% (99.351%)\n",
      "Epoch: [89][300/391]\tTime 0.054 (0.056)\tData 0.001 (0.002)\tLoss 0.0083 (0.0193)\tPrec 100.000% (99.362%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 0.1716 (0.1716)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.950% \n",
      "best acc: 91.320000\n",
      "Epoch: [90][0/391]\tTime 0.275 (0.275)\tData 0.234 (0.234)\tLoss 0.0494 (0.0494)\tPrec 98.438% (98.438%)\n",
      "Epoch: [90][100/391]\tTime 0.056 (0.058)\tData 0.001 (0.004)\tLoss 0.0477 (0.0188)\tPrec 98.438% (99.350%)\n",
      "Epoch: [90][200/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.0167 (0.0184)\tPrec 99.219% (99.370%)\n",
      "Epoch: [90][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.0110 (0.0188)\tPrec 99.219% (99.369%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.1840 (0.1840)\tPrec 95.312% (95.312%)\n",
      " * Prec 91.260% \n",
      "best acc: 91.320000\n",
      "Epoch: [91][0/391]\tTime 0.266 (0.266)\tData 0.219 (0.219)\tLoss 0.0039 (0.0039)\tPrec 100.000% (100.000%)\n",
      "Epoch: [91][100/391]\tTime 0.055 (0.057)\tData 0.001 (0.004)\tLoss 0.0295 (0.0185)\tPrec 98.438% (99.381%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [91][200/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.0072 (0.0177)\tPrec 100.000% (99.390%)\n",
      "Epoch: [91][300/391]\tTime 0.056 (0.056)\tData 0.001 (0.002)\tLoss 0.0057 (0.0176)\tPrec 100.000% (99.421%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.253 (0.253)\tLoss 0.1996 (0.1996)\tPrec 96.094% (96.094%)\n",
      " * Prec 91.380% \n",
      "best acc: 91.380000\n",
      "Epoch: [92][0/391]\tTime 0.272 (0.272)\tData 0.230 (0.230)\tLoss 0.0136 (0.0136)\tPrec 99.219% (99.219%)\n",
      "Epoch: [92][100/391]\tTime 0.054 (0.057)\tData 0.001 (0.004)\tLoss 0.0074 (0.0162)\tPrec 100.000% (99.497%)\n",
      "Epoch: [92][200/391]\tTime 0.053 (0.056)\tData 0.001 (0.003)\tLoss 0.0251 (0.0158)\tPrec 99.219% (99.499%)\n",
      "Epoch: [92][300/391]\tTime 0.061 (0.056)\tData 0.001 (0.002)\tLoss 0.0315 (0.0166)\tPrec 99.219% (99.496%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.233 (0.233)\tLoss 0.1921 (0.1921)\tPrec 96.094% (96.094%)\n",
      " * Prec 91.380% \n",
      "best acc: 91.380000\n",
      "Epoch: [93][0/391]\tTime 0.284 (0.284)\tData 0.237 (0.237)\tLoss 0.0277 (0.0277)\tPrec 98.438% (98.438%)\n",
      "Epoch: [93][100/391]\tTime 0.055 (0.057)\tData 0.002 (0.004)\tLoss 0.0112 (0.0143)\tPrec 100.000% (99.520%)\n",
      "Epoch: [93][200/391]\tTime 0.053 (0.056)\tData 0.001 (0.003)\tLoss 0.0232 (0.0140)\tPrec 99.219% (99.537%)\n",
      "Epoch: [93][300/391]\tTime 0.056 (0.056)\tData 0.002 (0.002)\tLoss 0.0072 (0.0149)\tPrec 100.000% (99.504%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.217 (0.217)\tLoss 0.2127 (0.2127)\tPrec 96.094% (96.094%)\n",
      " * Prec 91.340% \n",
      "best acc: 91.380000\n",
      "Epoch: [94][0/391]\tTime 0.280 (0.280)\tData 0.232 (0.232)\tLoss 0.0344 (0.0344)\tPrec 99.219% (99.219%)\n",
      "Epoch: [94][100/391]\tTime 0.059 (0.057)\tData 0.002 (0.004)\tLoss 0.0162 (0.0167)\tPrec 99.219% (99.513%)\n",
      "Epoch: [94][200/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.0128 (0.0154)\tPrec 99.219% (99.526%)\n",
      "Epoch: [94][300/391]\tTime 0.053 (0.056)\tData 0.001 (0.002)\tLoss 0.0131 (0.0149)\tPrec 100.000% (99.546%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 0.2090 (0.2090)\tPrec 95.312% (95.312%)\n",
      " * Prec 91.320% \n",
      "best acc: 91.380000\n",
      "Epoch: [95][0/391]\tTime 0.294 (0.294)\tData 0.249 (0.249)\tLoss 0.0032 (0.0032)\tPrec 100.000% (100.000%)\n",
      "Epoch: [95][100/391]\tTime 0.056 (0.058)\tData 0.002 (0.004)\tLoss 0.0031 (0.0152)\tPrec 100.000% (99.513%)\n",
      "Epoch: [95][200/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.0818 (0.0151)\tPrec 96.875% (99.526%)\n",
      "Epoch: [95][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.0053 (0.0161)\tPrec 100.000% (99.483%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.235 (0.235)\tLoss 0.2050 (0.2050)\tPrec 95.312% (95.312%)\n",
      " * Prec 91.410% \n",
      "best acc: 91.410000\n",
      "Epoch: [96][0/391]\tTime 0.267 (0.267)\tData 0.218 (0.218)\tLoss 0.0111 (0.0111)\tPrec 99.219% (99.219%)\n",
      "Epoch: [96][100/391]\tTime 0.056 (0.057)\tData 0.001 (0.004)\tLoss 0.0271 (0.0150)\tPrec 99.219% (99.536%)\n",
      "Epoch: [96][200/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.0369 (0.0147)\tPrec 99.219% (99.537%)\n",
      "Epoch: [96][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.0187 (0.0157)\tPrec 99.219% (99.507%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.221 (0.221)\tLoss 0.1923 (0.1923)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.350% \n",
      "best acc: 91.410000\n",
      "Epoch: [97][0/391]\tTime 0.266 (0.266)\tData 0.221 (0.221)\tLoss 0.0034 (0.0034)\tPrec 100.000% (100.000%)\n",
      "Epoch: [97][100/391]\tTime 0.055 (0.057)\tData 0.001 (0.004)\tLoss 0.0098 (0.0145)\tPrec 99.219% (99.513%)\n",
      "Epoch: [97][200/391]\tTime 0.060 (0.057)\tData 0.001 (0.003)\tLoss 0.0065 (0.0149)\tPrec 100.000% (99.479%)\n",
      "Epoch: [97][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.0180 (0.0153)\tPrec 100.000% (99.489%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.224 (0.224)\tLoss 0.2169 (0.2169)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.340% \n",
      "best acc: 91.410000\n",
      "Epoch: [98][0/391]\tTime 0.274 (0.274)\tData 0.233 (0.233)\tLoss 0.0144 (0.0144)\tPrec 100.000% (100.000%)\n",
      "Epoch: [98][100/391]\tTime 0.055 (0.059)\tData 0.001 (0.004)\tLoss 0.0020 (0.0144)\tPrec 100.000% (99.575%)\n",
      "Epoch: [98][200/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.0238 (0.0154)\tPrec 98.438% (99.514%)\n",
      "Epoch: [98][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.002)\tLoss 0.0104 (0.0151)\tPrec 100.000% (99.512%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.233 (0.233)\tLoss 0.2104 (0.2104)\tPrec 95.312% (95.312%)\n",
      " * Prec 91.410% \n",
      "best acc: 91.410000\n",
      "Epoch: [99][0/391]\tTime 0.261 (0.261)\tData 0.218 (0.218)\tLoss 0.0469 (0.0469)\tPrec 98.438% (98.438%)\n",
      "Epoch: [99][100/391]\tTime 0.054 (0.057)\tData 0.001 (0.004)\tLoss 0.0216 (0.0139)\tPrec 99.219% (99.544%)\n",
      "Epoch: [99][200/391]\tTime 0.052 (0.056)\tData 0.002 (0.003)\tLoss 0.0088 (0.0151)\tPrec 100.000% (99.499%)\n",
      "Epoch: [99][300/391]\tTime 0.058 (0.056)\tData 0.001 (0.002)\tLoss 0.0170 (0.0153)\tPrec 100.000% (99.517%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.1903 (0.1903)\tPrec 96.094% (96.094%)\n",
      " * Prec 91.570% \n",
      "best acc: 91.570000\n"
     ]
    }
   ],
   "source": [
    "lr = 4e-2\n",
    "weight_decay = 1e-4\n",
    "epochs = 100\n",
    "best_prec = 0\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9,weight_decay=weight_decay)\n",
    "\n",
    "if not os.path.exists('result'): \n",
    "    os.makedirs('result')\n",
    "\n",
    "fdir = 'result/'+str(model_name) \n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "\n",
    "adjust_list = [80,90]\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch,adjust_list)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dae27d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9157/10000 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/VGG16_quant_project/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f19f5cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 -th layer prehooked\n",
      "7 -th layer prehooked\n",
      "12 -th layer prehooked\n",
      "16 -th layer prehooked\n",
      "21 -th layer prehooked\n",
      "25 -th layer prehooked\n",
      "29 -th layer prehooked\n",
      "34 -th layer prehooked\n",
      "38 -th layer prehooked\n",
      "41 -th layer prehooked\n",
      "46 -th layer prehooked\n",
      "50 -th layer prehooked\n",
      "54 -th layer prehooked\n"
     ]
    }
   ],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "i = 0\n",
    "\n",
    "for layer in model.modules():\n",
    "    i = i+1\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        print(i,\"-th layer prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)             \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.to(device)\n",
    "out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "16c459db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.8603e-09, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "w_bit = 4\n",
    "weight_q = model.features[27].weight_q\n",
    "w_alpha = model.features[27].weight_quant.wgt_alpha\n",
    "w_delta = w_alpha/(2**(w_bit-1)-1)\n",
    "weight_int = weight_q/w_delta\n",
    "\n",
    "x_bit = 4\n",
    "x = save_output.outputs[8][0]\n",
    "x_alpha = model.features[27].act_alpha\n",
    "x_delta = x_alpha/(2**x_bit-1)\n",
    "act_quant = act_quantization(x_bit)\n",
    "x_q = act_quant(x,x_alpha)\n",
    "x_int = x_q/x_delta\n",
    "\n",
    "conv_int = nn.Conv2d(8,8,kernel_size=3, padding=1, bias=False)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "output_int = conv_int(x_int)\n",
    "psum_recovered = output_int*w_delta*x_delta\n",
    "relu = nn.ReLU(inplace=True)\n",
    "psum_after_relu = relu(psum_recovered)\n",
    "\n",
    "difference = (save_output.outputs[9][0] - psum_after_relu).mean()\n",
    "\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1cb5e71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = 1\n",
    "stride = 1\n",
    "array_size = 8\n",
    "x_size = x_int.size()\n",
    "nig = range(x_size[2])\n",
    "njg = range(x_size[3])\n",
    "\n",
    "kijg = range(w_int.size(2))\n",
    "ki_dim = int(math.sqrt(w_int.size(2)))  ## Kernel's 1 dim size\n",
    "\n",
    "icg = range(int(w_int.size(1)))  ## input channel \n",
    "ocg = range(int(w_int.size(0)))  ## output channel\n",
    "\n",
    "a_pad = torch.zeros((x_size[1],x_size[2]+2*padding,x_size[3]+2*padding))\n",
    "act_int = x_int[0,:,:,:]\n",
    "a_pad[ :, padding:padding+len(nig), padding:padding+len(njg)] = act_int.cuda()\n",
    "a_pad = torch.reshape(a_pad, (a_pad.size(0), -1))\n",
    "w_int = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))\n",
    "\n",
    "ic_tile = range(int(int(act_int.size(0))/array_size))\n",
    "oc_tile = range(int(int(w_int.size(0))/array_size))\n",
    "\n",
    "\n",
    "a_tile = torch.zeros(len(ic_tile),array_size,len(nig)+padding*2,len(njg)+padding*2).cuda()\n",
    "a_tile = torch.reshape(a_tile,(a_tile.size(0),a_tile.size(1),-1))\n",
    "\n",
    "for ict in ic_tile:\n",
    "    a_tile[ict,:,:] = a_pad[(ict*array_size):((ict+1)*array_size),:]\n",
    "\n",
    "w_tile = torch.zeros(len(ic_tile),len(oc_tile),array_size,array_size,len(kijg)).cuda()\n",
    "\n",
    "\n",
    "\n",
    "for oct in oc_tile:\n",
    "    for ict in ic_tile:\n",
    "        w_tile[ict,oct,:,:,:] = w_int[(oct*array_size):((oct+1)*array_size),(ict*array_size):((ict+1)*array_size),:]\n",
    "\n",
    "        \n",
    "        \n",
    "p_nijg = range(a_pad.size(1)) ## paded activation's nij group\n",
    "\n",
    "psum = torch.zeros(len(ic_tile),len(oc_tile),array_size,len(p_nijg),len(kijg)).cuda() \n",
    "\n",
    "for kij in kijg:\n",
    "    for ict in ic_tile:\n",
    "        for oct in oc_tile:\n",
    "            for nij in p_nijg:     # time domain, sequentially given input\n",
    "                m = nn.Linear(array_size, array_size, bias=False)\n",
    "                m.weight = torch.nn.Parameter(w_tile[ict,oct,:,:,kij])\n",
    "                psum[ict,oct,:, nij, kij] = m(a_tile[ict,:,nij]).cuda()\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1fd9742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "a_pad_ni_dim = int(math.sqrt(a_pad.size(1))) # 32 + 2*pad = 34\n",
    "\n",
    "o_ni_dim = int((a_pad_ni_dim - (ki_dim- 1) - 1)/stride + 1) #34 - 2 - 1 + 1 = 32\n",
    "o_nijg = range(o_ni_dim**2)    \n",
    "    \n",
    "out = torch.zeros(len(ocg), len(o_nijg)).cuda()\n",
    "  \n",
    "   \n",
    "### SFP accumulation ###\n",
    "for o_nij in o_nijg: \n",
    "    for kij in kijg:  \n",
    "        for ict in ic_tile:\n",
    "            for oct in oc_tile:\n",
    "                out[oct*array_size:(oct+1)*array_size,o_nij] = out[oct*array_size:(oct+1)*array_size,o_nij] + \\\n",
    "                psum[ict,oct,:, int(o_nij/o_ni_dim)*a_pad_ni_dim + o_nij%o_ni_dim + int(kij/ki_dim)*a_pad_ni_dim + kij%ki_dim, kij]\n",
    "                ## 2nd index = (int(o_nij/30)*32 + o_nij%30) + (int(kij/3)*32 + kij%3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "229fd452",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions to dump files\n",
    "def dec_to_bin(arr,bit):\n",
    "    bin_arr = []\n",
    "    for a in arr:\n",
    "        a = int(a)\n",
    "        if a < 0:\n",
    "            a+=bit\n",
    "        b = '{0:04b}'.format(int(a))\n",
    "        bin_arr.append(b)\n",
    "    return bin_arr\n",
    "\n",
    "def dec_to_bin_psum(arr,bit):\n",
    "    bin_arr = []\n",
    "    for a in arr:\n",
    "        a = int(a)\n",
    "        sign = 0\n",
    "        if a < 0:\n",
    "            sign = 1\n",
    "            a+=bit\n",
    "        b = '{0:16b}'.format(int(a))\n",
    "        if sign == 1:\n",
    "            b = b.replace(\" \", \"1\")\n",
    "        else:\n",
    "            b = b.replace(\" \",\"0\")\n",
    "        bin_arr.append(b)\n",
    "    return bin_arr\n",
    "\n",
    "\n",
    "def convert_to_list(arr):\n",
    "    return arr.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9cc17518",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Activation dump\n",
    "\n",
    "fp_act = open('activation_project.txt','w')\n",
    "fp_act.write(\"#####\\n\")\n",
    "fp_act.write(\"#####\\n\")\n",
    "fp_act.write(\"#####\\n\")\n",
    "fp_act_dec = open('activation_dec.txt','w')\n",
    "for i in range(36):\n",
    "    act_line = a_pad[:,i]\n",
    "    act_arr = [int(j+0.001) for j in convert_to_list(act_line)]\n",
    "    for a in act_arr[::-1]:\n",
    "        #print(int(a))\n",
    "        fp_act_dec.write(str(int(a)))\n",
    "        fp_act_dec.write(\" \")\n",
    "    fp_act_dec.write(\"\\n\")\n",
    "    bin_act = dec_to_bin(act_arr,16)\n",
    "    for b in bin_act[::-1]:\n",
    "        #print(b)\n",
    "        fp_act.write(b)\n",
    "    fp_act.write('\\n')\n",
    "    \n",
    "\n",
    "fp_act.close()\n",
    "fp_act_dec.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "97153924",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weight dump\n",
    "fp_wgt = open('weight_project.txt','w')\n",
    "fp_wgt.write(\"#####\\n\")\n",
    "fp_wgt.write(\"#####\\n\")\n",
    "fp_wgt.write(\"#####\\n\")\n",
    "fp_wgt_dec = open('weight_dec.txt','w')\n",
    "\n",
    "for kij in range(9):\n",
    "    for w in range(8):\n",
    "        w_line = w_int[w,:,kij]\n",
    "        w_arr = []\n",
    "        for i in convert_to_list(w_line):\n",
    "            if i < 0:\n",
    "                w_arr.append(int(i-0.001))\n",
    "            else:\n",
    "                w_arr.append(int(i+0.001))\n",
    "        \n",
    "        for ww in w_arr[::-1]:\n",
    "            #print(int(ww))\n",
    "            fp_wgt_dec.write(str(int(ww)))\n",
    "            fp_wgt_dec.write(\" \")\n",
    "        fp_wgt_dec.write(\"\\n\")\n",
    "        bin_wgt = dec_to_bin(w_arr,16)\n",
    "        for b in bin_wgt[::-1]:\n",
    "            #print(\"Count = {} , b = {}\".format(count,b))\n",
    "            fp_wgt.write(b)\n",
    "        fp_wgt.write('\\n')\n",
    "\n",
    "fp_wgt.close()\n",
    "fp_wgt_dec.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "51d0360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## psum dump\n",
    "fp_psum = open('psum_project.txt','w')\n",
    "fp_psum.write(\"#####\\n\")\n",
    "fp_psum.write(\"#####\\n\")\n",
    "fp_psum.write(\"#####\\n\")\n",
    "fp_psum_dec = open('psum_dec.txt','w')\n",
    "fp_psum_relu = open('output_project.txt','w')\n",
    "for kij in range(16):\n",
    "    psum_line = out[:,kij]\n",
    "    psum_arr = []\n",
    "    out_arr = []\n",
    "    for i in convert_to_list(psum_line):\n",
    "        if i < 0:\n",
    "            psum_arr.append(int(i-0.001))\n",
    "            out_arr.append(0)\n",
    "        else:\n",
    "            psum_arr.append(int(i+0.001))\n",
    "            out_arr.append(int(i+0.001))\n",
    "    for p in psum_arr:\n",
    "        #print(int(a))\n",
    "        fp_psum_dec.write(str(int(p)))\n",
    "        fp_psum_dec.write(\" \")\n",
    "    fp_psum_dec.write(\"\\n\")\n",
    "    bin_act = dec_to_bin_psum(psum_arr,65536)\n",
    "    out_bin_act = dec_to_bin_psum(out_arr,65536)\n",
    "    for b in bin_act:\n",
    "        #print(b)\n",
    "        fp_psum.write(b)\n",
    "        fp_psum.write(' ')\n",
    "    fp_psum.write('\\n')\n",
    "    fp_psum_relu.write(\"#\")\n",
    "    fp_psum_relu.write(\"#\")\n",
    "    \n",
    "    for b in out_bin_act:\n",
    "        fp_psum_relu.write(b)\n",
    "        fp_psum_relu.write(' ')\n",
    "    fp_psum_relu.write(\"\\n\")\n",
    "fp_psum.close()\n",
    "fp_psum_dec.close()\n",
    "fp_psum_relu.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
