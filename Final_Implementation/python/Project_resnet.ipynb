{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9a6dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "     \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\")\n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"Resnet_20_quant_project\"\n",
    "model = resnet20_quant_project()\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a6f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_freq = 100\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch,adjust_list):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    \n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f40ee4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 0.723 (0.723)\tData 0.588 (0.588)\tLoss 2.4852 (2.4852)\tPrec 7.031% (7.031%)\n",
      "Epoch: [0][100/391]\tTime 0.055 (0.056)\tData 0.002 (0.008)\tLoss 1.8671 (2.0559)\tPrec 30.469% (21.047%)\n",
      "Epoch: [0][200/391]\tTime 0.051 (0.055)\tData 0.002 (0.005)\tLoss 1.7032 (1.9121)\tPrec 39.062% (27.247%)\n",
      "Epoch: [0][300/391]\tTime 0.051 (0.052)\tData 0.002 (0.004)\tLoss 1.4083 (1.8174)\tPrec 46.875% (31.341%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.354 (0.354)\tLoss 1.5558 (1.5558)\tPrec 42.188% (42.188%)\n",
      " * Prec 41.410% \n",
      "best acc: 41.410000\n",
      "Epoch: [1][0/391]\tTime 0.428 (0.428)\tData 0.362 (0.362)\tLoss 1.4099 (1.4099)\tPrec 43.750% (43.750%)\n",
      "Epoch: [1][100/391]\tTime 0.048 (0.052)\tData 0.002 (0.006)\tLoss 1.3916 (1.4359)\tPrec 50.000% (47.223%)\n",
      "Epoch: [1][200/391]\tTime 0.040 (0.051)\tData 0.001 (0.004)\tLoss 1.4276 (1.3768)\tPrec 46.094% (49.938%)\n",
      "Epoch: [1][300/391]\tTime 0.050 (0.049)\tData 0.002 (0.003)\tLoss 1.1543 (1.3324)\tPrec 60.156% (51.744%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.426 (0.426)\tLoss 1.3888 (1.3888)\tPrec 53.125% (53.125%)\n",
      " * Prec 52.660% \n",
      "best acc: 52.660000\n",
      "Epoch: [2][0/391]\tTime 0.756 (0.756)\tData 0.692 (0.692)\tLoss 1.1296 (1.1296)\tPrec 58.594% (58.594%)\n",
      "Epoch: [2][100/391]\tTime 0.057 (0.060)\tData 0.003 (0.009)\tLoss 1.2002 (1.1215)\tPrec 61.719% (60.288%)\n",
      "Epoch: [2][200/391]\tTime 0.050 (0.056)\tData 0.003 (0.006)\tLoss 0.9285 (1.0979)\tPrec 66.406% (61.050%)\n",
      "Epoch: [2][300/391]\tTime 0.043 (0.054)\tData 0.002 (0.005)\tLoss 0.8716 (1.0763)\tPrec 66.406% (61.768%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.409 (0.409)\tLoss 1.1291 (1.1291)\tPrec 60.938% (60.938%)\n",
      " * Prec 60.810% \n",
      "best acc: 60.810000\n",
      "Epoch: [3][0/391]\tTime 0.659 (0.659)\tData 0.595 (0.595)\tLoss 1.0072 (1.0072)\tPrec 65.625% (65.625%)\n",
      "Epoch: [3][100/391]\tTime 0.050 (0.059)\tData 0.002 (0.008)\tLoss 1.0853 (0.9882)\tPrec 60.156% (65.347%)\n",
      "Epoch: [3][200/391]\tTime 0.055 (0.057)\tData 0.003 (0.005)\tLoss 0.9933 (0.9642)\tPrec 67.188% (65.920%)\n",
      "Epoch: [3][300/391]\tTime 0.053 (0.055)\tData 0.002 (0.004)\tLoss 0.8162 (0.9502)\tPrec 72.656% (66.562%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.873 (0.873)\tLoss 0.7776 (0.7776)\tPrec 73.438% (73.438%)\n",
      " * Prec 69.230% \n",
      "best acc: 69.230000\n",
      "Epoch: [4][0/391]\tTime 0.595 (0.595)\tData 0.531 (0.531)\tLoss 0.8532 (0.8532)\tPrec 63.281% (63.281%)\n",
      "Epoch: [4][100/391]\tTime 0.055 (0.057)\tData 0.003 (0.008)\tLoss 0.8541 (0.8590)\tPrec 66.406% (69.531%)\n",
      "Epoch: [4][200/391]\tTime 0.046 (0.054)\tData 0.002 (0.005)\tLoss 0.7850 (0.8652)\tPrec 69.531% (69.551%)\n",
      "Epoch: [4][300/391]\tTime 0.048 (0.054)\tData 0.001 (0.004)\tLoss 0.9558 (0.8609)\tPrec 66.406% (69.640%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.465 (0.465)\tLoss 0.7475 (0.7475)\tPrec 71.875% (71.875%)\n",
      " * Prec 70.440% \n",
      "best acc: 70.440000\n",
      "Epoch: [5][0/391]\tTime 0.513 (0.513)\tData 0.448 (0.448)\tLoss 0.5259 (0.5259)\tPrec 84.375% (84.375%)\n",
      "Epoch: [5][100/391]\tTime 0.056 (0.057)\tData 0.002 (0.007)\tLoss 0.6973 (0.8027)\tPrec 78.125% (71.937%)\n",
      "Epoch: [5][200/391]\tTime 0.046 (0.053)\tData 0.002 (0.004)\tLoss 0.8067 (0.8005)\tPrec 71.875% (71.801%)\n",
      "Epoch: [5][300/391]\tTime 0.049 (0.053)\tData 0.002 (0.004)\tLoss 0.6789 (0.7961)\tPrec 78.125% (72.098%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.529 (0.529)\tLoss 0.8746 (0.8746)\tPrec 70.312% (70.312%)\n",
      " * Prec 66.890% \n",
      "best acc: 70.440000\n",
      "Epoch: [6][0/391]\tTime 0.467 (0.467)\tData 0.401 (0.401)\tLoss 0.7818 (0.7818)\tPrec 74.219% (74.219%)\n",
      "Epoch: [6][100/391]\tTime 0.056 (0.061)\tData 0.002 (0.006)\tLoss 0.7240 (0.7521)\tPrec 74.219% (73.693%)\n",
      "Epoch: [6][200/391]\tTime 0.048 (0.057)\tData 0.002 (0.004)\tLoss 0.6805 (0.7511)\tPrec 74.219% (73.640%)\n",
      "Epoch: [6][300/391]\tTime 0.052 (0.055)\tData 0.002 (0.004)\tLoss 0.7250 (0.7553)\tPrec 69.531% (73.544%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.440 (0.440)\tLoss 0.8272 (0.8272)\tPrec 73.438% (73.438%)\n",
      " * Prec 69.660% \n",
      "best acc: 70.440000\n",
      "Epoch: [7][0/391]\tTime 0.585 (0.585)\tData 0.520 (0.520)\tLoss 0.6912 (0.6912)\tPrec 75.000% (75.000%)\n",
      "Epoch: [7][100/391]\tTime 0.058 (0.060)\tData 0.002 (0.007)\tLoss 0.7684 (0.7198)\tPrec 75.000% (75.217%)\n",
      "Epoch: [7][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.005)\tLoss 0.6532 (0.7276)\tPrec 75.781% (74.953%)\n",
      "Epoch: [7][300/391]\tTime 0.055 (0.056)\tData 0.003 (0.004)\tLoss 0.6186 (0.7290)\tPrec 82.031% (74.777%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.667 (0.667)\tLoss 0.8228 (0.8228)\tPrec 71.875% (71.875%)\n",
      " * Prec 71.500% \n",
      "best acc: 71.500000\n",
      "Epoch: [8][0/391]\tTime 0.534 (0.534)\tData 0.469 (0.469)\tLoss 0.6864 (0.6864)\tPrec 77.344% (77.344%)\n",
      "Epoch: [8][100/391]\tTime 0.053 (0.057)\tData 0.002 (0.007)\tLoss 0.6234 (0.6682)\tPrec 76.562% (76.439%)\n",
      "Epoch: [8][200/391]\tTime 0.051 (0.055)\tData 0.002 (0.005)\tLoss 0.5489 (0.6639)\tPrec 80.469% (76.905%)\n",
      "Epoch: [8][300/391]\tTime 0.053 (0.055)\tData 0.002 (0.004)\tLoss 0.6218 (0.6733)\tPrec 76.562% (76.575%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.389 (0.389)\tLoss 1.0358 (1.0358)\tPrec 65.625% (65.625%)\n",
      " * Prec 66.550% \n",
      "best acc: 71.500000\n",
      "Epoch: [9][0/391]\tTime 0.606 (0.606)\tData 0.544 (0.544)\tLoss 0.5445 (0.5445)\tPrec 81.250% (81.250%)\n",
      "Epoch: [9][100/391]\tTime 0.050 (0.055)\tData 0.002 (0.008)\tLoss 0.5818 (0.6570)\tPrec 80.469% (76.733%)\n",
      "Epoch: [9][200/391]\tTime 0.047 (0.052)\tData 0.002 (0.005)\tLoss 0.7932 (0.6664)\tPrec 71.094% (76.481%)\n",
      "Epoch: [9][300/391]\tTime 0.048 (0.051)\tData 0.002 (0.004)\tLoss 0.6268 (0.6646)\tPrec 78.125% (76.692%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.526 (0.526)\tLoss 0.7717 (0.7717)\tPrec 73.438% (73.438%)\n",
      " * Prec 72.790% \n",
      "best acc: 72.790000\n",
      "Epoch: [10][0/391]\tTime 0.523 (0.523)\tData 0.458 (0.458)\tLoss 0.6118 (0.6118)\tPrec 78.906% (78.906%)\n",
      "Epoch: [10][100/391]\tTime 0.052 (0.054)\tData 0.002 (0.007)\tLoss 0.6333 (0.6346)\tPrec 79.688% (77.916%)\n",
      "Epoch: [10][200/391]\tTime 0.053 (0.054)\tData 0.003 (0.005)\tLoss 0.7144 (0.6350)\tPrec 76.562% (78.012%)\n",
      "Epoch: [10][300/391]\tTime 0.059 (0.054)\tData 0.002 (0.004)\tLoss 0.6236 (0.6385)\tPrec 77.344% (77.876%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.304 (1.304)\tLoss 0.9510 (0.9510)\tPrec 68.750% (68.750%)\n",
      " * Prec 67.620% \n",
      "best acc: 72.790000\n",
      "Epoch: [11][0/391]\tTime 0.451 (0.451)\tData 0.389 (0.389)\tLoss 0.6256 (0.6256)\tPrec 76.562% (76.562%)\n",
      "Epoch: [11][100/391]\tTime 0.063 (0.056)\tData 0.003 (0.006)\tLoss 0.6800 (0.6013)\tPrec 74.219% (78.991%)\n",
      "Epoch: [11][200/391]\tTime 0.051 (0.055)\tData 0.002 (0.004)\tLoss 0.6946 (0.6140)\tPrec 75.781% (78.751%)\n",
      "Epoch: [11][300/391]\tTime 0.059 (0.054)\tData 0.003 (0.004)\tLoss 0.5900 (0.6118)\tPrec 82.031% (78.761%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.638 (0.638)\tLoss 0.7047 (0.7047)\tPrec 74.219% (74.219%)\n",
      " * Prec 72.720% \n",
      "best acc: 72.790000\n",
      "Epoch: [12][0/391]\tTime 0.558 (0.558)\tData 0.463 (0.463)\tLoss 0.4608 (0.4608)\tPrec 84.375% (84.375%)\n",
      "Epoch: [12][100/391]\tTime 0.050 (0.059)\tData 0.002 (0.007)\tLoss 0.4683 (0.5877)\tPrec 80.469% (79.394%)\n",
      "Epoch: [12][200/391]\tTime 0.056 (0.056)\tData 0.002 (0.005)\tLoss 0.4336 (0.5840)\tPrec 85.938% (79.660%)\n",
      "Epoch: [12][300/391]\tTime 0.059 (0.054)\tData 0.002 (0.004)\tLoss 0.7537 (0.5889)\tPrec 78.906% (79.472%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.441 (0.441)\tLoss 0.6678 (0.6678)\tPrec 78.906% (78.906%)\n",
      " * Prec 77.110% \n",
      "best acc: 77.110000\n",
      "Epoch: [13][0/391]\tTime 0.573 (0.573)\tData 0.508 (0.508)\tLoss 0.6092 (0.6092)\tPrec 78.906% (78.906%)\n",
      "Epoch: [13][100/391]\tTime 0.049 (0.057)\tData 0.002 (0.007)\tLoss 0.6873 (0.5749)\tPrec 78.125% (80.067%)\n",
      "Epoch: [13][200/391]\tTime 0.055 (0.055)\tData 0.002 (0.005)\tLoss 0.6250 (0.5819)\tPrec 78.125% (79.796%)\n",
      "Epoch: [13][300/391]\tTime 0.057 (0.054)\tData 0.002 (0.004)\tLoss 0.4878 (0.5842)\tPrec 82.812% (79.698%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.359 (0.359)\tLoss 0.7049 (0.7049)\tPrec 78.906% (78.906%)\n",
      " * Prec 75.850% \n",
      "best acc: 77.110000\n",
      "Epoch: [14][0/391]\tTime 0.821 (0.821)\tData 0.756 (0.756)\tLoss 0.6366 (0.6366)\tPrec 78.906% (78.906%)\n",
      "Epoch: [14][100/391]\tTime 0.056 (0.061)\tData 0.003 (0.010)\tLoss 0.5679 (0.5564)\tPrec 78.125% (80.678%)\n",
      "Epoch: [14][200/391]\tTime 0.045 (0.055)\tData 0.002 (0.006)\tLoss 0.5897 (0.5631)\tPrec 74.219% (80.492%)\n",
      "Epoch: [14][300/391]\tTime 0.057 (0.053)\tData 0.003 (0.005)\tLoss 0.4574 (0.5612)\tPrec 85.156% (80.565%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.510 (0.510)\tLoss 0.5636 (0.5636)\tPrec 80.469% (80.469%)\n",
      " * Prec 77.640% \n",
      "best acc: 77.640000\n",
      "Epoch: [15][0/391]\tTime 0.494 (0.494)\tData 0.431 (0.431)\tLoss 0.6154 (0.6154)\tPrec 76.562% (76.562%)\n",
      "Epoch: [15][100/391]\tTime 0.051 (0.058)\tData 0.002 (0.007)\tLoss 0.6685 (0.5574)\tPrec 77.344% (80.492%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][200/391]\tTime 0.054 (0.056)\tData 0.002 (0.004)\tLoss 0.5135 (0.5601)\tPrec 83.594% (80.496%)\n",
      "Epoch: [15][300/391]\tTime 0.062 (0.053)\tData 0.002 (0.004)\tLoss 0.4505 (0.5562)\tPrec 82.812% (80.721%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.483 (0.483)\tLoss 0.6223 (0.6223)\tPrec 80.469% (80.469%)\n",
      " * Prec 78.700% \n",
      "best acc: 78.700000\n",
      "Epoch: [16][0/391]\tTime 0.455 (0.455)\tData 0.393 (0.393)\tLoss 0.5377 (0.5377)\tPrec 84.375% (84.375%)\n",
      "Epoch: [16][100/391]\tTime 0.039 (0.049)\tData 0.001 (0.006)\tLoss 0.4802 (0.5335)\tPrec 83.594% (81.706%)\n",
      "Epoch: [16][200/391]\tTime 0.051 (0.049)\tData 0.002 (0.004)\tLoss 0.4999 (0.5435)\tPrec 80.469% (81.285%)\n",
      "Epoch: [16][300/391]\tTime 0.051 (0.049)\tData 0.002 (0.003)\tLoss 0.4867 (0.5454)\tPrec 78.125% (81.206%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.281 (0.281)\tLoss 0.5143 (0.5143)\tPrec 82.812% (82.812%)\n",
      " * Prec 78.900% \n",
      "best acc: 78.900000\n",
      "Epoch: [17][0/391]\tTime 0.479 (0.479)\tData 0.390 (0.390)\tLoss 0.6850 (0.6850)\tPrec 77.344% (77.344%)\n",
      "Epoch: [17][100/391]\tTime 0.041 (0.052)\tData 0.002 (0.006)\tLoss 0.5936 (0.5437)\tPrec 75.000% (81.273%)\n",
      "Epoch: [17][200/391]\tTime 0.043 (0.050)\tData 0.002 (0.004)\tLoss 0.4822 (0.5315)\tPrec 83.594% (81.522%)\n",
      "Epoch: [17][300/391]\tTime 0.051 (0.049)\tData 0.002 (0.003)\tLoss 0.4882 (0.5284)\tPrec 87.500% (81.717%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.368 (0.368)\tLoss 0.6041 (0.6041)\tPrec 79.688% (79.688%)\n",
      " * Prec 78.790% \n",
      "best acc: 78.900000\n",
      "Epoch: [18][0/391]\tTime 0.438 (0.438)\tData 0.370 (0.370)\tLoss 0.5500 (0.5500)\tPrec 78.906% (78.906%)\n",
      "Epoch: [18][100/391]\tTime 0.035 (0.048)\tData 0.002 (0.006)\tLoss 0.5410 (0.5185)\tPrec 79.688% (81.877%)\n",
      "Epoch: [18][200/391]\tTime 0.039 (0.046)\tData 0.001 (0.004)\tLoss 0.5384 (0.5094)\tPrec 80.469% (82.210%)\n",
      "Epoch: [18][300/391]\tTime 0.051 (0.047)\tData 0.002 (0.003)\tLoss 0.3522 (0.5106)\tPrec 85.938% (82.257%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.402 (0.402)\tLoss 0.4263 (0.4263)\tPrec 85.156% (85.156%)\n",
      " * Prec 80.920% \n",
      "best acc: 80.920000\n",
      "Epoch: [19][0/391]\tTime 0.564 (0.564)\tData 0.507 (0.507)\tLoss 0.5488 (0.5488)\tPrec 77.344% (77.344%)\n",
      "Epoch: [19][100/391]\tTime 0.064 (0.052)\tData 0.003 (0.007)\tLoss 0.4193 (0.5000)\tPrec 86.719% (82.851%)\n",
      "Epoch: [19][200/391]\tTime 0.057 (0.048)\tData 0.003 (0.004)\tLoss 0.7118 (0.4995)\tPrec 75.000% (82.618%)\n",
      "Epoch: [19][300/391]\tTime 0.041 (0.048)\tData 0.001 (0.004)\tLoss 0.5429 (0.4973)\tPrec 80.469% (82.688%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.635 (0.635)\tLoss 0.5854 (0.5854)\tPrec 81.250% (81.250%)\n",
      " * Prec 78.310% \n",
      "best acc: 80.920000\n",
      "Epoch: [20][0/391]\tTime 0.625 (0.625)\tData 0.565 (0.565)\tLoss 0.5191 (0.5191)\tPrec 83.594% (83.594%)\n",
      "Epoch: [20][100/391]\tTime 0.044 (0.053)\tData 0.001 (0.008)\tLoss 0.3865 (0.4913)\tPrec 87.500% (82.758%)\n",
      "Epoch: [20][200/391]\tTime 0.051 (0.051)\tData 0.002 (0.005)\tLoss 0.5962 (0.4881)\tPrec 79.688% (82.937%)\n",
      "Epoch: [20][300/391]\tTime 0.048 (0.050)\tData 0.003 (0.004)\tLoss 0.6095 (0.4866)\tPrec 77.344% (82.981%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.271 (0.271)\tLoss 0.5186 (0.5186)\tPrec 79.688% (79.688%)\n",
      " * Prec 81.200% \n",
      "best acc: 81.200000\n",
      "Epoch: [21][0/391]\tTime 0.586 (0.586)\tData 0.526 (0.526)\tLoss 0.3842 (0.3842)\tPrec 87.500% (87.500%)\n",
      "Epoch: [21][100/391]\tTime 0.052 (0.058)\tData 0.002 (0.008)\tLoss 0.5291 (0.4863)\tPrec 83.594% (83.284%)\n",
      "Epoch: [21][200/391]\tTime 0.051 (0.053)\tData 0.002 (0.005)\tLoss 0.4660 (0.4776)\tPrec 83.594% (83.664%)\n",
      "Epoch: [21][300/391]\tTime 0.053 (0.053)\tData 0.002 (0.004)\tLoss 0.4639 (0.4778)\tPrec 85.156% (83.524%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.502 (0.502)\tLoss 0.6461 (0.6461)\tPrec 78.125% (78.125%)\n",
      " * Prec 77.080% \n",
      "best acc: 81.200000\n",
      "Epoch: [22][0/391]\tTime 0.501 (0.501)\tData 0.440 (0.440)\tLoss 0.4528 (0.4528)\tPrec 85.938% (85.938%)\n",
      "Epoch: [22][100/391]\tTime 0.044 (0.054)\tData 0.002 (0.007)\tLoss 0.2880 (0.4575)\tPrec 93.750% (84.135%)\n",
      "Epoch: [22][200/391]\tTime 0.055 (0.052)\tData 0.003 (0.004)\tLoss 0.4604 (0.4609)\tPrec 85.156% (84.033%)\n",
      "Epoch: [22][300/391]\tTime 0.049 (0.051)\tData 0.002 (0.004)\tLoss 0.5867 (0.4741)\tPrec 78.906% (83.599%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.448 (0.448)\tLoss 0.4444 (0.4444)\tPrec 84.375% (84.375%)\n",
      " * Prec 80.510% \n",
      "best acc: 81.200000\n",
      "Epoch: [23][0/391]\tTime 0.663 (0.663)\tData 0.598 (0.598)\tLoss 0.4956 (0.4956)\tPrec 84.375% (84.375%)\n",
      "Epoch: [23][100/391]\tTime 0.044 (0.053)\tData 0.002 (0.008)\tLoss 0.4670 (0.4576)\tPrec 85.938% (84.073%)\n",
      "Epoch: [23][200/391]\tTime 0.039 (0.048)\tData 0.002 (0.005)\tLoss 0.5568 (0.4650)\tPrec 80.469% (83.975%)\n",
      "Epoch: [23][300/391]\tTime 0.036 (0.046)\tData 0.002 (0.004)\tLoss 0.4672 (0.4690)\tPrec 82.031% (83.786%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.292 (0.292)\tLoss 0.6100 (0.6100)\tPrec 77.344% (77.344%)\n",
      " * Prec 76.010% \n",
      "best acc: 81.200000\n",
      "Epoch: [24][0/391]\tTime 0.424 (0.424)\tData 0.363 (0.363)\tLoss 0.4234 (0.4234)\tPrec 86.719% (86.719%)\n",
      "Epoch: [24][100/391]\tTime 0.042 (0.046)\tData 0.002 (0.005)\tLoss 0.5697 (0.4535)\tPrec 79.688% (83.934%)\n",
      "Epoch: [24][200/391]\tTime 0.046 (0.044)\tData 0.002 (0.004)\tLoss 0.4184 (0.4535)\tPrec 85.938% (84.049%)\n",
      "Epoch: [24][300/391]\tTime 0.053 (0.043)\tData 0.002 (0.003)\tLoss 0.3722 (0.4617)\tPrec 85.938% (83.807%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.403 (0.403)\tLoss 0.6277 (0.6277)\tPrec 78.906% (78.906%)\n",
      " * Prec 78.560% \n",
      "best acc: 81.200000\n",
      "Epoch: [25][0/391]\tTime 0.452 (0.452)\tData 0.390 (0.390)\tLoss 0.4773 (0.4773)\tPrec 82.031% (82.031%)\n",
      "Epoch: [25][100/391]\tTime 0.048 (0.046)\tData 0.002 (0.006)\tLoss 0.4087 (0.4403)\tPrec 85.938% (84.669%)\n",
      "Epoch: [25][200/391]\tTime 0.046 (0.049)\tData 0.002 (0.004)\tLoss 0.6309 (0.4520)\tPrec 78.125% (84.301%)\n",
      "Epoch: [25][300/391]\tTime 0.039 (0.047)\tData 0.002 (0.003)\tLoss 0.4316 (0.4551)\tPrec 87.500% (84.230%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.426 (0.426)\tLoss 0.5048 (0.5048)\tPrec 78.906% (78.906%)\n",
      " * Prec 80.550% \n",
      "best acc: 81.200000\n",
      "Epoch: [26][0/391]\tTime 0.479 (0.479)\tData 0.392 (0.392)\tLoss 0.5335 (0.5335)\tPrec 82.031% (82.031%)\n",
      "Epoch: [26][100/391]\tTime 0.058 (0.055)\tData 0.002 (0.006)\tLoss 0.3149 (0.4361)\tPrec 87.500% (84.916%)\n",
      "Epoch: [26][200/391]\tTime 0.057 (0.054)\tData 0.002 (0.004)\tLoss 0.4211 (0.4416)\tPrec 83.594% (84.748%)\n",
      "Epoch: [26][300/391]\tTime 0.059 (0.054)\tData 0.002 (0.004)\tLoss 0.3963 (0.4464)\tPrec 88.281% (84.611%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.630 (0.630)\tLoss 0.4889 (0.4889)\tPrec 82.812% (82.812%)\n",
      " * Prec 80.560% \n",
      "best acc: 81.200000\n",
      "Epoch: [27][0/391]\tTime 0.608 (0.608)\tData 0.542 (0.542)\tLoss 0.4655 (0.4655)\tPrec 82.031% (82.031%)\n",
      "Epoch: [27][100/391]\tTime 0.059 (0.059)\tData 0.003 (0.008)\tLoss 0.3607 (0.4290)\tPrec 86.719% (84.940%)\n",
      "Epoch: [27][200/391]\tTime 0.055 (0.056)\tData 0.003 (0.005)\tLoss 0.3756 (0.4351)\tPrec 85.938% (84.768%)\n",
      "Epoch: [27][300/391]\tTime 0.055 (0.055)\tData 0.003 (0.004)\tLoss 0.3910 (0.4373)\tPrec 88.281% (84.731%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.392 (0.392)\tLoss 0.4796 (0.4796)\tPrec 84.375% (84.375%)\n",
      " * Prec 78.330% \n",
      "best acc: 81.200000\n",
      "Epoch: [28][0/391]\tTime 0.452 (0.452)\tData 0.394 (0.394)\tLoss 0.4482 (0.4482)\tPrec 86.719% (86.719%)\n",
      "Epoch: [28][100/391]\tTime 0.046 (0.053)\tData 0.003 (0.006)\tLoss 0.4714 (0.4219)\tPrec 84.375% (85.326%)\n",
      "Epoch: [28][200/391]\tTime 0.047 (0.051)\tData 0.002 (0.004)\tLoss 0.4539 (0.4238)\tPrec 85.156% (85.215%)\n",
      "Epoch: [28][300/391]\tTime 0.045 (0.049)\tData 0.002 (0.003)\tLoss 0.5435 (0.4297)\tPrec 78.906% (85.094%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.418 (0.418)\tLoss 0.6876 (0.6876)\tPrec 80.469% (80.469%)\n",
      " * Prec 75.580% \n",
      "best acc: 81.200000\n",
      "Epoch: [29][0/391]\tTime 0.649 (0.649)\tData 0.582 (0.582)\tLoss 0.2729 (0.2729)\tPrec 91.406% (91.406%)\n",
      "Epoch: [29][100/391]\tTime 0.051 (0.057)\tData 0.001 (0.008)\tLoss 0.5360 (0.4329)\tPrec 81.250% (84.568%)\n",
      "Epoch: [29][200/391]\tTime 0.044 (0.050)\tData 0.002 (0.005)\tLoss 0.5160 (0.4319)\tPrec 85.156% (84.779%)\n",
      "Epoch: [29][300/391]\tTime 0.042 (0.047)\tData 0.002 (0.004)\tLoss 0.3365 (0.4297)\tPrec 89.844% (84.943%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.272 (0.272)\tLoss 0.4617 (0.4617)\tPrec 85.156% (85.156%)\n",
      " * Prec 81.000% \n",
      "best acc: 81.200000\n",
      "Epoch: [30][0/391]\tTime 0.523 (0.523)\tData 0.425 (0.425)\tLoss 0.4473 (0.4473)\tPrec 84.375% (84.375%)\n",
      "Epoch: [30][100/391]\tTime 0.040 (0.051)\tData 0.002 (0.006)\tLoss 0.3495 (0.4219)\tPrec 88.281% (85.520%)\n",
      "Epoch: [30][200/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 0.3759 (0.4178)\tPrec 88.281% (85.623%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30][300/391]\tTime 0.050 (0.047)\tData 0.001 (0.003)\tLoss 0.4753 (0.4221)\tPrec 82.031% (85.395%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.518 (0.518)\tLoss 0.4748 (0.4748)\tPrec 84.375% (84.375%)\n",
      " * Prec 81.740% \n",
      "best acc: 81.740000\n",
      "Epoch: [31][0/391]\tTime 0.419 (0.419)\tData 0.356 (0.356)\tLoss 0.4778 (0.4778)\tPrec 85.938% (85.938%)\n",
      "Epoch: [31][100/391]\tTime 0.051 (0.055)\tData 0.002 (0.006)\tLoss 0.4700 (0.4069)\tPrec 85.156% (85.999%)\n",
      "Epoch: [31][200/391]\tTime 0.051 (0.053)\tData 0.002 (0.004)\tLoss 0.4383 (0.4068)\tPrec 81.250% (85.669%)\n",
      "Epoch: [31][300/391]\tTime 0.066 (0.053)\tData 0.003 (0.003)\tLoss 0.3968 (0.4116)\tPrec 85.156% (85.501%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.364 (0.364)\tLoss 0.4586 (0.4586)\tPrec 85.156% (85.156%)\n",
      " * Prec 81.140% \n",
      "best acc: 81.740000\n",
      "Epoch: [32][0/391]\tTime 1.215 (1.215)\tData 1.167 (1.167)\tLoss 0.4458 (0.4458)\tPrec 85.938% (85.938%)\n",
      "Epoch: [32][100/391]\tTime 0.051 (0.060)\tData 0.002 (0.014)\tLoss 0.4414 (0.3949)\tPrec 82.812% (86.054%)\n",
      "Epoch: [32][200/391]\tTime 0.051 (0.056)\tData 0.002 (0.008)\tLoss 0.3734 (0.3972)\tPrec 86.719% (85.988%)\n",
      "Epoch: [32][300/391]\tTime 0.053 (0.055)\tData 0.002 (0.006)\tLoss 0.3841 (0.4038)\tPrec 88.281% (85.828%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.479 (0.479)\tLoss 0.4150 (0.4150)\tPrec 85.156% (85.156%)\n",
      " * Prec 82.050% \n",
      "best acc: 82.050000\n",
      "Epoch: [33][0/391]\tTime 0.450 (0.450)\tData 0.354 (0.354)\tLoss 0.5132 (0.5132)\tPrec 83.594% (83.594%)\n",
      "Epoch: [33][100/391]\tTime 0.051 (0.052)\tData 0.002 (0.006)\tLoss 0.4137 (0.4132)\tPrec 84.375% (85.528%)\n",
      "Epoch: [33][200/391]\tTime 0.058 (0.049)\tData 0.003 (0.004)\tLoss 0.4257 (0.4146)\tPrec 85.938% (85.397%)\n",
      "Epoch: [33][300/391]\tTime 0.054 (0.049)\tData 0.003 (0.003)\tLoss 0.3985 (0.4122)\tPrec 85.156% (85.460%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.324 (0.324)\tLoss 0.4655 (0.4655)\tPrec 83.594% (83.594%)\n",
      " * Prec 79.300% \n",
      "best acc: 82.050000\n",
      "Epoch: [34][0/391]\tTime 0.544 (0.544)\tData 0.496 (0.496)\tLoss 0.3356 (0.3356)\tPrec 86.719% (86.719%)\n",
      "Epoch: [34][100/391]\tTime 0.048 (0.052)\tData 0.002 (0.007)\tLoss 0.4791 (0.4111)\tPrec 82.812% (85.636%)\n",
      "Epoch: [34][200/391]\tTime 0.052 (0.047)\tData 0.002 (0.004)\tLoss 0.4486 (0.4037)\tPrec 82.812% (85.708%)\n",
      "Epoch: [34][300/391]\tTime 0.038 (0.045)\tData 0.001 (0.004)\tLoss 0.3099 (0.3957)\tPrec 90.625% (86.036%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.481 (0.481)\tLoss 0.5298 (0.5298)\tPrec 81.250% (81.250%)\n",
      " * Prec 82.130% \n",
      "best acc: 82.130000\n",
      "Epoch: [35][0/391]\tTime 0.621 (0.621)\tData 0.559 (0.559)\tLoss 0.4270 (0.4270)\tPrec 85.938% (85.938%)\n",
      "Epoch: [35][100/391]\tTime 0.055 (0.050)\tData 0.002 (0.007)\tLoss 0.3185 (0.3930)\tPrec 89.062% (86.146%)\n",
      "Epoch: [35][200/391]\tTime 0.054 (0.049)\tData 0.002 (0.005)\tLoss 0.4849 (0.4027)\tPrec 81.250% (85.759%)\n",
      "Epoch: [35][300/391]\tTime 0.058 (0.049)\tData 0.003 (0.004)\tLoss 0.3021 (0.4022)\tPrec 89.844% (85.870%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.389 (0.389)\tLoss 0.4776 (0.4776)\tPrec 86.719% (86.719%)\n",
      " * Prec 79.750% \n",
      "best acc: 82.130000\n",
      "Epoch: [36][0/391]\tTime 0.536 (0.536)\tData 0.488 (0.488)\tLoss 0.3817 (0.3817)\tPrec 88.281% (88.281%)\n",
      "Epoch: [36][100/391]\tTime 0.052 (0.055)\tData 0.003 (0.007)\tLoss 0.3319 (0.3734)\tPrec 87.500% (87.044%)\n",
      "Epoch: [36][200/391]\tTime 0.043 (0.054)\tData 0.002 (0.005)\tLoss 0.4001 (0.3830)\tPrec 85.156% (86.532%)\n",
      "Epoch: [36][300/391]\tTime 0.049 (0.054)\tData 0.002 (0.004)\tLoss 0.2560 (0.3865)\tPrec 92.188% (86.449%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.360 (0.360)\tLoss 0.3966 (0.3966)\tPrec 85.156% (85.156%)\n",
      " * Prec 80.600% \n",
      "best acc: 82.130000\n",
      "Epoch: [37][0/391]\tTime 0.458 (0.458)\tData 0.392 (0.392)\tLoss 0.5006 (0.5006)\tPrec 80.469% (80.469%)\n",
      "Epoch: [37][100/391]\tTime 0.046 (0.056)\tData 0.002 (0.006)\tLoss 0.4404 (0.3768)\tPrec 82.031% (86.502%)\n",
      "Epoch: [37][200/391]\tTime 0.055 (0.055)\tData 0.002 (0.004)\tLoss 0.3262 (0.3808)\tPrec 89.062% (86.416%)\n",
      "Epoch: [37][300/391]\tTime 0.038 (0.054)\tData 0.002 (0.003)\tLoss 0.3136 (0.3873)\tPrec 87.500% (86.200%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.557 (0.557)\tLoss 0.3437 (0.3437)\tPrec 89.844% (89.844%)\n",
      " * Prec 82.940% \n",
      "best acc: 82.940000\n",
      "Epoch: [38][0/391]\tTime 0.263 (0.263)\tData 0.200 (0.200)\tLoss 0.3633 (0.3633)\tPrec 88.281% (88.281%)\n",
      "Epoch: [38][100/391]\tTime 0.045 (0.048)\tData 0.002 (0.004)\tLoss 0.3367 (0.3619)\tPrec 88.281% (87.492%)\n",
      "Epoch: [38][200/391]\tTime 0.050 (0.050)\tData 0.002 (0.003)\tLoss 0.4304 (0.3723)\tPrec 81.250% (86.995%)\n",
      "Epoch: [38][300/391]\tTime 0.051 (0.051)\tData 0.002 (0.003)\tLoss 0.2578 (0.3825)\tPrec 90.625% (86.682%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.342 (0.342)\tLoss 0.6482 (0.6482)\tPrec 78.906% (78.906%)\n",
      " * Prec 78.460% \n",
      "best acc: 82.940000\n",
      "Epoch: [39][0/391]\tTime 0.414 (0.414)\tData 0.363 (0.363)\tLoss 0.3562 (0.3562)\tPrec 89.062% (89.062%)\n",
      "Epoch: [39][100/391]\tTime 0.053 (0.049)\tData 0.002 (0.006)\tLoss 0.4518 (0.3901)\tPrec 87.500% (86.317%)\n",
      "Epoch: [39][200/391]\tTime 0.054 (0.051)\tData 0.002 (0.004)\tLoss 0.3538 (0.3882)\tPrec 88.281% (86.388%)\n",
      "Epoch: [39][300/391]\tTime 0.053 (0.052)\tData 0.002 (0.003)\tLoss 0.3353 (0.3837)\tPrec 89.062% (86.483%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.396 (0.396)\tLoss 0.5270 (0.5270)\tPrec 83.594% (83.594%)\n",
      " * Prec 80.960% \n",
      "best acc: 82.940000\n",
      "Epoch: [40][0/391]\tTime 0.519 (0.519)\tData 0.456 (0.456)\tLoss 0.4222 (0.4222)\tPrec 84.375% (84.375%)\n",
      "Epoch: [40][100/391]\tTime 0.050 (0.055)\tData 0.002 (0.007)\tLoss 0.4214 (0.3728)\tPrec 88.281% (87.059%)\n",
      "Epoch: [40][200/391]\tTime 0.046 (0.054)\tData 0.002 (0.004)\tLoss 0.3763 (0.3797)\tPrec 85.938% (86.777%)\n",
      "Epoch: [40][300/391]\tTime 0.037 (0.053)\tData 0.002 (0.004)\tLoss 0.3789 (0.3748)\tPrec 85.156% (86.981%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.430 (0.430)\tLoss 0.5500 (0.5500)\tPrec 81.250% (81.250%)\n",
      " * Prec 78.880% \n",
      "best acc: 82.940000\n",
      "Epoch: [41][0/391]\tTime 0.397 (0.397)\tData 0.330 (0.330)\tLoss 0.3527 (0.3527)\tPrec 88.281% (88.281%)\n",
      "Epoch: [41][100/391]\tTime 0.048 (0.056)\tData 0.002 (0.006)\tLoss 0.2638 (0.3639)\tPrec 89.844% (87.044%)\n",
      "Epoch: [41][200/391]\tTime 0.044 (0.053)\tData 0.002 (0.004)\tLoss 0.3601 (0.3685)\tPrec 85.156% (86.777%)\n",
      "Epoch: [41][300/391]\tTime 0.042 (0.051)\tData 0.002 (0.003)\tLoss 0.4169 (0.3670)\tPrec 87.500% (86.919%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.550 (0.550)\tLoss 0.4779 (0.4779)\tPrec 79.688% (79.688%)\n",
      " * Prec 82.210% \n",
      "best acc: 82.940000\n",
      "Epoch: [42][0/391]\tTime 0.463 (0.463)\tData 0.390 (0.390)\tLoss 0.3684 (0.3684)\tPrec 85.156% (85.156%)\n",
      "Epoch: [42][100/391]\tTime 0.052 (0.057)\tData 0.002 (0.006)\tLoss 0.4166 (0.3593)\tPrec 85.938% (87.252%)\n",
      "Epoch: [42][200/391]\tTime 0.058 (0.056)\tData 0.002 (0.004)\tLoss 0.4294 (0.3631)\tPrec 82.812% (87.240%)\n",
      "Epoch: [42][300/391]\tTime 0.051 (0.055)\tData 0.002 (0.003)\tLoss 0.3573 (0.3658)\tPrec 86.719% (87.202%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.564 (0.564)\tLoss 0.4013 (0.4013)\tPrec 89.062% (89.062%)\n",
      " * Prec 83.530% \n",
      "best acc: 83.530000\n",
      "Epoch: [43][0/391]\tTime 0.668 (0.668)\tData 0.602 (0.602)\tLoss 0.3096 (0.3096)\tPrec 89.844% (89.844%)\n",
      "Epoch: [43][100/391]\tTime 0.060 (0.061)\tData 0.003 (0.008)\tLoss 0.2530 (0.3648)\tPrec 90.625% (87.283%)\n",
      "Epoch: [43][200/391]\tTime 0.050 (0.055)\tData 0.002 (0.005)\tLoss 0.4724 (0.3667)\tPrec 82.812% (87.174%)\n",
      "Epoch: [43][300/391]\tTime 0.046 (0.053)\tData 0.002 (0.004)\tLoss 0.3570 (0.3706)\tPrec 86.719% (86.981%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.335 (0.335)\tLoss 0.3239 (0.3239)\tPrec 89.062% (89.062%)\n",
      " * Prec 83.220% \n",
      "best acc: 83.530000\n",
      "Epoch: [44][0/391]\tTime 0.591 (0.591)\tData 0.526 (0.526)\tLoss 0.3521 (0.3521)\tPrec 87.500% (87.500%)\n",
      "Epoch: [44][100/391]\tTime 0.039 (0.050)\tData 0.002 (0.007)\tLoss 0.2638 (0.3456)\tPrec 89.062% (87.894%)\n",
      "Epoch: [44][200/391]\tTime 0.054 (0.052)\tData 0.002 (0.005)\tLoss 0.4488 (0.3578)\tPrec 86.719% (87.469%)\n",
      "Epoch: [44][300/391]\tTime 0.052 (0.053)\tData 0.002 (0.004)\tLoss 0.2872 (0.3618)\tPrec 90.625% (87.456%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.268 (0.268)\tLoss 0.4336 (0.4336)\tPrec 83.594% (83.594%)\n",
      " * Prec 79.990% \n",
      "best acc: 83.530000\n",
      "Epoch: [45][0/391]\tTime 0.771 (0.771)\tData 0.709 (0.709)\tLoss 0.3331 (0.3331)\tPrec 87.500% (87.500%)\n",
      "Epoch: [45][100/391]\tTime 0.047 (0.057)\tData 0.002 (0.009)\tLoss 0.2855 (0.3507)\tPrec 88.281% (87.709%)\n",
      "Epoch: [45][200/391]\tTime 0.039 (0.052)\tData 0.002 (0.006)\tLoss 0.4039 (0.3576)\tPrec 85.156% (87.399%)\n",
      "Epoch: [45][300/391]\tTime 0.055 (0.050)\tData 0.002 (0.004)\tLoss 0.5707 (0.3687)\tPrec 85.938% (86.976%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation starts\n",
      "Test: [0/79]\tTime 0.507 (0.507)\tLoss 0.4075 (0.4075)\tPrec 85.156% (85.156%)\n",
      " * Prec 82.230% \n",
      "best acc: 83.530000\n",
      "Epoch: [46][0/391]\tTime 0.462 (0.462)\tData 0.401 (0.401)\tLoss 0.4497 (0.4497)\tPrec 85.156% (85.156%)\n",
      "Epoch: [46][100/391]\tTime 0.052 (0.054)\tData 0.002 (0.006)\tLoss 0.4244 (0.3693)\tPrec 84.375% (86.897%)\n",
      "Epoch: [46][200/391]\tTime 0.051 (0.053)\tData 0.002 (0.004)\tLoss 0.2887 (0.3634)\tPrec 90.625% (87.177%)\n",
      "Epoch: [46][300/391]\tTime 0.050 (0.052)\tData 0.002 (0.004)\tLoss 0.4226 (0.3679)\tPrec 85.156% (87.087%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.500 (0.500)\tLoss 0.3780 (0.3780)\tPrec 85.156% (85.156%)\n",
      " * Prec 81.600% \n",
      "best acc: 83.530000\n",
      "Epoch: [47][0/391]\tTime 0.515 (0.515)\tData 0.455 (0.455)\tLoss 0.2599 (0.2599)\tPrec 89.062% (89.062%)\n",
      "Epoch: [47][100/391]\tTime 0.056 (0.057)\tData 0.002 (0.007)\tLoss 0.2829 (0.3643)\tPrec 92.969% (87.260%)\n",
      "Epoch: [47][200/391]\tTime 0.042 (0.055)\tData 0.002 (0.004)\tLoss 0.4781 (0.3607)\tPrec 82.812% (87.310%)\n",
      "Epoch: [47][300/391]\tTime 0.053 (0.054)\tData 0.002 (0.004)\tLoss 0.3456 (0.3665)\tPrec 85.938% (87.017%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.503 (0.503)\tLoss 0.4572 (0.4572)\tPrec 83.594% (83.594%)\n",
      " * Prec 81.430% \n",
      "best acc: 83.530000\n",
      "Epoch: [48][0/391]\tTime 0.415 (0.415)\tData 0.354 (0.354)\tLoss 0.3865 (0.3865)\tPrec 89.844% (89.844%)\n",
      "Epoch: [48][100/391]\tTime 0.053 (0.050)\tData 0.003 (0.006)\tLoss 0.3626 (0.3423)\tPrec 88.281% (88.065%)\n",
      "Epoch: [48][200/391]\tTime 0.045 (0.050)\tData 0.002 (0.004)\tLoss 0.4742 (0.3499)\tPrec 82.031% (87.671%)\n",
      "Epoch: [48][300/391]\tTime 0.056 (0.050)\tData 0.002 (0.003)\tLoss 0.3135 (0.3536)\tPrec 89.062% (87.557%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.537 (0.537)\tLoss 0.4952 (0.4952)\tPrec 86.719% (86.719%)\n",
      " * Prec 82.410% \n",
      "best acc: 83.530000\n",
      "Epoch: [49][0/391]\tTime 0.615 (0.615)\tData 0.544 (0.544)\tLoss 0.3620 (0.3620)\tPrec 88.281% (88.281%)\n",
      "Epoch: [49][100/391]\tTime 0.053 (0.057)\tData 0.003 (0.008)\tLoss 0.3872 (0.3390)\tPrec 86.719% (88.243%)\n",
      "Epoch: [49][200/391]\tTime 0.060 (0.053)\tData 0.003 (0.005)\tLoss 0.3393 (0.3486)\tPrec 88.281% (87.893%)\n",
      "Epoch: [49][300/391]\tTime 0.059 (0.053)\tData 0.002 (0.004)\tLoss 0.3139 (0.3513)\tPrec 89.844% (87.752%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.539 (0.539)\tLoss 0.4755 (0.4755)\tPrec 82.812% (82.812%)\n",
      " * Prec 83.260% \n",
      "best acc: 83.530000\n",
      "Epoch: [50][0/391]\tTime 0.452 (0.452)\tData 0.389 (0.389)\tLoss 0.2974 (0.2974)\tPrec 89.844% (89.844%)\n",
      "Epoch: [50][100/391]\tTime 0.052 (0.055)\tData 0.002 (0.006)\tLoss 0.2493 (0.3483)\tPrec 93.750% (87.871%)\n",
      "Epoch: [50][200/391]\tTime 0.053 (0.054)\tData 0.002 (0.004)\tLoss 0.2464 (0.3550)\tPrec 94.531% (87.508%)\n",
      "Epoch: [50][300/391]\tTime 0.050 (0.052)\tData 0.002 (0.004)\tLoss 0.2101 (0.3530)\tPrec 93.750% (87.604%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.350 (0.350)\tLoss 0.3712 (0.3712)\tPrec 89.844% (89.844%)\n",
      " * Prec 83.340% \n",
      "best acc: 83.530000\n",
      "Epoch: [51][0/391]\tTime 0.740 (0.740)\tData 0.670 (0.670)\tLoss 0.2108 (0.2108)\tPrec 94.531% (94.531%)\n",
      "Epoch: [51][100/391]\tTime 0.043 (0.054)\tData 0.002 (0.009)\tLoss 0.4852 (0.3316)\tPrec 83.594% (88.575%)\n",
      "Epoch: [51][200/391]\tTime 0.040 (0.053)\tData 0.002 (0.006)\tLoss 0.3428 (0.3318)\tPrec 87.500% (88.390%)\n",
      "Epoch: [51][300/391]\tTime 0.051 (0.052)\tData 0.002 (0.005)\tLoss 0.3765 (0.3409)\tPrec 85.156% (88.094%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.403 (0.403)\tLoss 0.3934 (0.3934)\tPrec 85.938% (85.938%)\n",
      " * Prec 82.010% \n",
      "best acc: 83.530000\n",
      "Epoch: [52][0/391]\tTime 0.465 (0.465)\tData 0.419 (0.419)\tLoss 0.3077 (0.3077)\tPrec 87.500% (87.500%)\n",
      "Epoch: [52][100/391]\tTime 0.059 (0.055)\tData 0.002 (0.006)\tLoss 0.2912 (0.3364)\tPrec 88.281% (88.312%)\n",
      "Epoch: [52][200/391]\tTime 0.053 (0.049)\tData 0.002 (0.004)\tLoss 0.4036 (0.3314)\tPrec 83.594% (88.343%)\n",
      "Epoch: [52][300/391]\tTime 0.042 (0.049)\tData 0.002 (0.003)\tLoss 0.3998 (0.3391)\tPrec 89.062% (88.100%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.324 (0.324)\tLoss 0.4155 (0.4155)\tPrec 85.938% (85.938%)\n",
      " * Prec 84.470% \n",
      "best acc: 84.470000\n",
      "Epoch: [53][0/391]\tTime 0.554 (0.554)\tData 0.512 (0.512)\tLoss 0.3180 (0.3180)\tPrec 88.281% (88.281%)\n",
      "Epoch: [53][100/391]\tTime 0.050 (0.049)\tData 0.002 (0.007)\tLoss 0.3813 (0.3261)\tPrec 83.594% (88.374%)\n",
      "Epoch: [53][200/391]\tTime 0.052 (0.049)\tData 0.002 (0.004)\tLoss 0.3150 (0.3289)\tPrec 89.062% (88.452%)\n",
      "Epoch: [53][300/391]\tTime 0.039 (0.048)\tData 0.002 (0.003)\tLoss 0.3482 (0.3287)\tPrec 84.375% (88.419%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.301 (0.301)\tLoss 0.5554 (0.5554)\tPrec 80.469% (80.469%)\n",
      " * Prec 81.480% \n",
      "best acc: 84.470000\n",
      "Epoch: [54][0/391]\tTime 0.491 (0.491)\tData 0.429 (0.429)\tLoss 0.2271 (0.2271)\tPrec 92.969% (92.969%)\n",
      "Epoch: [54][100/391]\tTime 0.042 (0.051)\tData 0.002 (0.006)\tLoss 0.3058 (0.3154)\tPrec 90.625% (88.714%)\n",
      "Epoch: [54][200/391]\tTime 0.042 (0.046)\tData 0.002 (0.004)\tLoss 0.3690 (0.3223)\tPrec 88.281% (88.616%)\n",
      "Epoch: [54][300/391]\tTime 0.045 (0.045)\tData 0.002 (0.003)\tLoss 0.4278 (0.3291)\tPrec 82.812% (88.473%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.407 (0.407)\tLoss 0.4497 (0.4497)\tPrec 84.375% (84.375%)\n",
      " * Prec 83.790% \n",
      "best acc: 84.470000\n",
      "Epoch: [55][0/391]\tTime 0.638 (0.638)\tData 0.580 (0.580)\tLoss 0.2757 (0.2757)\tPrec 90.625% (90.625%)\n",
      "Epoch: [55][100/391]\tTime 0.050 (0.056)\tData 0.002 (0.008)\tLoss 0.3724 (0.3234)\tPrec 86.719% (88.583%)\n",
      "Epoch: [55][200/391]\tTime 0.066 (0.054)\tData 0.004 (0.005)\tLoss 0.2573 (0.3248)\tPrec 92.969% (88.647%)\n",
      "Epoch: [55][300/391]\tTime 0.058 (0.054)\tData 0.003 (0.004)\tLoss 0.3158 (0.3307)\tPrec 89.062% (88.502%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.470 (0.470)\tLoss 0.4672 (0.4672)\tPrec 84.375% (84.375%)\n",
      " * Prec 82.690% \n",
      "best acc: 84.470000\n",
      "Epoch: [56][0/391]\tTime 0.513 (0.513)\tData 0.444 (0.444)\tLoss 0.3074 (0.3074)\tPrec 87.500% (87.500%)\n",
      "Epoch: [56][100/391]\tTime 0.055 (0.058)\tData 0.002 (0.007)\tLoss 0.3448 (0.3015)\tPrec 85.938% (89.581%)\n",
      "Epoch: [56][200/391]\tTime 0.059 (0.054)\tData 0.003 (0.005)\tLoss 0.2845 (0.3115)\tPrec 89.844% (89.202%)\n",
      "Epoch: [56][300/391]\tTime 0.051 (0.053)\tData 0.002 (0.004)\tLoss 0.3666 (0.3249)\tPrec 86.719% (88.671%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.666 (0.666)\tLoss 0.5415 (0.5415)\tPrec 81.250% (81.250%)\n",
      " * Prec 82.510% \n",
      "best acc: 84.470000\n",
      "Epoch: [57][0/391]\tTime 0.576 (0.576)\tData 0.514 (0.514)\tLoss 0.3623 (0.3623)\tPrec 84.375% (84.375%)\n",
      "Epoch: [57][100/391]\tTime 0.054 (0.055)\tData 0.002 (0.007)\tLoss 0.2630 (0.3206)\tPrec 92.969% (88.939%)\n",
      "Epoch: [57][200/391]\tTime 0.060 (0.054)\tData 0.002 (0.004)\tLoss 0.3749 (0.3201)\tPrec 84.375% (88.872%)\n",
      "Epoch: [57][300/391]\tTime 0.050 (0.053)\tData 0.001 (0.004)\tLoss 0.4654 (0.3260)\tPrec 84.375% (88.632%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.332 (0.332)\tLoss 0.3631 (0.3631)\tPrec 86.719% (86.719%)\n",
      " * Prec 83.800% \n",
      "best acc: 84.470000\n",
      "Epoch: [58][0/391]\tTime 0.800 (0.800)\tData 0.734 (0.734)\tLoss 0.3179 (0.3179)\tPrec 88.281% (88.281%)\n",
      "Epoch: [58][100/391]\tTime 0.050 (0.052)\tData 0.002 (0.009)\tLoss 0.4765 (0.3093)\tPrec 82.812% (89.248%)\n",
      "Epoch: [58][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.006)\tLoss 0.3097 (0.3222)\tPrec 87.500% (88.748%)\n",
      "Epoch: [58][300/391]\tTime 0.042 (0.047)\tData 0.002 (0.004)\tLoss 0.3345 (0.3249)\tPrec 85.156% (88.603%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.436 (0.436)\tLoss 0.4466 (0.4466)\tPrec 85.938% (85.938%)\n",
      " * Prec 84.190% \n",
      "best acc: 84.470000\n",
      "Epoch: [59][0/391]\tTime 0.433 (0.433)\tData 0.373 (0.373)\tLoss 0.3775 (0.3775)\tPrec 87.500% (87.500%)\n",
      "Epoch: [59][100/391]\tTime 0.055 (0.052)\tData 0.002 (0.006)\tLoss 0.3256 (0.3127)\tPrec 87.500% (89.101%)\n",
      "Epoch: [59][200/391]\tTime 0.049 (0.050)\tData 0.002 (0.004)\tLoss 0.3274 (0.3157)\tPrec 88.281% (88.856%)\n",
      "Epoch: [59][300/391]\tTime 0.050 (0.050)\tData 0.002 (0.003)\tLoss 0.3032 (0.3234)\tPrec 89.062% (88.567%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.396 (0.396)\tLoss 0.4677 (0.4677)\tPrec 85.938% (85.938%)\n",
      " * Prec 83.380% \n",
      "best acc: 84.470000\n",
      "Epoch: [60][0/391]\tTime 0.456 (0.456)\tData 0.405 (0.405)\tLoss 0.2426 (0.2426)\tPrec 91.406% (91.406%)\n",
      "Epoch: [60][100/391]\tTime 0.047 (0.049)\tData 0.002 (0.006)\tLoss 0.4202 (0.2973)\tPrec 84.375% (89.511%)\n",
      "Epoch: [60][200/391]\tTime 0.057 (0.051)\tData 0.002 (0.004)\tLoss 0.2923 (0.3104)\tPrec 89.062% (89.074%)\n",
      "Epoch: [60][300/391]\tTime 0.044 (0.049)\tData 0.002 (0.003)\tLoss 0.2469 (0.3200)\tPrec 90.625% (88.795%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.268 (0.268)\tLoss 0.4548 (0.4548)\tPrec 85.156% (85.156%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec 83.240% \n",
      "best acc: 84.470000\n",
      "Epoch: [61][0/391]\tTime 0.493 (0.493)\tData 0.438 (0.438)\tLoss 0.2896 (0.2896)\tPrec 90.625% (90.625%)\n",
      "Epoch: [61][100/391]\tTime 0.045 (0.048)\tData 0.002 (0.006)\tLoss 0.3485 (0.3213)\tPrec 88.281% (88.475%)\n",
      "Epoch: [61][200/391]\tTime 0.041 (0.045)\tData 0.001 (0.004)\tLoss 0.4378 (0.3146)\tPrec 87.500% (88.783%)\n",
      "Epoch: [61][300/391]\tTime 0.047 (0.044)\tData 0.002 (0.003)\tLoss 0.4114 (0.3180)\tPrec 82.031% (88.684%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.345 (0.345)\tLoss 0.4112 (0.4112)\tPrec 85.156% (85.156%)\n",
      " * Prec 82.720% \n",
      "best acc: 84.470000\n",
      "Epoch: [62][0/391]\tTime 0.516 (0.516)\tData 0.451 (0.451)\tLoss 0.3013 (0.3013)\tPrec 88.281% (88.281%)\n",
      "Epoch: [62][100/391]\tTime 0.052 (0.057)\tData 0.002 (0.006)\tLoss 0.2037 (0.3014)\tPrec 93.750% (89.387%)\n",
      "Epoch: [62][200/391]\tTime 0.060 (0.057)\tData 0.003 (0.004)\tLoss 0.4131 (0.3083)\tPrec 82.812% (89.121%)\n",
      "Epoch: [62][300/391]\tTime 0.060 (0.056)\tData 0.002 (0.003)\tLoss 0.2976 (0.3151)\tPrec 88.281% (88.943%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.395 (0.395)\tLoss 0.3594 (0.3594)\tPrec 86.719% (86.719%)\n",
      " * Prec 82.960% \n",
      "best acc: 84.470000\n",
      "Epoch: [63][0/391]\tTime 0.542 (0.542)\tData 0.476 (0.476)\tLoss 0.3209 (0.3209)\tPrec 89.844% (89.844%)\n",
      "Epoch: [63][100/391]\tTime 0.051 (0.054)\tData 0.002 (0.007)\tLoss 0.2915 (0.3171)\tPrec 87.500% (88.962%)\n",
      "Epoch: [63][200/391]\tTime 0.041 (0.052)\tData 0.002 (0.005)\tLoss 0.2207 (0.3160)\tPrec 91.406% (89.051%)\n",
      "Epoch: [63][300/391]\tTime 0.040 (0.049)\tData 0.002 (0.004)\tLoss 0.3609 (0.3137)\tPrec 87.500% (89.094%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.352 (0.352)\tLoss 0.3513 (0.3513)\tPrec 88.281% (88.281%)\n",
      " * Prec 83.660% \n",
      "best acc: 84.470000\n",
      "Epoch: [64][0/391]\tTime 0.492 (0.492)\tData 0.425 (0.425)\tLoss 0.2535 (0.2535)\tPrec 92.188% (92.188%)\n",
      "Epoch: [64][100/391]\tTime 0.050 (0.056)\tData 0.002 (0.006)\tLoss 0.3169 (0.3067)\tPrec 89.844% (89.233%)\n",
      "Epoch: [64][200/391]\tTime 0.052 (0.054)\tData 0.003 (0.004)\tLoss 0.3535 (0.3014)\tPrec 86.719% (89.346%)\n",
      "Epoch: [64][300/391]\tTime 0.040 (0.052)\tData 0.002 (0.004)\tLoss 0.2387 (0.3049)\tPrec 92.188% (89.200%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.328 (0.328)\tLoss 0.3871 (0.3871)\tPrec 88.281% (88.281%)\n",
      " * Prec 82.730% \n",
      "best acc: 84.470000\n",
      "Epoch: [65][0/391]\tTime 1.107 (1.107)\tData 1.056 (1.056)\tLoss 0.4033 (0.4033)\tPrec 87.500% (87.500%)\n",
      "Epoch: [65][100/391]\tTime 0.046 (0.063)\tData 0.003 (0.013)\tLoss 0.2823 (0.2986)\tPrec 90.625% (89.349%)\n",
      "Epoch: [65][200/391]\tTime 0.039 (0.057)\tData 0.002 (0.008)\tLoss 0.3514 (0.3088)\tPrec 85.938% (88.958%)\n",
      "Epoch: [65][300/391]\tTime 0.051 (0.053)\tData 0.003 (0.006)\tLoss 0.2863 (0.3067)\tPrec 89.062% (89.135%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.308 (0.308)\tLoss 0.4870 (0.4870)\tPrec 85.938% (85.938%)\n",
      " * Prec 81.140% \n",
      "best acc: 84.470000\n",
      "Epoch: [66][0/391]\tTime 0.544 (0.544)\tData 0.481 (0.481)\tLoss 0.3355 (0.3355)\tPrec 88.281% (88.281%)\n",
      "Epoch: [66][100/391]\tTime 0.057 (0.051)\tData 0.002 (0.007)\tLoss 0.3004 (0.3005)\tPrec 91.406% (89.240%)\n",
      "Epoch: [66][200/391]\tTime 0.051 (0.050)\tData 0.002 (0.005)\tLoss 0.2412 (0.3069)\tPrec 90.625% (89.035%)\n",
      "Epoch: [66][300/391]\tTime 0.051 (0.050)\tData 0.002 (0.004)\tLoss 0.3339 (0.3088)\tPrec 89.844% (89.016%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.404 (0.404)\tLoss 0.4927 (0.4927)\tPrec 82.812% (82.812%)\n",
      " * Prec 81.880% \n",
      "best acc: 84.470000\n",
      "Epoch: [67][0/391]\tTime 0.483 (0.483)\tData 0.435 (0.435)\tLoss 0.3462 (0.3462)\tPrec 86.719% (86.719%)\n",
      "Epoch: [67][100/391]\tTime 0.042 (0.057)\tData 0.002 (0.007)\tLoss 0.3334 (0.3144)\tPrec 84.375% (88.637%)\n",
      "Epoch: [67][200/391]\tTime 0.045 (0.051)\tData 0.002 (0.004)\tLoss 0.2308 (0.3144)\tPrec 90.625% (88.779%)\n",
      "Epoch: [67][300/391]\tTime 0.049 (0.050)\tData 0.002 (0.003)\tLoss 0.3574 (0.3164)\tPrec 88.281% (88.808%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.356 (0.356)\tLoss 0.3967 (0.3967)\tPrec 87.500% (87.500%)\n",
      " * Prec 82.420% \n",
      "best acc: 84.470000\n",
      "Epoch: [68][0/391]\tTime 0.589 (0.589)\tData 0.527 (0.527)\tLoss 0.2847 (0.2847)\tPrec 88.281% (88.281%)\n",
      "Epoch: [68][100/391]\tTime 0.038 (0.048)\tData 0.002 (0.007)\tLoss 0.2286 (0.2930)\tPrec 88.281% (89.705%)\n",
      "Epoch: [68][200/391]\tTime 0.036 (0.047)\tData 0.002 (0.005)\tLoss 0.2441 (0.2954)\tPrec 89.062% (89.440%)\n",
      "Epoch: [68][300/391]\tTime 0.029 (0.044)\tData 0.001 (0.004)\tLoss 0.3211 (0.3017)\tPrec 89.844% (89.278%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.352 (0.352)\tLoss 0.3907 (0.3907)\tPrec 87.500% (87.500%)\n",
      " * Prec 83.690% \n",
      "best acc: 84.470000\n",
      "Epoch: [69][0/391]\tTime 0.420 (0.420)\tData 0.359 (0.359)\tLoss 0.4164 (0.4164)\tPrec 85.938% (85.938%)\n",
      "Epoch: [69][100/391]\tTime 0.038 (0.045)\tData 0.002 (0.005)\tLoss 0.2001 (0.2909)\tPrec 94.531% (89.712%)\n",
      "Epoch: [69][200/391]\tTime 0.039 (0.044)\tData 0.002 (0.004)\tLoss 0.2286 (0.2854)\tPrec 94.531% (89.883%)\n",
      "Epoch: [69][300/391]\tTime 0.040 (0.044)\tData 0.002 (0.003)\tLoss 0.3041 (0.2924)\tPrec 89.062% (89.727%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.436 (0.436)\tLoss 0.3961 (0.3961)\tPrec 84.375% (84.375%)\n",
      " * Prec 83.180% \n",
      "best acc: 84.470000\n",
      "Epoch: [70][0/391]\tTime 0.490 (0.490)\tData 0.425 (0.425)\tLoss 0.2011 (0.2011)\tPrec 92.188% (92.188%)\n",
      "Epoch: [70][100/391]\tTime 0.036 (0.053)\tData 0.002 (0.006)\tLoss 0.1857 (0.2972)\tPrec 94.531% (89.565%)\n",
      "Epoch: [70][200/391]\tTime 0.041 (0.049)\tData 0.002 (0.004)\tLoss 0.3160 (0.2908)\tPrec 89.844% (89.673%)\n",
      "Epoch: [70][300/391]\tTime 0.042 (0.048)\tData 0.001 (0.003)\tLoss 0.4878 (0.2996)\tPrec 82.031% (89.392%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.451 (0.451)\tLoss 0.4183 (0.4183)\tPrec 86.719% (86.719%)\n",
      " * Prec 81.810% \n",
      "best acc: 84.470000\n",
      "Epoch: [71][0/391]\tTime 0.438 (0.438)\tData 0.376 (0.376)\tLoss 0.2099 (0.2099)\tPrec 92.188% (92.188%)\n",
      "Epoch: [71][100/391]\tTime 0.045 (0.046)\tData 0.002 (0.006)\tLoss 0.2397 (0.2805)\tPrec 91.406% (89.998%)\n",
      "Epoch: [71][200/391]\tTime 0.045 (0.045)\tData 0.002 (0.004)\tLoss 0.1834 (0.2898)\tPrec 94.531% (89.700%)\n",
      "Epoch: [71][300/391]\tTime 0.050 (0.044)\tData 0.002 (0.003)\tLoss 0.2231 (0.2917)\tPrec 90.625% (89.794%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.339 (0.339)\tLoss 0.3026 (0.3026)\tPrec 88.281% (88.281%)\n",
      " * Prec 84.030% \n",
      "best acc: 84.470000\n",
      "Epoch: [72][0/391]\tTime 0.629 (0.629)\tData 0.568 (0.568)\tLoss 0.3344 (0.3344)\tPrec 86.719% (86.719%)\n",
      "Epoch: [72][100/391]\tTime 0.044 (0.050)\tData 0.002 (0.008)\tLoss 0.1642 (0.2793)\tPrec 94.531% (90.153%)\n",
      "Epoch: [72][200/391]\tTime 0.048 (0.048)\tData 0.002 (0.005)\tLoss 0.3628 (0.2942)\tPrec 91.406% (89.548%)\n",
      "Epoch: [72][300/391]\tTime 0.050 (0.049)\tData 0.002 (0.004)\tLoss 0.2713 (0.3024)\tPrec 90.625% (89.273%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.345 (0.345)\tLoss 0.3914 (0.3914)\tPrec 86.719% (86.719%)\n",
      " * Prec 83.870% \n",
      "best acc: 84.470000\n",
      "Epoch: [73][0/391]\tTime 0.461 (0.461)\tData 0.401 (0.401)\tLoss 0.2364 (0.2364)\tPrec 93.750% (93.750%)\n",
      "Epoch: [73][100/391]\tTime 0.046 (0.050)\tData 0.002 (0.006)\tLoss 0.2978 (0.2884)\tPrec 90.625% (89.882%)\n",
      "Epoch: [73][200/391]\tTime 0.041 (0.048)\tData 0.002 (0.004)\tLoss 0.3413 (0.2949)\tPrec 89.844% (89.649%)\n",
      "Epoch: [73][300/391]\tTime 0.053 (0.047)\tData 0.002 (0.003)\tLoss 0.3919 (0.3068)\tPrec 86.719% (89.327%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.468 (0.468)\tLoss 0.4133 (0.4133)\tPrec 86.719% (86.719%)\n",
      " * Prec 84.430% \n",
      "best acc: 84.470000\n",
      "Epoch: [74][0/391]\tTime 0.469 (0.469)\tData 0.426 (0.426)\tLoss 0.2598 (0.2598)\tPrec 90.625% (90.625%)\n",
      "Epoch: [74][100/391]\tTime 0.047 (0.047)\tData 0.002 (0.006)\tLoss 0.3057 (0.2912)\tPrec 89.062% (89.674%)\n",
      "Epoch: [74][200/391]\tTime 0.044 (0.048)\tData 0.001 (0.004)\tLoss 0.2056 (0.2946)\tPrec 92.188% (89.618%)\n",
      "Epoch: [74][300/391]\tTime 0.060 (0.048)\tData 0.003 (0.004)\tLoss 0.1921 (0.2932)\tPrec 92.188% (89.589%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.399 (0.399)\tLoss 0.4394 (0.4394)\tPrec 83.594% (83.594%)\n",
      " * Prec 84.360% \n",
      "best acc: 84.470000\n",
      "Epoch: [75][0/391]\tTime 0.675 (0.675)\tData 0.577 (0.577)\tLoss 0.1876 (0.1876)\tPrec 92.969% (92.969%)\n",
      "Epoch: [75][100/391]\tTime 0.036 (0.051)\tData 0.002 (0.008)\tLoss 0.2268 (0.2831)\tPrec 92.188% (89.991%)\n",
      "Epoch: [75][200/391]\tTime 0.052 (0.048)\tData 0.002 (0.005)\tLoss 0.2645 (0.2948)\tPrec 88.281% (89.572%)\n",
      "Epoch: [75][300/391]\tTime 0.049 (0.047)\tData 0.002 (0.004)\tLoss 0.2842 (0.2981)\tPrec 86.719% (89.418%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.288 (0.288)\tLoss 0.3897 (0.3897)\tPrec 86.719% (86.719%)\n",
      " * Prec 81.230% \n",
      "best acc: 84.470000\n",
      "Epoch: [76][0/391]\tTime 0.815 (0.815)\tData 0.756 (0.756)\tLoss 0.4097 (0.4097)\tPrec 85.938% (85.938%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [76][100/391]\tTime 0.040 (0.051)\tData 0.002 (0.009)\tLoss 0.3379 (0.2832)\tPrec 88.281% (90.076%)\n",
      "Epoch: [76][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.006)\tLoss 0.2864 (0.2908)\tPrec 91.406% (89.762%)\n",
      "Epoch: [76][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.004)\tLoss 0.3412 (0.2943)\tPrec 89.062% (89.714%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.349 (0.349)\tLoss 0.4253 (0.4253)\tPrec 88.281% (88.281%)\n",
      " * Prec 84.250% \n",
      "best acc: 84.470000\n",
      "Epoch: [77][0/391]\tTime 0.538 (0.538)\tData 0.476 (0.476)\tLoss 0.2067 (0.2067)\tPrec 90.625% (90.625%)\n",
      "Epoch: [77][100/391]\tTime 0.044 (0.048)\tData 0.002 (0.007)\tLoss 0.3172 (0.2900)\tPrec 86.719% (90.022%)\n",
      "Epoch: [77][200/391]\tTime 0.043 (0.047)\tData 0.002 (0.004)\tLoss 0.3211 (0.2904)\tPrec 88.281% (89.914%)\n",
      "Epoch: [77][300/391]\tTime 0.046 (0.045)\tData 0.002 (0.004)\tLoss 0.2808 (0.2958)\tPrec 91.406% (89.696%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.320 (0.320)\tLoss 0.3832 (0.3832)\tPrec 85.938% (85.938%)\n",
      " * Prec 84.580% \n",
      "best acc: 84.580000\n",
      "Epoch: [78][0/391]\tTime 0.420 (0.420)\tData 0.356 (0.356)\tLoss 0.2135 (0.2135)\tPrec 92.188% (92.188%)\n",
      "Epoch: [78][100/391]\tTime 0.047 (0.048)\tData 0.002 (0.005)\tLoss 0.3452 (0.2638)\tPrec 87.500% (90.764%)\n",
      "Epoch: [78][200/391]\tTime 0.038 (0.045)\tData 0.001 (0.004)\tLoss 0.3107 (0.2779)\tPrec 87.500% (90.333%)\n",
      "Epoch: [78][300/391]\tTime 0.042 (0.045)\tData 0.002 (0.003)\tLoss 0.3062 (0.2863)\tPrec 89.844% (90.005%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.286 (0.286)\tLoss 0.4770 (0.4770)\tPrec 84.375% (84.375%)\n",
      " * Prec 83.230% \n",
      "best acc: 84.580000\n",
      "Epoch: [79][0/391]\tTime 0.433 (0.433)\tData 0.372 (0.372)\tLoss 0.3460 (0.3460)\tPrec 85.156% (85.156%)\n",
      "Epoch: [79][100/391]\tTime 0.048 (0.045)\tData 0.002 (0.006)\tLoss 0.2328 (0.2860)\tPrec 92.969% (89.913%)\n",
      "Epoch: [79][200/391]\tTime 0.038 (0.045)\tData 0.002 (0.004)\tLoss 0.2968 (0.2876)\tPrec 91.406% (89.778%)\n",
      "Epoch: [79][300/391]\tTime 0.048 (0.043)\tData 0.002 (0.003)\tLoss 0.2550 (0.2919)\tPrec 92.969% (89.610%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.301 (0.301)\tLoss 0.4312 (0.4312)\tPrec 87.500% (87.500%)\n",
      " * Prec 85.250% \n",
      "best acc: 85.250000\n",
      "Epoch: [80][0/391]\tTime 1.052 (1.052)\tData 0.989 (0.989)\tLoss 0.2563 (0.2563)\tPrec 89.844% (89.844%)\n",
      "Epoch: [80][100/391]\tTime 0.048 (0.057)\tData 0.002 (0.012)\tLoss 0.2235 (0.2384)\tPrec 93.750% (91.754%)\n",
      "Epoch: [80][200/391]\tTime 0.038 (0.051)\tData 0.001 (0.007)\tLoss 0.2224 (0.2270)\tPrec 92.969% (92.086%)\n",
      "Epoch: [80][300/391]\tTime 0.044 (0.048)\tData 0.002 (0.005)\tLoss 0.2408 (0.2178)\tPrec 91.406% (92.424%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.469 (0.469)\tLoss 0.2459 (0.2459)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.340% \n",
      "best acc: 87.340000\n",
      "Epoch: [81][0/391]\tTime 0.472 (0.472)\tData 0.407 (0.407)\tLoss 0.1664 (0.1664)\tPrec 95.312% (95.312%)\n",
      "Epoch: [81][100/391]\tTime 0.044 (0.049)\tData 0.001 (0.006)\tLoss 0.1495 (0.2012)\tPrec 96.094% (93.147%)\n",
      "Epoch: [81][200/391]\tTime 0.041 (0.046)\tData 0.001 (0.004)\tLoss 0.1373 (0.1888)\tPrec 93.750% (93.493%)\n",
      "Epoch: [81][300/391]\tTime 0.044 (0.044)\tData 0.002 (0.003)\tLoss 0.1167 (0.1886)\tPrec 96.094% (93.579%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.549 (0.549)\tLoss 0.2333 (0.2333)\tPrec 89.062% (89.062%)\n",
      " * Prec 88.110% \n",
      "best acc: 88.110000\n",
      "Epoch: [82][0/391]\tTime 0.649 (0.649)\tData 0.588 (0.588)\tLoss 0.2046 (0.2046)\tPrec 92.969% (92.969%)\n",
      "Epoch: [82][100/391]\tTime 0.040 (0.050)\tData 0.002 (0.008)\tLoss 0.2171 (0.1878)\tPrec 92.188% (93.541%)\n",
      "Epoch: [82][200/391]\tTime 0.043 (0.046)\tData 0.002 (0.005)\tLoss 0.1820 (0.1828)\tPrec 93.750% (93.746%)\n",
      "Epoch: [82][300/391]\tTime 0.042 (0.045)\tData 0.002 (0.004)\tLoss 0.1165 (0.1809)\tPrec 96.875% (93.781%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.422 (0.422)\tLoss 0.2492 (0.2492)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.280% \n",
      "best acc: 88.280000\n",
      "Epoch: [83][0/391]\tTime 0.558 (0.558)\tData 0.492 (0.492)\tLoss 0.1080 (0.1080)\tPrec 96.094% (96.094%)\n",
      "Epoch: [83][100/391]\tTime 0.054 (0.053)\tData 0.003 (0.007)\tLoss 0.2562 (0.1674)\tPrec 90.625% (94.291%)\n",
      "Epoch: [83][200/391]\tTime 0.046 (0.050)\tData 0.002 (0.005)\tLoss 0.1940 (0.1700)\tPrec 94.531% (94.150%)\n",
      "Epoch: [83][300/391]\tTime 0.039 (0.049)\tData 0.002 (0.004)\tLoss 0.1636 (0.1743)\tPrec 94.531% (93.989%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.372 (0.372)\tLoss 0.2442 (0.2442)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.020% \n",
      "best acc: 88.280000\n",
      "Epoch: [84][0/391]\tTime 0.523 (0.523)\tData 0.461 (0.461)\tLoss 0.2174 (0.2174)\tPrec 93.750% (93.750%)\n",
      "Epoch: [84][100/391]\tTime 0.052 (0.053)\tData 0.002 (0.006)\tLoss 0.1422 (0.1685)\tPrec 94.531% (94.338%)\n",
      "Epoch: [84][200/391]\tTime 0.050 (0.053)\tData 0.002 (0.004)\tLoss 0.1699 (0.1703)\tPrec 92.969% (94.236%)\n",
      "Epoch: [84][300/391]\tTime 0.038 (0.052)\tData 0.002 (0.004)\tLoss 0.1069 (0.1695)\tPrec 95.312% (94.269%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.335 (0.335)\tLoss 0.2128 (0.2128)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.360% \n",
      "best acc: 88.360000\n",
      "Epoch: [85][0/391]\tTime 0.480 (0.480)\tData 0.416 (0.416)\tLoss 0.1610 (0.1610)\tPrec 93.750% (93.750%)\n",
      "Epoch: [85][100/391]\tTime 0.056 (0.054)\tData 0.002 (0.006)\tLoss 0.1398 (0.1660)\tPrec 96.875% (94.160%)\n",
      "Epoch: [85][200/391]\tTime 0.057 (0.052)\tData 0.002 (0.004)\tLoss 0.2612 (0.1652)\tPrec 91.406% (94.317%)\n",
      "Epoch: [85][300/391]\tTime 0.040 (0.051)\tData 0.002 (0.003)\tLoss 0.1643 (0.1637)\tPrec 94.531% (94.383%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.394 (0.394)\tLoss 0.2461 (0.2461)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.020% \n",
      "best acc: 88.360000\n",
      "Epoch: [86][0/391]\tTime 0.643 (0.643)\tData 0.582 (0.582)\tLoss 0.1409 (0.1409)\tPrec 94.531% (94.531%)\n",
      "Epoch: [86][100/391]\tTime 0.040 (0.051)\tData 0.002 (0.008)\tLoss 0.1783 (0.1596)\tPrec 95.312% (94.392%)\n",
      "Epoch: [86][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.005)\tLoss 0.2012 (0.1636)\tPrec 94.531% (94.426%)\n",
      "Epoch: [86][300/391]\tTime 0.050 (0.046)\tData 0.002 (0.004)\tLoss 0.2081 (0.1633)\tPrec 92.969% (94.407%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.252 (0.252)\tLoss 0.2445 (0.2445)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.340% \n",
      "best acc: 88.360000\n",
      "Epoch: [87][0/391]\tTime 0.521 (0.521)\tData 0.460 (0.460)\tLoss 0.1399 (0.1399)\tPrec 95.312% (95.312%)\n",
      "Epoch: [87][100/391]\tTime 0.044 (0.046)\tData 0.002 (0.006)\tLoss 0.1843 (0.1537)\tPrec 93.750% (94.732%)\n",
      "Epoch: [87][200/391]\tTime 0.048 (0.044)\tData 0.002 (0.004)\tLoss 0.1567 (0.1538)\tPrec 92.188% (94.745%)\n",
      "Epoch: [87][300/391]\tTime 0.048 (0.043)\tData 0.002 (0.003)\tLoss 0.1948 (0.1517)\tPrec 93.750% (94.874%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.379 (0.379)\tLoss 0.2032 (0.2032)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.300% \n",
      "best acc: 88.360000\n",
      "Epoch: [88][0/391]\tTime 0.553 (0.553)\tData 0.436 (0.436)\tLoss 0.1392 (0.1392)\tPrec 94.531% (94.531%)\n",
      "Epoch: [88][100/391]\tTime 0.040 (0.047)\tData 0.002 (0.006)\tLoss 0.1765 (0.1510)\tPrec 92.188% (94.756%)\n",
      "Epoch: [88][200/391]\tTime 0.045 (0.044)\tData 0.002 (0.004)\tLoss 0.1156 (0.1497)\tPrec 96.094% (94.803%)\n",
      "Epoch: [88][300/391]\tTime 0.045 (0.044)\tData 0.002 (0.003)\tLoss 0.1962 (0.1511)\tPrec 96.094% (94.726%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.440 (0.440)\tLoss 0.2273 (0.2273)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.340% \n",
      "best acc: 88.360000\n",
      "Epoch: [89][0/391]\tTime 0.460 (0.460)\tData 0.402 (0.402)\tLoss 0.0822 (0.0822)\tPrec 99.219% (99.219%)\n",
      "Epoch: [89][100/391]\tTime 0.040 (0.049)\tData 0.002 (0.006)\tLoss 0.1377 (0.1356)\tPrec 96.094% (95.398%)\n",
      "Epoch: [89][200/391]\tTime 0.042 (0.046)\tData 0.002 (0.004)\tLoss 0.1402 (0.1481)\tPrec 96.875% (95.033%)\n",
      "Epoch: [89][300/391]\tTime 0.039 (0.046)\tData 0.001 (0.003)\tLoss 0.1894 (0.1497)\tPrec 93.750% (94.954%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.478 (0.478)\tLoss 0.2507 (0.2507)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.400% \n",
      "best acc: 88.400000\n",
      "Epoch: [90][0/391]\tTime 0.592 (0.592)\tData 0.522 (0.522)\tLoss 0.1079 (0.1079)\tPrec 96.094% (96.094%)\n",
      "Epoch: [90][100/391]\tTime 0.039 (0.048)\tData 0.002 (0.007)\tLoss 0.1324 (0.1522)\tPrec 98.438% (94.825%)\n",
      "Epoch: [90][200/391]\tTime 0.044 (0.045)\tData 0.002 (0.004)\tLoss 0.1083 (0.1486)\tPrec 95.312% (94.904%)\n",
      "Epoch: [90][300/391]\tTime 0.040 (0.044)\tData 0.002 (0.004)\tLoss 0.1052 (0.1450)\tPrec 97.656% (95.024%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.400 (0.400)\tLoss 0.2127 (0.2127)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.630% \n",
      "best acc: 88.630000\n",
      "Epoch: [91][0/391]\tTime 0.572 (0.572)\tData 0.504 (0.504)\tLoss 0.2293 (0.2293)\tPrec 92.969% (92.969%)\n",
      "Epoch: [91][100/391]\tTime 0.047 (0.055)\tData 0.002 (0.007)\tLoss 0.1483 (0.1414)\tPrec 95.312% (95.305%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [91][200/391]\tTime 0.050 (0.053)\tData 0.002 (0.004)\tLoss 0.1434 (0.1441)\tPrec 93.750% (95.149%)\n",
      "Epoch: [91][300/391]\tTime 0.059 (0.053)\tData 0.002 (0.003)\tLoss 0.1435 (0.1424)\tPrec 92.969% (95.141%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.340 (0.340)\tLoss 0.2109 (0.2109)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.580% \n",
      "best acc: 88.630000\n",
      "Epoch: [92][0/391]\tTime 0.413 (0.413)\tData 0.355 (0.355)\tLoss 0.2125 (0.2125)\tPrec 90.625% (90.625%)\n",
      "Epoch: [92][100/391]\tTime 0.044 (0.048)\tData 0.002 (0.005)\tLoss 0.1934 (0.1429)\tPrec 92.188% (94.995%)\n",
      "Epoch: [92][200/391]\tTime 0.047 (0.046)\tData 0.002 (0.004)\tLoss 0.0900 (0.1402)\tPrec 97.656% (95.215%)\n",
      "Epoch: [92][300/391]\tTime 0.048 (0.045)\tData 0.002 (0.003)\tLoss 0.0871 (0.1384)\tPrec 98.438% (95.315%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.379 (0.379)\tLoss 0.2112 (0.2112)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.720% \n",
      "best acc: 88.720000\n",
      "Epoch: [93][0/391]\tTime 0.466 (0.466)\tData 0.406 (0.406)\tLoss 0.0967 (0.0967)\tPrec 96.875% (96.875%)\n",
      "Epoch: [93][100/391]\tTime 0.049 (0.047)\tData 0.002 (0.006)\tLoss 0.1780 (0.1392)\tPrec 95.312% (95.382%)\n",
      "Epoch: [93][200/391]\tTime 0.039 (0.045)\tData 0.002 (0.004)\tLoss 0.1657 (0.1400)\tPrec 95.312% (95.258%)\n",
      "Epoch: [93][300/391]\tTime 0.048 (0.044)\tData 0.002 (0.003)\tLoss 0.1687 (0.1405)\tPrec 94.531% (95.214%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.350 (0.350)\tLoss 0.2156 (0.2156)\tPrec 94.531% (94.531%)\n",
      " * Prec 88.590% \n",
      "best acc: 88.720000\n",
      "Epoch: [94][0/391]\tTime 0.510 (0.510)\tData 0.448 (0.448)\tLoss 0.1175 (0.1175)\tPrec 96.094% (96.094%)\n",
      "Epoch: [94][100/391]\tTime 0.043 (0.051)\tData 0.002 (0.007)\tLoss 0.1700 (0.1418)\tPrec 92.969% (95.297%)\n",
      "Epoch: [94][200/391]\tTime 0.040 (0.048)\tData 0.002 (0.004)\tLoss 0.2082 (0.1355)\tPrec 90.625% (95.495%)\n",
      "Epoch: [94][300/391]\tTime 0.043 (0.047)\tData 0.002 (0.004)\tLoss 0.1367 (0.1377)\tPrec 95.312% (95.416%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.329 (0.329)\tLoss 0.2064 (0.2064)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.470% \n",
      "best acc: 88.720000\n",
      "Epoch: [95][0/391]\tTime 0.507 (0.507)\tData 0.406 (0.406)\tLoss 0.2039 (0.2039)\tPrec 92.969% (92.969%)\n",
      "Epoch: [95][100/391]\tTime 0.054 (0.053)\tData 0.002 (0.006)\tLoss 0.1547 (0.1355)\tPrec 94.531% (95.514%)\n",
      "Epoch: [95][200/391]\tTime 0.050 (0.053)\tData 0.002 (0.004)\tLoss 0.1613 (0.1378)\tPrec 94.531% (95.398%)\n",
      "Epoch: [95][300/391]\tTime 0.049 (0.052)\tData 0.002 (0.003)\tLoss 0.1087 (0.1384)\tPrec 96.094% (95.307%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.290 (0.290)\tLoss 0.2053 (0.2053)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.450% \n",
      "best acc: 88.720000\n",
      "Epoch: [96][0/391]\tTime 0.465 (0.465)\tData 0.418 (0.418)\tLoss 0.1093 (0.1093)\tPrec 95.312% (95.312%)\n",
      "Epoch: [96][100/391]\tTime 0.037 (0.042)\tData 0.002 (0.006)\tLoss 0.1506 (0.1408)\tPrec 93.750% (95.127%)\n",
      "Epoch: [96][200/391]\tTime 0.045 (0.040)\tData 0.002 (0.004)\tLoss 0.1861 (0.1377)\tPrec 92.969% (95.250%)\n",
      "Epoch: [96][300/391]\tTime 0.051 (0.042)\tData 0.003 (0.003)\tLoss 0.1482 (0.1376)\tPrec 93.750% (95.279%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.264 (0.264)\tLoss 0.2109 (0.2109)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.500% \n",
      "best acc: 88.720000\n",
      "Epoch: [97][0/391]\tTime 0.474 (0.474)\tData 0.406 (0.406)\tLoss 0.0436 (0.0436)\tPrec 100.000% (100.000%)\n",
      "Epoch: [97][100/391]\tTime 0.042 (0.051)\tData 0.002 (0.006)\tLoss 0.0933 (0.1307)\tPrec 97.656% (95.684%)\n",
      "Epoch: [97][200/391]\tTime 0.038 (0.046)\tData 0.002 (0.004)\tLoss 0.0951 (0.1344)\tPrec 96.875% (95.460%)\n",
      "Epoch: [97][300/391]\tTime 0.048 (0.045)\tData 0.003 (0.003)\tLoss 0.2157 (0.1355)\tPrec 92.188% (95.403%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.286 (0.286)\tLoss 0.2300 (0.2300)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.570% \n",
      "best acc: 88.720000\n",
      "Epoch: [98][0/391]\tTime 0.582 (0.582)\tData 0.522 (0.522)\tLoss 0.1413 (0.1413)\tPrec 95.312% (95.312%)\n",
      "Epoch: [98][100/391]\tTime 0.035 (0.047)\tData 0.002 (0.007)\tLoss 0.1291 (0.1364)\tPrec 96.875% (95.274%)\n",
      "Epoch: [98][200/391]\tTime 0.037 (0.044)\tData 0.001 (0.004)\tLoss 0.1309 (0.1329)\tPrec 94.531% (95.375%)\n",
      "Epoch: [98][300/391]\tTime 0.040 (0.044)\tData 0.001 (0.003)\tLoss 0.1694 (0.1366)\tPrec 93.750% (95.294%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.347 (0.347)\tLoss 0.1940 (0.1940)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.520% \n",
      "best acc: 88.720000\n",
      "Epoch: [99][0/391]\tTime 0.525 (0.525)\tData 0.460 (0.460)\tLoss 0.1084 (0.1084)\tPrec 96.875% (96.875%)\n",
      "Epoch: [99][100/391]\tTime 0.035 (0.049)\tData 0.002 (0.006)\tLoss 0.1555 (0.1336)\tPrec 96.094% (95.560%)\n",
      "Epoch: [99][200/391]\tTime 0.040 (0.046)\tData 0.001 (0.004)\tLoss 0.0759 (0.1351)\tPrec 96.875% (95.332%)\n",
      "Epoch: [99][300/391]\tTime 0.041 (0.045)\tData 0.002 (0.003)\tLoss 0.1100 (0.1359)\tPrec 95.312% (95.281%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.425 (0.425)\tLoss 0.1837 (0.1837)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.580% \n",
      "best acc: 88.720000\n"
     ]
    }
   ],
   "source": [
    "lr = 4e-2\n",
    "weight_decay = 1e-4\n",
    "epochs = 100\n",
    "best_prec = 0\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9,weight_decay=weight_decay)\n",
    "\n",
    "if not os.path.exists('result'): \n",
    "    os.makedirs('result')\n",
    "\n",
    "fdir = 'result/'+str(model_name) \n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "\n",
    "adjust_list = [80,90]\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch,adjust_list)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6751af9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 8872/10000 (89%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/Resnet_20_quant_project/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c9deeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 -th layer prehooked\n",
      "9 -th layer prehooked\n",
      "13 -th layer prehooked\n",
      "15 -th layer prehooked\n",
      "21 -th layer prehooked\n",
      "25 -th layer prehooked\n",
      "27 -th layer prehooked\n",
      "34 -th layer prehooked\n",
      "36 -th layer prehooked\n",
      "42 -th layer prehooked\n",
      "46 -th layer prehooked\n",
      "48 -th layer prehooked\n",
      "54 -th layer prehooked\n",
      "56 -th layer prehooked\n",
      "63 -th layer prehooked\n",
      "65 -th layer prehooked\n",
      "71 -th layer prehooked\n",
      "75 -th layer prehooked\n",
      "77 -th layer prehooked\n",
      "83 -th layer prehooked\n",
      "85 -th layer prehooked\n"
     ]
    }
   ],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "i = 0\n",
    "\n",
    "for layer in model.modules():\n",
    "    i = i+1\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        print(i,\"-th layer prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)             \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.to(device)\n",
    "out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba87f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Layer 9\n",
    "## Layer 13\n",
    "## save_outputs.output[1][0]\n",
    "## save_outputs.output[2][0]\n",
    "model.layer1[0].conv2.weight_quant.wgt_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f82d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Residual x0_int calculation\n",
    "x0_bit = 4\n",
    "w0_bit = 4\n",
    "x0 = save_output.outputs[0][0]\n",
    "x0_alpha = model.layer1[0].conv2.act_alpha\n",
    "w0_alpha = model.layer1[0].conv2.weight_quant.wgt_alpha\n",
    "x0_delta = x0_alpha/(2**x0_bit-1)\n",
    "w0_delta = w0_alpha/(2**(w0_bit-1)-1)\n",
    "act_quant = act_quantization(x0_bit)\n",
    "x0_q = act_quant(x0,(x0_alpha*w0_alpha))\n",
    "x0_int = x0_q/(x0_delta*w0_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c382aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference between psum original and psum recovered = 2.9711912929997197e-07\n"
     ]
    }
   ],
   "source": [
    "w_bit = 4\n",
    "weight_q = model.layer1[0].conv2.weight_q\n",
    "w_alpha = model.layer1[0].conv2.weight_quant.wgt_alpha\n",
    "w_delta = w_alpha/(2**(w_bit-1)-1)\n",
    "weight_int = weight_q/w_delta\n",
    "\n",
    "x_bit = 4\n",
    "x = save_output.outputs[1][0]\n",
    "x_alpha = model.layer1[0].conv2.act_alpha\n",
    "x_delta = x_alpha/(2**x_bit-1)\n",
    "act_quant = act_quantization(x_bit)\n",
    "x_q = act_quant(x,x_alpha)\n",
    "x_int = x_q/x_delta\n",
    "\n",
    "conv_int = nn.Conv2d(8,8,kernel_size=3, padding=1, bias=False)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "output_int = (conv_int(x_int))\n",
    "psum_recovered = output_int*x_delta*w_delta + x0\n",
    "relu = nn.ReLU(inplace=True)\n",
    "psum_after_relu = relu(psum_recovered)\n",
    "difference = (save_output.outputs[2][0] - psum_after_relu).mean()\n",
    "print(\"The difference between psum original and psum recovered = {}\".format(difference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f23a7787",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_int = x_int[0,:,:,:]  # pick only one input out of batch\n",
    "# a_int.size() = [64, 32, 32]\n",
    "\n",
    "# conv_int.weight.size() = torch.Size([64, 64, 3, 3])  <- output_ch, input_ch, ki, kj\n",
    "w_int = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))  # merge ki, kj index to kij\n",
    "\n",
    "padding = 1\n",
    "stride = 1\n",
    "array_size = 8\n",
    "x_size = x_int.size()\n",
    "nig = range(x_size[2])\n",
    "njg = range(x_size[3])\n",
    "\n",
    "kijg = range(w_int.size(2))\n",
    "ki_dim = int(math.sqrt(w_int.size(2)))  ## Kernel's 1 dim size\n",
    "\n",
    "icg = range(int(w_int.size(1)))  ## input channel \n",
    "ocg = range(int(w_int.size(0)))  ## output channel\n",
    "\n",
    "a_pad = torch.zeros((x_size[1],x_size[2]+2*padding,x_size[3]+2*padding))\n",
    "\n",
    "a_pad[ :, padding:padding+len(nig), padding:padding+len(njg)] = act_int.cuda()\n",
    "a_pad = torch.reshape(a_pad, (a_pad.size(0), -1))\n",
    "\n",
    "ic_tile = range(int(int(act_int.size(0))/array_size))\n",
    "oc_tile = range(int(int(w_int.size(0))/array_size))\n",
    "\n",
    "a_tile = torch.zeros(len(ic_tile),array_size,len(nig)+padding*2,len(njg)+padding*2).cuda()\n",
    "a_tile = torch.reshape(a_tile,(a_tile.size(0),a_tile.size(1),-1))\n",
    "\n",
    "for ict in ic_tile:\n",
    "    a_tile[ict,:,:] = a_pad[(ict*array_size):((ict+1)*array_size),:]\n",
    "\n",
    "w_tile = torch.zeros(len(ic_tile),len(oc_tile),array_size,array_size,len(kijg)).cuda()\n",
    "\n",
    "for oct in oc_tile:\n",
    "    for ict in ic_tile:\n",
    "        w_tile[ict,oct,:,:,:] = w_int[(oct*array_size):((oct+1)*array_size),(ict*array_size):((ict+1)*array_size),:]\n",
    "\n",
    "p_nijg = range(a_pad.size(1)) ## paded activation's nij group\n",
    "\n",
    "psum = torch.zeros(len(ic_tile),len(oc_tile),array_size,len(p_nijg),len(kijg)).cuda() \n",
    "\n",
    "for kij in kijg:\n",
    "    for ict in ic_tile:\n",
    "        for oct in oc_tile:\n",
    "            for nij in p_nijg:     # time domain, sequentially given input\n",
    "                m = nn.Linear(array_size, array_size, bias=False)\n",
    "                m.weight = torch.nn.Parameter(w_tile[ict,oct,:,:,kij])\n",
    "                psum[ict,oct,:, nij, kij] = m(a_tile[ict,:,nij]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a32a1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "a_pad_ni_dim = int(math.sqrt(a_pad.size(1))) # 32 + 2*pad = 34\n",
    "\n",
    "o_ni_dim = int((a_pad_ni_dim - (ki_dim- 1) - 1)/stride + 1) #34 - 2 - 1 + 1 = 32\n",
    "o_nijg = range(o_ni_dim**2)    \n",
    "    \n",
    "out = torch.zeros(len(ocg), len(o_nijg)).cuda()\n",
    "  \n",
    "   \n",
    "### SFP accumulation ###\n",
    "for o_nij in o_nijg: \n",
    "    for kij in kijg:  \n",
    "        for ict in ic_tile:\n",
    "            for oct in oc_tile:\n",
    "                out[oct*array_size:(oct+1)*array_size,o_nij] = out[oct*array_size:(oct+1)*array_size,o_nij] + \\\n",
    "                psum[ict,oct,:, int(o_nij/o_ni_dim)*a_pad_ni_dim + o_nij%o_ni_dim + int(kij/ki_dim)*a_pad_ni_dim + kij%ki_dim, kij]\n",
    "                ## 2nd index = (int(o_nij/30)*32 + o_nij%30) + (int(kij/3)*32 + kij%3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7315d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = x0_int[0,:,:,:]\n",
    "residual_reshaped = torch.reshape(residual,(residual.size(0),-1))\n",
    "out_after_residual = out + residual_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5914aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dump all the files\n",
    "\n",
    "## Helper functions to dump files\n",
    "def dec_to_bin(arr,bit):\n",
    "    bin_arr = []\n",
    "    for a in arr:\n",
    "        a = int(a)\n",
    "        if a < 0:\n",
    "            a+=bit\n",
    "        b = '{0:04b}'.format(int(a))\n",
    "        bin_arr.append(b)\n",
    "    return bin_arr\n",
    "\n",
    "def dec_to_bin_psum(arr,bit):\n",
    "    bin_arr = []\n",
    "    for a in arr:\n",
    "        a = int(a)\n",
    "        sign = 0\n",
    "        if a < 0:\n",
    "            sign = 1\n",
    "            a+=bit\n",
    "        b = '{0:16b}'.format(int(a))\n",
    "        if sign == 1:\n",
    "            b = b.replace(\" \", \"1\")\n",
    "        else:\n",
    "            b = b.replace(\" \",\"0\")\n",
    "        bin_arr.append(b)\n",
    "    return bin_arr\n",
    "\n",
    "\n",
    "def convert_to_list(arr):\n",
    "    return arr.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98061c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Activation dump\n",
    "\n",
    "fp_act = open('Resnet_activation_project.txt','w')\n",
    "fp_act.write(\"#####\\n\")\n",
    "fp_act.write(\"#####\\n\")\n",
    "fp_act.write(\"#####\\n\")\n",
    "fp_act_dec = open('Resnet_activation_dec.txt','w')\n",
    "for i in range(a_pad.size()[1]):\n",
    "    act_line = a_pad[:,i]\n",
    "    act_arr = [int(j+0.001) for j in convert_to_list(act_line)]\n",
    "    for a in act_arr[::-1]:\n",
    "        #print(int(a))\n",
    "        fp_act_dec.write(str(int(a)))\n",
    "        fp_act_dec.write(\" \")\n",
    "    fp_act_dec.write(\"\\n\")\n",
    "    bin_act = dec_to_bin(act_arr,16)\n",
    "    for b in bin_act[::-1]:\n",
    "        #print(b)\n",
    "        fp_act.write(b)\n",
    "    fp_act.write('\\n')\n",
    "    \n",
    "\n",
    "fp_act.close()\n",
    "fp_act_dec.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9af62655",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weight dump\n",
    "fp_wgt = open('Resnet_weight_project.txt','w')\n",
    "fp_wgt.write(\"#####\\n\")\n",
    "fp_wgt.write(\"#####\\n\")\n",
    "fp_wgt.write(\"#####\\n\")\n",
    "fp_wgt_dec = open('Resnet_weight_dec.txt','w')\n",
    "\n",
    "for kij in range(9):\n",
    "    for w in range(8):\n",
    "        w_line = w_int[w,:,kij]\n",
    "        w_arr = []\n",
    "        for i in convert_to_list(w_line):\n",
    "            if i < 0:\n",
    "                w_arr.append(int(i-0.001))\n",
    "            else:\n",
    "                w_arr.append(int(i+0.001))\n",
    "        \n",
    "        for ww in w_arr[::-1]:\n",
    "            #print(int(ww))\n",
    "            fp_wgt_dec.write(str(int(ww)))\n",
    "            fp_wgt_dec.write(\" \")\n",
    "        fp_wgt_dec.write(\"\\n\")\n",
    "        bin_wgt = dec_to_bin(w_arr,16)\n",
    "        for b in bin_wgt[::-1]:\n",
    "            #print(\"Count = {} , b = {}\".format(count,b))\n",
    "            fp_wgt.write(b)\n",
    "        fp_wgt.write('\\n')\n",
    "\n",
    "fp_wgt.close()\n",
    "fp_wgt_dec.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "915168f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## psum dump and output.txt dump\n",
    "fp_psum = open('Resnet_psum_project.txt','w')\n",
    "fp_psum.write(\"#####\\n\")\n",
    "fp_psum.write(\"#####\\n\")\n",
    "fp_psum.write(\"#####\\n\")\n",
    "\n",
    "fp_psum_dec = open('Resnet_psum_dec.txt','w')\n",
    "fp_psum_relu = open('Resnet_output_project.txt','w')\n",
    "fp_psum_relu_dec = open('Resnet_output_project_dec.txt','w')\n",
    "fp_psum_relu.write(\"#\\n\")\n",
    "fp_psum_relu.write(\"#\\n\")\n",
    "fp_psum_relu.write(\"#\\n\")\n",
    "for kij in range(o_ni_dim*o_ni_dim):\n",
    "    psum_line = out_after_residual[:,kij]\n",
    "    psum_old = out[:,kij]\n",
    "    psum_arr = []\n",
    "    out_arr = []\n",
    "    for i in convert_to_list(psum_line):\n",
    "        if i < 0:\n",
    "            #psum_arr.append(int(i-0.001))\n",
    "            out_arr.append(0)\n",
    "        else:\n",
    "            #psum_arr.append(int(i+0.001))\n",
    "            out_arr.append(int(i+0.001))\n",
    "    for i in convert_to_list(psum_old):\n",
    "        if i < 0:\n",
    "            psum_arr.append(int(i-0.001))\n",
    "        else:\n",
    "            psum_arr.append(int(i+0.001))\n",
    "    for p in psum_arr:\n",
    "        #print(int(a))\n",
    "        fp_psum_dec.write(str(int(p)))\n",
    "        fp_psum_dec.write(\" \")\n",
    "    fp_psum_dec.write(\"\\n\")\n",
    "    \n",
    "    for p in out_arr:\n",
    "        fp_psum_relu_dec.write(str(int(p)))\n",
    "        fp_psum_relu_dec.write(\" \")\n",
    "    fp_psum_relu_dec.write('\\n')\n",
    "                               \n",
    "    bin_act = dec_to_bin_psum(psum_arr,65536)\n",
    "    out_bin_act = dec_to_bin_psum(out_arr,65536)\n",
    "    for b in bin_act:\n",
    "        #print(b)\n",
    "        fp_psum.write(b)\n",
    "    fp_psum.write('\\n')\n",
    "    \n",
    "    for b in out_bin_act:\n",
    "        fp_psum_relu.write(b)\n",
    "    fp_psum_relu.write(\"\\n\")\n",
    "fp_psum.close()\n",
    "fp_psum_dec.close()\n",
    "fp_psum_relu.close()\n",
    "fp_psum_relu_dec.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "655c3ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Residual file dump\n",
    "fp_act = open('Resnet_residual_project.txt','w')\n",
    "fp_act.write(\"#####\\n\")\n",
    "fp_act.write(\"#####\\n\")\n",
    "fp_act.write(\"#####\\n\")\n",
    "fp_act_dec = open('Resnet_residual_dec.txt','w')\n",
    "for i in range(o_ni_dim*o_ni_dim):\n",
    "    act_line = residual_reshaped[:,i]\n",
    "    act_arr = [int(j+0.001) for j in convert_to_list(act_line)]\n",
    "    for a in act_arr:\n",
    "        #print(int(a))\n",
    "        fp_act_dec.write(str(int(a)))\n",
    "        fp_act_dec.write(\" \")\n",
    "    fp_act_dec.write(\"\\n\")\n",
    "    bin_act = dec_to_bin(act_arr,16)\n",
    "    for b in bin_act:\n",
    "        #print(b)\n",
    "        fp_act.write(b)\n",
    "    fp_act.write('\\n')\n",
    "    \n",
    "\n",
    "fp_act.close()\n",
    "fp_act_dec.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712736d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For input activations tiling. Handled in testbench. Written here just for reference logic\n",
    "hardware_ni_dim = 6\n",
    "hor_step = hardware_ni_dim-kernel_dim+1 ## 4\n",
    "ver_step = (hardware_ni_dim-kernel_dim+1)*a_pad_ni_dim ## 136\n",
    "stop_point = (a_pad_ni_dim-hardware_ni_dim)*a_pad_ni_dim+1 ## 953\n",
    "group_count = 0\n",
    "act_arr = []\n",
    "## Vertical movement loop\n",
    "for v in range(0,stop_point,ver_step):\n",
    "    ## Now move horizontally\n",
    "    for h in range(v,v+34,hor_step):\n",
    "        if h+hardware_ni_dim>v+a_pad_ni_dim:\n",
    "            break\n",
    "        group = []\n",
    "        group_count+=1\n",
    "        for hh in range(h,h+(hardware_ni_dim)*a_pad_ni_dim,a_pad_ni_dim):\n",
    "            \n",
    "            for hhh in range(hardware_ni_dim):\n",
    "                group.append(hh+hhh)\n",
    "        act_group.append(group)       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185c9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For output tiling. Handled in testbench. Written here just for reference logic\n",
    "our_out_hw = 4\n",
    "out_ni_dim = int(math.sqrt(out.size(1)))\n",
    "out_stop_point = (out_ni_dim-our_out_hw)*out_ni_dim+1\n",
    "out_ver_step = our_out_hw*out_ni_dim\n",
    "group_count = 0\n",
    "out_group = []\n",
    "for v in range(0,out_stop_point,out_ver_step):\n",
    "    ## Now move horizontally\n",
    "    for h in range(v,v+32,our_out_hw):\n",
    "        group = []\n",
    "        group_count+=1\n",
    "        for hh in range(h,h+our_out_hw*out_ni_dim,out_ni_dim):\n",
    "            for hhh in range(our_out_hw):\n",
    "                group.append(hh+hhh)\n",
    "        out_group.append(group)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
