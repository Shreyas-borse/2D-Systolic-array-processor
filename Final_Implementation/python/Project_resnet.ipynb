{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec9a6dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "     \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\")\n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"Resnet_20_quant_project\"\n",
    "model = resnet20_quant_project()\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0a6f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_freq = 100\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch,adjust_list):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    \n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f40ee4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 0.697 (0.697)\tData 0.576 (0.576)\tLoss 2.6520 (2.6520)\tPrec 6.250% (6.250%)\n",
      "Epoch: [0][100/391]\tTime 0.039 (0.052)\tData 0.003 (0.008)\tLoss 1.9711 (2.0783)\tPrec 25.000% (21.744%)\n",
      "Epoch: [0][200/391]\tTime 0.041 (0.049)\tData 0.002 (0.005)\tLoss 1.8291 (1.9321)\tPrec 33.594% (27.433%)\n",
      "Epoch: [0][300/391]\tTime 0.046 (0.049)\tData 0.002 (0.004)\tLoss 1.6122 (1.8335)\tPrec 39.062% (31.364%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.585 (0.585)\tLoss 1.6914 (1.6914)\tPrec 35.938% (35.938%)\n",
      " * Prec 37.970% \n",
      "best acc: 37.970000\n",
      "Epoch: [1][0/391]\tTime 0.536 (0.536)\tData 0.479 (0.479)\tLoss 1.5299 (1.5299)\tPrec 44.531% (44.531%)\n",
      "Epoch: [1][100/391]\tTime 0.051 (0.052)\tData 0.002 (0.007)\tLoss 1.4429 (1.4517)\tPrec 47.656% (47.300%)\n",
      "Epoch: [1][200/391]\tTime 0.048 (0.049)\tData 0.002 (0.005)\tLoss 1.3430 (1.4097)\tPrec 48.438% (49.114%)\n",
      "Epoch: [1][300/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 1.1828 (1.3801)\tPrec 54.688% (50.016%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.441 (0.441)\tLoss 1.7276 (1.7276)\tPrec 49.219% (49.219%)\n",
      " * Prec 44.460% \n",
      "best acc: 44.460000\n",
      "Epoch: [2][0/391]\tTime 0.543 (0.543)\tData 0.481 (0.481)\tLoss 1.0911 (1.0911)\tPrec 60.156% (60.156%)\n",
      "Epoch: [2][100/391]\tTime 0.044 (0.050)\tData 0.002 (0.007)\tLoss 1.2717 (1.2106)\tPrec 53.906% (56.235%)\n",
      "Epoch: [2][200/391]\tTime 0.038 (0.048)\tData 0.002 (0.004)\tLoss 1.2264 (1.1977)\tPrec 50.781% (56.817%)\n",
      "Epoch: [2][300/391]\tTime 0.037 (0.047)\tData 0.002 (0.004)\tLoss 1.1645 (1.1675)\tPrec 59.375% (58.088%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.330 (0.330)\tLoss 1.4364 (1.4364)\tPrec 54.688% (54.688%)\n",
      " * Prec 56.720% \n",
      "best acc: 56.720000\n",
      "Epoch: [3][0/391]\tTime 0.712 (0.712)\tData 0.649 (0.649)\tLoss 1.1354 (1.1354)\tPrec 55.469% (55.469%)\n",
      "Epoch: [3][100/391]\tTime 0.042 (0.052)\tData 0.002 (0.009)\tLoss 1.0503 (1.0600)\tPrec 60.938% (62.175%)\n",
      "Epoch: [3][200/391]\tTime 0.044 (0.051)\tData 0.002 (0.005)\tLoss 1.0566 (1.0333)\tPrec 64.844% (63.122%)\n",
      "Epoch: [3][300/391]\tTime 0.051 (0.049)\tData 0.003 (0.004)\tLoss 0.8835 (1.0177)\tPrec 69.531% (63.899%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.394 (0.394)\tLoss 1.2359 (1.2359)\tPrec 52.344% (52.344%)\n",
      " * Prec 61.030% \n",
      "best acc: 61.030000\n",
      "Epoch: [4][0/391]\tTime 0.672 (0.672)\tData 0.612 (0.612)\tLoss 0.9447 (0.9447)\tPrec 71.875% (71.875%)\n",
      "Epoch: [4][100/391]\tTime 0.041 (0.050)\tData 0.002 (0.008)\tLoss 0.8651 (0.9116)\tPrec 71.875% (67.528%)\n",
      "Epoch: [4][200/391]\tTime 0.044 (0.048)\tData 0.002 (0.005)\tLoss 0.8039 (0.9043)\tPrec 75.781% (68.062%)\n",
      "Epoch: [4][300/391]\tTime 0.039 (0.048)\tData 0.002 (0.004)\tLoss 0.9637 (0.8946)\tPrec 67.188% (68.433%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.363 (0.363)\tLoss 0.9038 (0.9038)\tPrec 67.969% (67.969%)\n",
      " * Prec 67.010% \n",
      "best acc: 67.010000\n",
      "Epoch: [5][0/391]\tTime 0.545 (0.545)\tData 0.483 (0.483)\tLoss 0.8568 (0.8568)\tPrec 71.094% (71.094%)\n",
      "Epoch: [5][100/391]\tTime 0.045 (0.054)\tData 0.002 (0.007)\tLoss 0.8860 (0.8512)\tPrec 68.750% (70.498%)\n",
      "Epoch: [5][200/391]\tTime 0.045 (0.051)\tData 0.002 (0.005)\tLoss 0.8183 (0.8449)\tPrec 71.094% (70.460%)\n",
      "Epoch: [5][300/391]\tTime 0.040 (0.049)\tData 0.002 (0.004)\tLoss 0.8003 (0.8361)\tPrec 75.000% (70.720%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.327 (0.327)\tLoss 0.9208 (0.9208)\tPrec 61.719% (61.719%)\n",
      " * Prec 66.110% \n",
      "best acc: 67.010000\n",
      "Epoch: [6][0/391]\tTime 0.575 (0.575)\tData 0.517 (0.517)\tLoss 0.7186 (0.7186)\tPrec 79.688% (79.688%)\n",
      "Epoch: [6][100/391]\tTime 0.054 (0.053)\tData 0.003 (0.008)\tLoss 0.9389 (0.7764)\tPrec 68.750% (72.950%)\n",
      "Epoch: [6][200/391]\tTime 0.046 (0.050)\tData 0.002 (0.005)\tLoss 0.6818 (0.7733)\tPrec 72.656% (72.862%)\n",
      "Epoch: [6][300/391]\tTime 0.046 (0.049)\tData 0.002 (0.004)\tLoss 0.7320 (0.7697)\tPrec 71.875% (72.903%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.388 (0.388)\tLoss 0.9254 (0.9254)\tPrec 66.406% (66.406%)\n",
      " * Prec 70.240% \n",
      "best acc: 70.240000\n",
      "Epoch: [7][0/391]\tTime 0.841 (0.841)\tData 0.779 (0.779)\tLoss 0.6742 (0.6742)\tPrec 73.438% (73.438%)\n",
      "Epoch: [7][100/391]\tTime 0.059 (0.064)\tData 0.003 (0.010)\tLoss 0.6625 (0.7399)\tPrec 71.094% (74.025%)\n",
      "Epoch: [7][200/391]\tTime 0.044 (0.055)\tData 0.002 (0.006)\tLoss 0.6622 (0.7461)\tPrec 78.906% (73.842%)\n",
      "Epoch: [7][300/391]\tTime 0.043 (0.052)\tData 0.002 (0.005)\tLoss 0.7193 (0.7354)\tPrec 74.219% (74.255%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.279 (0.279)\tLoss 0.8234 (0.8234)\tPrec 72.656% (72.656%)\n",
      " * Prec 70.390% \n",
      "best acc: 70.390000\n",
      "Epoch: [8][0/391]\tTime 0.581 (0.581)\tData 0.523 (0.523)\tLoss 0.6751 (0.6751)\tPrec 75.000% (75.000%)\n",
      "Epoch: [8][100/391]\tTime 0.045 (0.053)\tData 0.002 (0.008)\tLoss 0.6582 (0.6747)\tPrec 73.438% (76.624%)\n",
      "Epoch: [8][200/391]\tTime 0.037 (0.048)\tData 0.002 (0.005)\tLoss 0.8347 (0.6898)\tPrec 70.312% (75.847%)\n",
      "Epoch: [8][300/391]\tTime 0.038 (0.044)\tData 0.001 (0.004)\tLoss 0.7509 (0.6847)\tPrec 75.000% (76.139%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.508 (0.508)\tLoss 0.5880 (0.5880)\tPrec 80.469% (80.469%)\n",
      " * Prec 74.010% \n",
      "best acc: 74.010000\n",
      "Epoch: [9][0/391]\tTime 0.636 (0.636)\tData 0.578 (0.578)\tLoss 0.6594 (0.6594)\tPrec 75.781% (75.781%)\n",
      "Epoch: [9][100/391]\tTime 0.049 (0.055)\tData 0.002 (0.008)\tLoss 0.8528 (0.6613)\tPrec 67.969% (76.756%)\n",
      "Epoch: [9][200/391]\tTime 0.041 (0.050)\tData 0.002 (0.005)\tLoss 0.6358 (0.6621)\tPrec 79.688% (76.850%)\n",
      "Epoch: [9][300/391]\tTime 0.043 (0.048)\tData 0.002 (0.004)\tLoss 0.5533 (0.6616)\tPrec 81.250% (76.877%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.433 (0.433)\tLoss 0.7407 (0.7407)\tPrec 74.219% (74.219%)\n",
      " * Prec 75.570% \n",
      "best acc: 75.570000\n",
      "Epoch: [10][0/391]\tTime 0.525 (0.525)\tData 0.469 (0.469)\tLoss 0.7799 (0.7799)\tPrec 72.656% (72.656%)\n",
      "Epoch: [10][100/391]\tTime 0.053 (0.053)\tData 0.003 (0.007)\tLoss 0.5645 (0.6187)\tPrec 80.469% (78.605%)\n",
      "Epoch: [10][200/391]\tTime 0.047 (0.050)\tData 0.002 (0.005)\tLoss 0.6457 (0.6184)\tPrec 78.125% (78.607%)\n",
      "Epoch: [10][300/391]\tTime 0.046 (0.049)\tData 0.002 (0.004)\tLoss 0.7006 (0.6287)\tPrec 71.875% (78.198%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.510 (0.510)\tLoss 0.7054 (0.7054)\tPrec 75.000% (75.000%)\n",
      " * Prec 76.940% \n",
      "best acc: 76.940000\n",
      "Epoch: [11][0/391]\tTime 0.542 (0.542)\tData 0.488 (0.488)\tLoss 0.7296 (0.7296)\tPrec 75.781% (75.781%)\n",
      "Epoch: [11][100/391]\tTime 0.045 (0.052)\tData 0.002 (0.007)\tLoss 0.4605 (0.6202)\tPrec 80.469% (78.055%)\n",
      "Epoch: [11][200/391]\tTime 0.038 (0.050)\tData 0.002 (0.005)\tLoss 0.6396 (0.6130)\tPrec 79.688% (78.537%)\n",
      "Epoch: [11][300/391]\tTime 0.044 (0.050)\tData 0.002 (0.004)\tLoss 0.5929 (0.6107)\tPrec 79.688% (78.673%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.380 (0.380)\tLoss 0.6441 (0.6441)\tPrec 78.125% (78.125%)\n",
      " * Prec 76.600% \n",
      "best acc: 76.940000\n",
      "Epoch: [12][0/391]\tTime 0.558 (0.558)\tData 0.498 (0.498)\tLoss 0.4537 (0.4537)\tPrec 83.594% (83.594%)\n",
      "Epoch: [12][100/391]\tTime 0.038 (0.049)\tData 0.002 (0.007)\tLoss 0.5921 (0.6042)\tPrec 78.906% (78.999%)\n",
      "Epoch: [12][200/391]\tTime 0.041 (0.047)\tData 0.002 (0.005)\tLoss 0.5482 (0.6017)\tPrec 82.812% (79.050%)\n",
      "Epoch: [12][300/391]\tTime 0.037 (0.047)\tData 0.002 (0.004)\tLoss 0.5295 (0.6046)\tPrec 86.719% (78.935%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.515 (0.515)\tLoss 0.5531 (0.5531)\tPrec 80.469% (80.469%)\n",
      " * Prec 77.480% \n",
      "best acc: 77.480000\n",
      "Epoch: [13][0/391]\tTime 0.718 (0.718)\tData 0.676 (0.676)\tLoss 0.5952 (0.5952)\tPrec 78.906% (78.906%)\n",
      "Epoch: [13][100/391]\tTime 0.040 (0.052)\tData 0.002 (0.009)\tLoss 0.6260 (0.5625)\tPrec 79.688% (80.229%)\n",
      "Epoch: [13][200/391]\tTime 0.041 (0.049)\tData 0.002 (0.006)\tLoss 0.4157 (0.5660)\tPrec 85.156% (80.263%)\n",
      "Epoch: [13][300/391]\tTime 0.046 (0.048)\tData 0.002 (0.004)\tLoss 0.4446 (0.5713)\tPrec 86.719% (80.137%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.297 (0.297)\tLoss 0.6328 (0.6328)\tPrec 78.125% (78.125%)\n",
      " * Prec 77.710% \n",
      "best acc: 77.710000\n",
      "Epoch: [14][0/391]\tTime 0.823 (0.823)\tData 0.778 (0.778)\tLoss 0.4488 (0.4488)\tPrec 88.281% (88.281%)\n",
      "Epoch: [14][100/391]\tTime 0.050 (0.055)\tData 0.003 (0.010)\tLoss 0.4761 (0.5541)\tPrec 81.250% (80.894%)\n",
      "Epoch: [14][200/391]\tTime 0.036 (0.052)\tData 0.002 (0.006)\tLoss 0.5584 (0.5569)\tPrec 83.594% (80.690%)\n",
      "Epoch: [14][300/391]\tTime 0.037 (0.050)\tData 0.002 (0.005)\tLoss 0.5966 (0.5561)\tPrec 79.688% (80.741%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.424 (0.424)\tLoss 0.5909 (0.5909)\tPrec 82.031% (82.031%)\n",
      " * Prec 77.640% \n",
      "best acc: 77.710000\n",
      "Epoch: [15][0/391]\tTime 0.522 (0.522)\tData 0.466 (0.466)\tLoss 0.5186 (0.5186)\tPrec 82.031% (82.031%)\n",
      "Epoch: [15][100/391]\tTime 0.043 (0.048)\tData 0.002 (0.007)\tLoss 0.6145 (0.5471)\tPrec 78.906% (81.134%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][200/391]\tTime 0.052 (0.048)\tData 0.002 (0.005)\tLoss 0.5816 (0.5466)\tPrec 82.031% (80.889%)\n",
      "Epoch: [15][300/391]\tTime 0.050 (0.048)\tData 0.003 (0.004)\tLoss 0.4391 (0.5470)\tPrec 83.594% (80.824%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.796 (0.796)\tLoss 0.5999 (0.5999)\tPrec 77.344% (77.344%)\n",
      " * Prec 78.220% \n",
      "best acc: 78.220000\n",
      "Epoch: [16][0/391]\tTime 0.641 (0.641)\tData 0.595 (0.595)\tLoss 0.4703 (0.4703)\tPrec 84.375% (84.375%)\n",
      "Epoch: [16][100/391]\tTime 0.056 (0.053)\tData 0.003 (0.008)\tLoss 0.5447 (0.5199)\tPrec 78.906% (81.877%)\n",
      "Epoch: [16][200/391]\tTime 0.045 (0.051)\tData 0.002 (0.005)\tLoss 0.6851 (0.5185)\tPrec 75.000% (82.027%)\n",
      "Epoch: [16][300/391]\tTime 0.044 (0.049)\tData 0.002 (0.004)\tLoss 0.5540 (0.5217)\tPrec 80.469% (81.842%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.245 (0.245)\tLoss 0.6395 (0.6395)\tPrec 74.219% (74.219%)\n",
      " * Prec 75.680% \n",
      "best acc: 78.220000\n",
      "Epoch: [17][0/391]\tTime 0.591 (0.591)\tData 0.527 (0.527)\tLoss 0.5065 (0.5065)\tPrec 83.594% (83.594%)\n",
      "Epoch: [17][100/391]\tTime 0.046 (0.053)\tData 0.002 (0.008)\tLoss 0.4520 (0.5143)\tPrec 82.812% (82.047%)\n",
      "Epoch: [17][200/391]\tTime 0.041 (0.049)\tData 0.002 (0.005)\tLoss 0.4913 (0.5076)\tPrec 82.812% (82.264%)\n",
      "Epoch: [17][300/391]\tTime 0.037 (0.048)\tData 0.002 (0.004)\tLoss 0.5568 (0.5103)\tPrec 82.812% (82.192%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.393 (0.393)\tLoss 0.4998 (0.4998)\tPrec 83.594% (83.594%)\n",
      " * Prec 79.220% \n",
      "best acc: 79.220000\n",
      "Epoch: [18][0/391]\tTime 0.578 (0.578)\tData 0.519 (0.519)\tLoss 0.4343 (0.4343)\tPrec 84.375% (84.375%)\n",
      "Epoch: [18][100/391]\tTime 0.044 (0.052)\tData 0.002 (0.007)\tLoss 0.4590 (0.5145)\tPrec 83.594% (81.745%)\n",
      "Epoch: [18][200/391]\tTime 0.036 (0.049)\tData 0.002 (0.005)\tLoss 0.5646 (0.5052)\tPrec 81.250% (82.257%)\n",
      "Epoch: [18][300/391]\tTime 0.047 (0.049)\tData 0.002 (0.004)\tLoss 0.4629 (0.5072)\tPrec 81.250% (82.229%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.300 (0.300)\tLoss 0.6272 (0.6272)\tPrec 77.344% (77.344%)\n",
      " * Prec 75.850% \n",
      "best acc: 79.220000\n",
      "Epoch: [19][0/391]\tTime 0.556 (0.556)\tData 0.493 (0.493)\tLoss 0.4065 (0.4065)\tPrec 87.500% (87.500%)\n",
      "Epoch: [19][100/391]\tTime 0.044 (0.051)\tData 0.002 (0.007)\tLoss 0.3701 (0.4789)\tPrec 89.844% (82.836%)\n",
      "Epoch: [19][200/391]\tTime 0.044 (0.048)\tData 0.002 (0.005)\tLoss 0.5877 (0.4934)\tPrec 78.906% (82.548%)\n",
      "Epoch: [19][300/391]\tTime 0.051 (0.048)\tData 0.003 (0.004)\tLoss 0.5256 (0.4953)\tPrec 78.906% (82.581%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.303 (0.303)\tLoss 0.4849 (0.4849)\tPrec 84.375% (84.375%)\n",
      " * Prec 78.130% \n",
      "best acc: 79.220000\n",
      "Epoch: [20][0/391]\tTime 0.598 (0.598)\tData 0.539 (0.539)\tLoss 0.3695 (0.3695)\tPrec 87.500% (87.500%)\n",
      "Epoch: [20][100/391]\tTime 0.048 (0.053)\tData 0.003 (0.008)\tLoss 0.6348 (0.4707)\tPrec 78.125% (83.377%)\n",
      "Epoch: [20][200/391]\tTime 0.043 (0.051)\tData 0.002 (0.005)\tLoss 0.4748 (0.4767)\tPrec 84.375% (83.326%)\n",
      "Epoch: [20][300/391]\tTime 0.045 (0.049)\tData 0.002 (0.004)\tLoss 0.3608 (0.4834)\tPrec 87.500% (83.140%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.339 (0.339)\tLoss 0.4761 (0.4761)\tPrec 82.812% (82.812%)\n",
      " * Prec 80.920% \n",
      "best acc: 80.920000\n",
      "Epoch: [21][0/391]\tTime 0.664 (0.664)\tData 0.600 (0.600)\tLoss 0.3877 (0.3877)\tPrec 85.938% (85.938%)\n",
      "Epoch: [21][100/391]\tTime 0.045 (0.055)\tData 0.002 (0.008)\tLoss 0.3209 (0.4577)\tPrec 86.719% (83.973%)\n",
      "Epoch: [21][200/391]\tTime 0.054 (0.051)\tData 0.003 (0.005)\tLoss 0.4491 (0.4715)\tPrec 83.594% (83.570%)\n",
      "Epoch: [21][300/391]\tTime 0.048 (0.049)\tData 0.002 (0.004)\tLoss 0.6024 (0.4772)\tPrec 79.688% (83.498%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.461 (0.461)\tLoss 0.4941 (0.4941)\tPrec 81.250% (81.250%)\n",
      " * Prec 80.150% \n",
      "best acc: 80.920000\n",
      "Epoch: [22][0/391]\tTime 0.690 (0.690)\tData 0.630 (0.630)\tLoss 0.3934 (0.3934)\tPrec 87.500% (87.500%)\n",
      "Epoch: [22][100/391]\tTime 0.043 (0.054)\tData 0.002 (0.008)\tLoss 0.4671 (0.4538)\tPrec 82.812% (84.205%)\n",
      "Epoch: [22][200/391]\tTime 0.051 (0.050)\tData 0.003 (0.005)\tLoss 0.4217 (0.4621)\tPrec 85.156% (83.874%)\n",
      "Epoch: [22][300/391]\tTime 0.043 (0.049)\tData 0.002 (0.004)\tLoss 0.5122 (0.4648)\tPrec 78.906% (83.770%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.457 (0.457)\tLoss 0.5885 (0.5885)\tPrec 77.344% (77.344%)\n",
      " * Prec 80.000% \n",
      "best acc: 80.920000\n",
      "Epoch: [23][0/391]\tTime 0.732 (0.732)\tData 0.677 (0.677)\tLoss 0.4861 (0.4861)\tPrec 82.812% (82.812%)\n",
      "Epoch: [23][100/391]\tTime 0.042 (0.055)\tData 0.002 (0.009)\tLoss 0.4643 (0.4410)\tPrec 83.594% (84.499%)\n",
      "Epoch: [23][200/391]\tTime 0.047 (0.049)\tData 0.002 (0.006)\tLoss 0.4364 (0.4451)\tPrec 84.375% (84.519%)\n",
      "Epoch: [23][300/391]\tTime 0.059 (0.049)\tData 0.003 (0.004)\tLoss 0.4405 (0.4481)\tPrec 82.031% (84.476%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.500 (0.500)\tLoss 0.5932 (0.5932)\tPrec 78.125% (78.125%)\n",
      " * Prec 79.530% \n",
      "best acc: 80.920000\n",
      "Epoch: [24][0/391]\tTime 1.098 (1.098)\tData 1.047 (1.047)\tLoss 0.5728 (0.5728)\tPrec 80.469% (80.469%)\n",
      "Epoch: [24][100/391]\tTime 0.048 (0.057)\tData 0.002 (0.013)\tLoss 0.4823 (0.4450)\tPrec 79.688% (84.506%)\n",
      "Epoch: [24][200/391]\tTime 0.044 (0.051)\tData 0.002 (0.008)\tLoss 0.4105 (0.4504)\tPrec 87.500% (84.274%)\n",
      "Epoch: [24][300/391]\tTime 0.045 (0.049)\tData 0.002 (0.006)\tLoss 0.5537 (0.4507)\tPrec 79.688% (84.359%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.686 (0.686)\tLoss 0.5138 (0.5138)\tPrec 84.375% (84.375%)\n",
      " * Prec 81.550% \n",
      "best acc: 81.550000\n",
      "Epoch: [25][0/391]\tTime 0.702 (0.702)\tData 0.637 (0.637)\tLoss 0.5204 (0.5204)\tPrec 83.594% (83.594%)\n",
      "Epoch: [25][100/391]\tTime 0.040 (0.053)\tData 0.002 (0.009)\tLoss 0.4542 (0.4283)\tPrec 81.250% (85.110%)\n",
      "Epoch: [25][200/391]\tTime 0.044 (0.050)\tData 0.002 (0.005)\tLoss 0.5575 (0.4313)\tPrec 84.375% (84.880%)\n",
      "Epoch: [25][300/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 0.5234 (0.4353)\tPrec 79.688% (84.749%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.493 (0.493)\tLoss 0.3820 (0.3820)\tPrec 88.281% (88.281%)\n",
      " * Prec 81.840% \n",
      "best acc: 81.840000\n",
      "Epoch: [26][0/391]\tTime 0.521 (0.521)\tData 0.463 (0.463)\tLoss 0.5043 (0.5043)\tPrec 82.812% (82.812%)\n",
      "Epoch: [26][100/391]\tTime 0.054 (0.053)\tData 0.003 (0.007)\tLoss 0.5119 (0.4258)\tPrec 84.375% (85.636%)\n",
      "Epoch: [26][200/391]\tTime 0.044 (0.050)\tData 0.002 (0.005)\tLoss 0.4541 (0.4238)\tPrec 86.719% (85.452%)\n",
      "Epoch: [26][300/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 0.3604 (0.4279)\tPrec 88.281% (85.182%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.352 (0.352)\tLoss 0.4834 (0.4834)\tPrec 82.031% (82.031%)\n",
      " * Prec 80.690% \n",
      "best acc: 81.840000\n",
      "Epoch: [27][0/391]\tTime 0.617 (0.617)\tData 0.560 (0.560)\tLoss 0.3419 (0.3419)\tPrec 87.500% (87.500%)\n",
      "Epoch: [27][100/391]\tTime 0.041 (0.051)\tData 0.002 (0.008)\tLoss 0.4454 (0.4071)\tPrec 82.812% (85.721%)\n",
      "Epoch: [27][200/391]\tTime 0.054 (0.049)\tData 0.003 (0.005)\tLoss 0.3638 (0.4272)\tPrec 87.500% (85.110%)\n",
      "Epoch: [27][300/391]\tTime 0.037 (0.048)\tData 0.002 (0.004)\tLoss 0.3775 (0.4319)\tPrec 86.719% (85.016%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.404 (0.404)\tLoss 0.4090 (0.4090)\tPrec 83.594% (83.594%)\n",
      " * Prec 81.530% \n",
      "best acc: 81.840000\n",
      "Epoch: [28][0/391]\tTime 0.594 (0.594)\tData 0.518 (0.518)\tLoss 0.3874 (0.3874)\tPrec 85.938% (85.938%)\n",
      "Epoch: [28][100/391]\tTime 0.047 (0.052)\tData 0.002 (0.007)\tLoss 0.4825 (0.4379)\tPrec 84.375% (84.847%)\n",
      "Epoch: [28][200/391]\tTime 0.037 (0.048)\tData 0.002 (0.005)\tLoss 0.3985 (0.4287)\tPrec 87.500% (85.016%)\n",
      "Epoch: [28][300/391]\tTime 0.047 (0.048)\tData 0.003 (0.004)\tLoss 0.5825 (0.4278)\tPrec 82.031% (85.058%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.345 (0.345)\tLoss 0.4670 (0.4670)\tPrec 85.156% (85.156%)\n",
      " * Prec 80.550% \n",
      "best acc: 81.840000\n",
      "Epoch: [29][0/391]\tTime 0.513 (0.513)\tData 0.458 (0.458)\tLoss 0.3137 (0.3137)\tPrec 87.500% (87.500%)\n",
      "Epoch: [29][100/391]\tTime 0.046 (0.050)\tData 0.003 (0.007)\tLoss 0.3582 (0.4082)\tPrec 88.281% (85.907%)\n",
      "Epoch: [29][200/391]\tTime 0.043 (0.049)\tData 0.002 (0.005)\tLoss 0.4982 (0.4115)\tPrec 82.031% (85.821%)\n",
      "Epoch: [29][300/391]\tTime 0.051 (0.049)\tData 0.002 (0.004)\tLoss 0.2727 (0.4101)\tPrec 91.406% (85.841%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.424 (0.424)\tLoss 0.4923 (0.4923)\tPrec 82.031% (82.031%)\n",
      " * Prec 81.490% \n",
      "best acc: 81.840000\n",
      "Epoch: [30][0/391]\tTime 0.955 (0.955)\tData 0.900 (0.900)\tLoss 0.5181 (0.5181)\tPrec 84.375% (84.375%)\n",
      "Epoch: [30][100/391]\tTime 0.044 (0.056)\tData 0.002 (0.011)\tLoss 0.4475 (0.4050)\tPrec 83.594% (85.930%)\n",
      "Epoch: [30][200/391]\tTime 0.037 (0.050)\tData 0.003 (0.007)\tLoss 0.5510 (0.4109)\tPrec 81.250% (85.557%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30][300/391]\tTime 0.046 (0.048)\tData 0.002 (0.005)\tLoss 0.4876 (0.4106)\tPrec 80.469% (85.670%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.339 (0.339)\tLoss 0.4842 (0.4842)\tPrec 82.031% (82.031%)\n",
      " * Prec 82.590% \n",
      "best acc: 82.590000\n",
      "Epoch: [31][0/391]\tTime 1.075 (1.075)\tData 1.026 (1.026)\tLoss 0.3488 (0.3488)\tPrec 90.625% (90.625%)\n",
      "Epoch: [31][100/391]\tTime 0.045 (0.059)\tData 0.002 (0.012)\tLoss 0.3139 (0.3979)\tPrec 88.281% (86.123%)\n",
      "Epoch: [31][200/391]\tTime 0.034 (0.053)\tData 0.002 (0.007)\tLoss 0.4960 (0.3981)\tPrec 82.031% (86.023%)\n",
      "Epoch: [31][300/391]\tTime 0.037 (0.048)\tData 0.001 (0.005)\tLoss 0.3585 (0.4020)\tPrec 85.156% (85.922%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.384 (0.384)\tLoss 0.4215 (0.4215)\tPrec 87.500% (87.500%)\n",
      " * Prec 79.750% \n",
      "best acc: 82.590000\n",
      "Epoch: [32][0/391]\tTime 0.957 (0.957)\tData 0.914 (0.914)\tLoss 0.3458 (0.3458)\tPrec 85.938% (85.938%)\n",
      "Epoch: [32][100/391]\tTime 0.043 (0.056)\tData 0.002 (0.011)\tLoss 0.5772 (0.4068)\tPrec 77.344% (85.953%)\n",
      "Epoch: [32][200/391]\tTime 0.045 (0.050)\tData 0.002 (0.007)\tLoss 0.4162 (0.4055)\tPrec 85.156% (85.875%)\n",
      "Epoch: [32][300/391]\tTime 0.044 (0.049)\tData 0.002 (0.005)\tLoss 0.4506 (0.4080)\tPrec 85.156% (85.870%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.349 (0.349)\tLoss 0.5196 (0.5196)\tPrec 82.812% (82.812%)\n",
      " * Prec 80.170% \n",
      "best acc: 82.590000\n",
      "Epoch: [33][0/391]\tTime 0.904 (0.904)\tData 0.850 (0.850)\tLoss 0.3991 (0.3991)\tPrec 84.375% (84.375%)\n",
      "Epoch: [33][100/391]\tTime 0.044 (0.054)\tData 0.002 (0.011)\tLoss 0.4365 (0.3985)\tPrec 85.156% (85.721%)\n",
      "Epoch: [33][200/391]\tTime 0.047 (0.050)\tData 0.002 (0.006)\tLoss 0.4893 (0.3984)\tPrec 84.375% (85.914%)\n",
      "Epoch: [33][300/391]\tTime 0.046 (0.049)\tData 0.002 (0.005)\tLoss 0.4493 (0.3973)\tPrec 86.719% (86.010%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.642 (0.642)\tLoss 0.4456 (0.4456)\tPrec 83.594% (83.594%)\n",
      " * Prec 82.210% \n",
      "best acc: 82.590000\n",
      "Epoch: [34][0/391]\tTime 0.410 (0.410)\tData 0.337 (0.337)\tLoss 0.4469 (0.4469)\tPrec 82.812% (82.812%)\n",
      "Epoch: [34][100/391]\tTime 0.052 (0.049)\tData 0.003 (0.005)\tLoss 0.2801 (0.3969)\tPrec 92.969% (86.046%)\n",
      "Epoch: [34][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.3937 (0.3940)\tPrec 86.719% (86.217%)\n",
      "Epoch: [34][300/391]\tTime 0.040 (0.047)\tData 0.002 (0.003)\tLoss 0.2769 (0.4020)\tPrec 90.625% (86.065%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.343 (0.343)\tLoss 0.4738 (0.4738)\tPrec 84.375% (84.375%)\n",
      " * Prec 80.660% \n",
      "best acc: 82.590000\n",
      "Epoch: [35][0/391]\tTime 0.675 (0.675)\tData 0.618 (0.618)\tLoss 0.3364 (0.3364)\tPrec 88.281% (88.281%)\n",
      "Epoch: [35][100/391]\tTime 0.052 (0.053)\tData 0.002 (0.008)\tLoss 0.3882 (0.3863)\tPrec 87.500% (86.603%)\n",
      "Epoch: [35][200/391]\tTime 0.049 (0.050)\tData 0.002 (0.005)\tLoss 0.3743 (0.3901)\tPrec 85.938% (86.447%)\n",
      "Epoch: [35][300/391]\tTime 0.038 (0.049)\tData 0.002 (0.004)\tLoss 0.5369 (0.3928)\tPrec 82.031% (86.358%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.635 (0.635)\tLoss 0.4625 (0.4625)\tPrec 84.375% (84.375%)\n",
      " * Prec 81.350% \n",
      "best acc: 82.590000\n",
      "Epoch: [36][0/391]\tTime 0.711 (0.711)\tData 0.650 (0.650)\tLoss 0.4067 (0.4067)\tPrec 82.812% (82.812%)\n",
      "Epoch: [36][100/391]\tTime 0.039 (0.054)\tData 0.002 (0.009)\tLoss 0.3652 (0.3816)\tPrec 85.156% (86.726%)\n",
      "Epoch: [36][200/391]\tTime 0.039 (0.050)\tData 0.002 (0.006)\tLoss 0.3161 (0.3817)\tPrec 89.062% (86.614%)\n",
      "Epoch: [36][300/391]\tTime 0.057 (0.049)\tData 0.003 (0.004)\tLoss 0.4354 (0.3825)\tPrec 83.594% (86.682%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.461 (0.461)\tLoss 0.5018 (0.5018)\tPrec 85.938% (85.938%)\n",
      " * Prec 83.090% \n",
      "best acc: 83.090000\n",
      "Epoch: [37][0/391]\tTime 0.804 (0.804)\tData 0.742 (0.742)\tLoss 0.3576 (0.3576)\tPrec 85.156% (85.156%)\n",
      "Epoch: [37][100/391]\tTime 0.047 (0.053)\tData 0.002 (0.010)\tLoss 0.5126 (0.3673)\tPrec 81.250% (87.090%)\n",
      "Epoch: [37][200/391]\tTime 0.046 (0.051)\tData 0.002 (0.006)\tLoss 0.3991 (0.3775)\tPrec 86.719% (86.855%)\n",
      "Epoch: [37][300/391]\tTime 0.047 (0.050)\tData 0.003 (0.005)\tLoss 0.3494 (0.3806)\tPrec 89.844% (86.698%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.390 (0.390)\tLoss 0.3730 (0.3730)\tPrec 88.281% (88.281%)\n",
      " * Prec 81.890% \n",
      "best acc: 83.090000\n",
      "Epoch: [38][0/391]\tTime 0.690 (0.690)\tData 0.631 (0.631)\tLoss 0.3630 (0.3630)\tPrec 83.594% (83.594%)\n",
      "Epoch: [38][100/391]\tTime 0.042 (0.052)\tData 0.002 (0.008)\tLoss 0.3859 (0.3644)\tPrec 86.719% (86.904%)\n",
      "Epoch: [38][200/391]\tTime 0.043 (0.049)\tData 0.002 (0.005)\tLoss 0.3925 (0.3653)\tPrec 85.156% (87.026%)\n",
      "Epoch: [38][300/391]\tTime 0.048 (0.049)\tData 0.002 (0.004)\tLoss 0.4904 (0.3755)\tPrec 85.938% (86.789%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.353 (0.353)\tLoss 0.5509 (0.5509)\tPrec 81.250% (81.250%)\n",
      " * Prec 82.010% \n",
      "best acc: 83.090000\n",
      "Epoch: [39][0/391]\tTime 0.514 (0.514)\tData 0.460 (0.460)\tLoss 0.4188 (0.4188)\tPrec 84.375% (84.375%)\n",
      "Epoch: [39][100/391]\tTime 0.039 (0.051)\tData 0.002 (0.007)\tLoss 0.3090 (0.3664)\tPrec 87.500% (87.252%)\n",
      "Epoch: [39][200/391]\tTime 0.054 (0.049)\tData 0.003 (0.005)\tLoss 0.3678 (0.3673)\tPrec 89.844% (87.255%)\n",
      "Epoch: [39][300/391]\tTime 0.044 (0.049)\tData 0.002 (0.004)\tLoss 0.3333 (0.3716)\tPrec 89.844% (87.095%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.516 (0.516)\tLoss 0.4395 (0.4395)\tPrec 85.938% (85.938%)\n",
      " * Prec 82.980% \n",
      "best acc: 83.090000\n",
      "Epoch: [40][0/391]\tTime 0.537 (0.537)\tData 0.479 (0.479)\tLoss 0.2937 (0.2937)\tPrec 90.625% (90.625%)\n",
      "Epoch: [40][100/391]\tTime 0.044 (0.050)\tData 0.002 (0.007)\tLoss 0.3555 (0.3718)\tPrec 86.719% (87.430%)\n",
      "Epoch: [40][200/391]\tTime 0.039 (0.049)\tData 0.002 (0.005)\tLoss 0.3408 (0.3743)\tPrec 88.281% (87.057%)\n",
      "Epoch: [40][300/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 0.3529 (0.3723)\tPrec 86.719% (87.142%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.619 (0.619)\tLoss 0.3183 (0.3183)\tPrec 89.844% (89.844%)\n",
      " * Prec 84.470% \n",
      "best acc: 84.470000\n",
      "Epoch: [41][0/391]\tTime 0.603 (0.603)\tData 0.507 (0.507)\tLoss 0.3871 (0.3871)\tPrec 86.719% (86.719%)\n",
      "Epoch: [41][100/391]\tTime 0.050 (0.052)\tData 0.003 (0.007)\tLoss 0.3077 (0.3632)\tPrec 86.719% (87.222%)\n",
      "Epoch: [41][200/391]\tTime 0.037 (0.049)\tData 0.002 (0.005)\tLoss 0.4430 (0.3643)\tPrec 85.938% (87.158%)\n",
      "Epoch: [41][300/391]\tTime 0.048 (0.048)\tData 0.002 (0.004)\tLoss 0.3366 (0.3700)\tPrec 88.281% (86.996%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.404 (0.404)\tLoss 0.5803 (0.5803)\tPrec 81.250% (81.250%)\n",
      " * Prec 81.140% \n",
      "best acc: 84.470000\n",
      "Epoch: [42][0/391]\tTime 0.773 (0.773)\tData 0.716 (0.716)\tLoss 0.4345 (0.4345)\tPrec 82.812% (82.812%)\n",
      "Epoch: [42][100/391]\tTime 0.049 (0.053)\tData 0.003 (0.009)\tLoss 0.3845 (0.3715)\tPrec 86.719% (87.098%)\n",
      "Epoch: [42][200/391]\tTime 0.041 (0.048)\tData 0.002 (0.006)\tLoss 0.3604 (0.3627)\tPrec 88.281% (87.376%)\n",
      "Epoch: [42][300/391]\tTime 0.040 (0.047)\tData 0.002 (0.004)\tLoss 0.4031 (0.3616)\tPrec 85.156% (87.373%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.253 (0.253)\tLoss 0.2920 (0.2920)\tPrec 89.062% (89.062%)\n",
      " * Prec 83.490% \n",
      "best acc: 84.470000\n",
      "Epoch: [43][0/391]\tTime 0.532 (0.532)\tData 0.472 (0.472)\tLoss 0.4248 (0.4248)\tPrec 83.594% (83.594%)\n",
      "Epoch: [43][100/391]\tTime 0.044 (0.049)\tData 0.002 (0.007)\tLoss 0.2562 (0.3523)\tPrec 91.406% (87.469%)\n",
      "Epoch: [43][200/391]\tTime 0.059 (0.047)\tData 0.003 (0.005)\tLoss 0.4075 (0.3552)\tPrec 84.375% (87.356%)\n",
      "Epoch: [43][300/391]\tTime 0.050 (0.047)\tData 0.002 (0.004)\tLoss 0.3064 (0.3583)\tPrec 89.062% (87.324%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.621 (0.621)\tLoss 0.4258 (0.4258)\tPrec 87.500% (87.500%)\n",
      " * Prec 82.130% \n",
      "best acc: 84.470000\n",
      "Epoch: [44][0/391]\tTime 0.880 (0.880)\tData 0.823 (0.823)\tLoss 0.3316 (0.3316)\tPrec 86.719% (86.719%)\n",
      "Epoch: [44][100/391]\tTime 0.043 (0.056)\tData 0.002 (0.010)\tLoss 0.4665 (0.3344)\tPrec 83.594% (88.359%)\n",
      "Epoch: [44][200/391]\tTime 0.046 (0.050)\tData 0.002 (0.006)\tLoss 0.3048 (0.3454)\tPrec 90.625% (87.947%)\n",
      "Epoch: [44][300/391]\tTime 0.047 (0.049)\tData 0.002 (0.005)\tLoss 0.4379 (0.3484)\tPrec 82.031% (87.739%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.633 (0.633)\tLoss 0.4757 (0.4757)\tPrec 85.938% (85.938%)\n",
      " * Prec 83.240% \n",
      "best acc: 84.470000\n",
      "Epoch: [45][0/391]\tTime 0.637 (0.637)\tData 0.579 (0.579)\tLoss 0.1772 (0.1772)\tPrec 93.750% (93.750%)\n",
      "Epoch: [45][100/391]\tTime 0.046 (0.052)\tData 0.002 (0.008)\tLoss 0.3743 (0.3334)\tPrec 85.938% (88.150%)\n",
      "Epoch: [45][200/391]\tTime 0.048 (0.050)\tData 0.002 (0.005)\tLoss 0.2952 (0.3431)\tPrec 89.844% (87.803%)\n",
      "Epoch: [45][300/391]\tTime 0.046 (0.048)\tData 0.002 (0.004)\tLoss 0.4560 (0.3523)\tPrec 85.938% (87.503%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation starts\n",
      "Test: [0/79]\tTime 0.528 (0.528)\tLoss 0.4761 (0.4761)\tPrec 85.156% (85.156%)\n",
      " * Prec 83.370% \n",
      "best acc: 84.470000\n",
      "Epoch: [46][0/391]\tTime 0.860 (0.860)\tData 0.799 (0.799)\tLoss 0.3677 (0.3677)\tPrec 87.500% (87.500%)\n",
      "Epoch: [46][100/391]\tTime 0.049 (0.056)\tData 0.002 (0.010)\tLoss 0.4591 (0.3518)\tPrec 83.594% (87.438%)\n",
      "Epoch: [46][200/391]\tTime 0.046 (0.051)\tData 0.002 (0.006)\tLoss 0.4097 (0.3537)\tPrec 86.719% (87.352%)\n",
      "Epoch: [46][300/391]\tTime 0.052 (0.049)\tData 0.002 (0.005)\tLoss 0.3269 (0.3565)\tPrec 89.844% (87.344%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.522 (0.522)\tLoss 0.4968 (0.4968)\tPrec 82.031% (82.031%)\n",
      " * Prec 80.740% \n",
      "best acc: 84.470000\n",
      "Epoch: [47][0/391]\tTime 0.603 (0.603)\tData 0.521 (0.521)\tLoss 0.3529 (0.3529)\tPrec 87.500% (87.500%)\n",
      "Epoch: [47][100/391]\tTime 0.052 (0.053)\tData 0.003 (0.007)\tLoss 0.3608 (0.3433)\tPrec 89.062% (87.871%)\n",
      "Epoch: [47][200/391]\tTime 0.046 (0.052)\tData 0.003 (0.005)\tLoss 0.3699 (0.3537)\tPrec 82.812% (87.395%)\n",
      "Epoch: [47][300/391]\tTime 0.060 (0.051)\tData 0.003 (0.004)\tLoss 0.2322 (0.3543)\tPrec 92.969% (87.440%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.592 (0.592)\tLoss 0.4180 (0.4180)\tPrec 85.938% (85.938%)\n",
      " * Prec 83.870% \n",
      "best acc: 84.470000\n",
      "Epoch: [48][0/391]\tTime 0.651 (0.651)\tData 0.591 (0.591)\tLoss 0.2269 (0.2269)\tPrec 92.969% (92.969%)\n",
      "Epoch: [48][100/391]\tTime 0.045 (0.055)\tData 0.002 (0.008)\tLoss 0.3518 (0.3252)\tPrec 87.500% (88.730%)\n",
      "Epoch: [48][200/391]\tTime 0.053 (0.053)\tData 0.002 (0.005)\tLoss 0.3392 (0.3319)\tPrec 91.406% (88.483%)\n",
      "Epoch: [48][300/391]\tTime 0.052 (0.053)\tData 0.002 (0.004)\tLoss 0.3975 (0.3392)\tPrec 86.719% (88.219%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.300 (0.300)\tLoss 0.4234 (0.4234)\tPrec 85.938% (85.938%)\n",
      " * Prec 82.790% \n",
      "best acc: 84.470000\n",
      "Epoch: [49][0/391]\tTime 0.677 (0.677)\tData 0.613 (0.613)\tLoss 0.3905 (0.3905)\tPrec 86.719% (86.719%)\n",
      "Epoch: [49][100/391]\tTime 0.054 (0.058)\tData 0.003 (0.008)\tLoss 0.3581 (0.3335)\tPrec 87.500% (88.475%)\n",
      "Epoch: [49][200/391]\tTime 0.047 (0.055)\tData 0.003 (0.005)\tLoss 0.2844 (0.3342)\tPrec 89.844% (88.242%)\n",
      "Epoch: [49][300/391]\tTime 0.050 (0.054)\tData 0.002 (0.004)\tLoss 0.3051 (0.3379)\tPrec 91.406% (88.123%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.403 (0.403)\tLoss 0.3672 (0.3672)\tPrec 89.844% (89.844%)\n",
      " * Prec 82.540% \n",
      "best acc: 84.470000\n",
      "Epoch: [50][0/391]\tTime 0.582 (0.582)\tData 0.520 (0.520)\tLoss 0.3456 (0.3456)\tPrec 87.500% (87.500%)\n",
      "Epoch: [50][100/391]\tTime 0.051 (0.056)\tData 0.002 (0.007)\tLoss 0.2424 (0.3101)\tPrec 92.188% (89.264%)\n",
      "Epoch: [50][200/391]\tTime 0.052 (0.051)\tData 0.003 (0.005)\tLoss 0.3192 (0.3234)\tPrec 88.281% (88.697%)\n",
      "Epoch: [50][300/391]\tTime 0.045 (0.049)\tData 0.002 (0.004)\tLoss 0.2739 (0.3293)\tPrec 92.969% (88.520%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.476 (0.476)\tLoss 0.4115 (0.4115)\tPrec 87.500% (87.500%)\n",
      " * Prec 84.020% \n",
      "best acc: 84.470000\n",
      "Epoch: [51][0/391]\tTime 0.508 (0.508)\tData 0.434 (0.434)\tLoss 0.4221 (0.4221)\tPrec 88.281% (88.281%)\n",
      "Epoch: [51][100/391]\tTime 0.050 (0.052)\tData 0.003 (0.006)\tLoss 0.3531 (0.3239)\tPrec 88.281% (88.629%)\n",
      "Epoch: [51][200/391]\tTime 0.040 (0.049)\tData 0.002 (0.004)\tLoss 0.3653 (0.3220)\tPrec 85.938% (88.720%)\n",
      "Epoch: [51][300/391]\tTime 0.046 (0.048)\tData 0.002 (0.004)\tLoss 0.2573 (0.3311)\tPrec 90.625% (88.476%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.346 (0.346)\tLoss 0.4217 (0.4217)\tPrec 87.500% (87.500%)\n",
      " * Prec 83.550% \n",
      "best acc: 84.470000\n",
      "Epoch: [52][0/391]\tTime 0.880 (0.880)\tData 0.820 (0.820)\tLoss 0.2934 (0.2934)\tPrec 89.062% (89.062%)\n",
      "Epoch: [52][100/391]\tTime 0.047 (0.056)\tData 0.002 (0.010)\tLoss 0.3247 (0.3150)\tPrec 88.281% (88.908%)\n",
      "Epoch: [52][200/391]\tTime 0.047 (0.051)\tData 0.002 (0.006)\tLoss 0.3337 (0.3255)\tPrec 85.156% (88.685%)\n",
      "Epoch: [52][300/391]\tTime 0.046 (0.049)\tData 0.003 (0.005)\tLoss 0.3747 (0.3271)\tPrec 83.594% (88.582%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.500 (0.500)\tLoss 0.3796 (0.3796)\tPrec 88.281% (88.281%)\n",
      " * Prec 84.140% \n",
      "best acc: 84.470000\n",
      "Epoch: [53][0/391]\tTime 0.758 (0.758)\tData 0.702 (0.702)\tLoss 0.2253 (0.2253)\tPrec 91.406% (91.406%)\n",
      "Epoch: [53][100/391]\tTime 0.048 (0.054)\tData 0.002 (0.009)\tLoss 0.3006 (0.3150)\tPrec 87.500% (89.318%)\n",
      "Epoch: [53][200/391]\tTime 0.045 (0.048)\tData 0.002 (0.006)\tLoss 0.2982 (0.3238)\tPrec 87.500% (88.934%)\n",
      "Epoch: [53][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.3785 (0.3285)\tPrec 83.594% (88.725%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.717 (0.717)\tLoss 0.4200 (0.4200)\tPrec 87.500% (87.500%)\n",
      " * Prec 84.170% \n",
      "best acc: 84.470000\n",
      "Epoch: [54][0/391]\tTime 0.802 (0.802)\tData 0.743 (0.743)\tLoss 0.3566 (0.3566)\tPrec 88.281% (88.281%)\n",
      "Epoch: [54][100/391]\tTime 0.051 (0.053)\tData 0.002 (0.010)\tLoss 0.2520 (0.3162)\tPrec 90.625% (88.946%)\n",
      "Epoch: [54][200/391]\tTime 0.052 (0.053)\tData 0.002 (0.006)\tLoss 0.5052 (0.3290)\tPrec 79.688% (88.444%)\n",
      "Epoch: [54][300/391]\tTime 0.051 (0.054)\tData 0.003 (0.005)\tLoss 0.2723 (0.3280)\tPrec 92.969% (88.406%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.357 (0.357)\tLoss 0.4325 (0.4325)\tPrec 86.719% (86.719%)\n",
      " * Prec 83.540% \n",
      "best acc: 84.470000\n",
      "Epoch: [55][0/391]\tTime 0.642 (0.642)\tData 0.599 (0.599)\tLoss 0.2571 (0.2571)\tPrec 90.625% (90.625%)\n",
      "Epoch: [55][100/391]\tTime 0.042 (0.050)\tData 0.002 (0.008)\tLoss 0.3850 (0.3103)\tPrec 87.500% (89.001%)\n",
      "Epoch: [55][200/391]\tTime 0.048 (0.048)\tData 0.002 (0.005)\tLoss 0.3162 (0.3176)\tPrec 91.406% (88.755%)\n",
      "Epoch: [55][300/391]\tTime 0.042 (0.048)\tData 0.002 (0.004)\tLoss 0.2824 (0.3256)\tPrec 91.406% (88.473%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.620 (0.620)\tLoss 0.4845 (0.4845)\tPrec 85.156% (85.156%)\n",
      " * Prec 80.570% \n",
      "best acc: 84.470000\n",
      "Epoch: [56][0/391]\tTime 0.594 (0.594)\tData 0.532 (0.532)\tLoss 0.3053 (0.3053)\tPrec 88.281% (88.281%)\n",
      "Epoch: [56][100/391]\tTime 0.047 (0.053)\tData 0.002 (0.008)\tLoss 0.1939 (0.3223)\tPrec 92.969% (88.653%)\n",
      "Epoch: [56][200/391]\tTime 0.047 (0.049)\tData 0.002 (0.005)\tLoss 0.2991 (0.3232)\tPrec 89.844% (88.592%)\n",
      "Epoch: [56][300/391]\tTime 0.041 (0.048)\tData 0.002 (0.004)\tLoss 0.2055 (0.3248)\tPrec 93.750% (88.445%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.325 (0.325)\tLoss 0.7412 (0.7412)\tPrec 79.688% (79.688%)\n",
      " * Prec 78.560% \n",
      "best acc: 84.470000\n",
      "Epoch: [57][0/391]\tTime 0.532 (0.532)\tData 0.489 (0.489)\tLoss 0.2709 (0.2709)\tPrec 90.625% (90.625%)\n",
      "Epoch: [57][100/391]\tTime 0.046 (0.051)\tData 0.002 (0.007)\tLoss 0.3686 (0.3043)\tPrec 85.938% (89.418%)\n",
      "Epoch: [57][200/391]\tTime 0.041 (0.048)\tData 0.002 (0.004)\tLoss 0.3585 (0.3146)\tPrec 85.938% (88.798%)\n",
      "Epoch: [57][300/391]\tTime 0.051 (0.048)\tData 0.003 (0.004)\tLoss 0.2051 (0.3185)\tPrec 93.750% (88.746%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.435 (0.435)\tLoss 0.5469 (0.5469)\tPrec 85.156% (85.156%)\n",
      " * Prec 83.590% \n",
      "best acc: 84.470000\n",
      "Epoch: [58][0/391]\tTime 0.766 (0.766)\tData 0.705 (0.705)\tLoss 0.3135 (0.3135)\tPrec 89.844% (89.844%)\n",
      "Epoch: [58][100/391]\tTime 0.045 (0.052)\tData 0.002 (0.009)\tLoss 0.3136 (0.3062)\tPrec 85.938% (88.885%)\n",
      "Epoch: [58][200/391]\tTime 0.046 (0.049)\tData 0.004 (0.006)\tLoss 0.2968 (0.3204)\tPrec 89.062% (88.569%)\n",
      "Epoch: [58][300/391]\tTime 0.048 (0.048)\tData 0.003 (0.005)\tLoss 0.2160 (0.3216)\tPrec 94.531% (88.697%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.626 (0.626)\tLoss 0.3330 (0.3330)\tPrec 87.500% (87.500%)\n",
      " * Prec 83.680% \n",
      "best acc: 84.470000\n",
      "Epoch: [59][0/391]\tTime 0.499 (0.499)\tData 0.442 (0.442)\tLoss 0.3729 (0.3729)\tPrec 85.938% (85.938%)\n",
      "Epoch: [59][100/391]\tTime 0.036 (0.049)\tData 0.002 (0.007)\tLoss 0.3455 (0.3025)\tPrec 88.281% (89.612%)\n",
      "Epoch: [59][200/391]\tTime 0.043 (0.047)\tData 0.002 (0.004)\tLoss 0.2668 (0.3069)\tPrec 90.625% (89.230%)\n",
      "Epoch: [59][300/391]\tTime 0.036 (0.047)\tData 0.002 (0.004)\tLoss 0.2658 (0.3125)\tPrec 90.625% (89.083%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.372 (0.372)\tLoss 0.4099 (0.4099)\tPrec 88.281% (88.281%)\n",
      " * Prec 82.550% \n",
      "best acc: 84.470000\n",
      "Epoch: [60][0/391]\tTime 0.781 (0.781)\tData 0.724 (0.724)\tLoss 0.2489 (0.2489)\tPrec 93.750% (93.750%)\n",
      "Epoch: [60][100/391]\tTime 0.039 (0.054)\tData 0.002 (0.009)\tLoss 0.2362 (0.3024)\tPrec 89.844% (89.295%)\n",
      "Epoch: [60][200/391]\tTime 0.048 (0.050)\tData 0.002 (0.006)\tLoss 0.3708 (0.3081)\tPrec 87.500% (89.144%)\n",
      "Epoch: [60][300/391]\tTime 0.046 (0.050)\tData 0.002 (0.005)\tLoss 0.4169 (0.3151)\tPrec 85.156% (88.922%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.997 (0.997)\tLoss 0.3705 (0.3705)\tPrec 86.719% (86.719%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec 85.510% \n",
      "best acc: 85.510000\n",
      "Epoch: [61][0/391]\tTime 0.534 (0.534)\tData 0.477 (0.477)\tLoss 0.3589 (0.3589)\tPrec 87.500% (87.500%)\n",
      "Epoch: [61][100/391]\tTime 0.052 (0.052)\tData 0.003 (0.007)\tLoss 0.3037 (0.3034)\tPrec 88.281% (89.217%)\n",
      "Epoch: [61][200/391]\tTime 0.044 (0.048)\tData 0.002 (0.005)\tLoss 0.2808 (0.3073)\tPrec 89.062% (89.125%)\n",
      "Epoch: [61][300/391]\tTime 0.043 (0.047)\tData 0.002 (0.004)\tLoss 0.3935 (0.3110)\tPrec 88.281% (89.024%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.488 (0.488)\tLoss 0.3072 (0.3072)\tPrec 89.062% (89.062%)\n",
      " * Prec 85.460% \n",
      "best acc: 85.510000\n",
      "Epoch: [62][0/391]\tTime 0.604 (0.604)\tData 0.509 (0.509)\tLoss 0.2207 (0.2207)\tPrec 93.750% (93.750%)\n",
      "Epoch: [62][100/391]\tTime 0.036 (0.050)\tData 0.002 (0.007)\tLoss 0.3309 (0.2777)\tPrec 90.625% (90.114%)\n",
      "Epoch: [62][200/391]\tTime 0.050 (0.046)\tData 0.002 (0.005)\tLoss 0.3072 (0.2872)\tPrec 90.625% (89.871%)\n",
      "Epoch: [62][300/391]\tTime 0.038 (0.047)\tData 0.002 (0.004)\tLoss 0.2786 (0.2982)\tPrec 92.188% (89.525%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.658 (0.658)\tLoss 0.5027 (0.5027)\tPrec 85.938% (85.938%)\n",
      " * Prec 83.840% \n",
      "best acc: 85.510000\n",
      "Epoch: [63][0/391]\tTime 0.864 (0.864)\tData 0.809 (0.809)\tLoss 0.3828 (0.3828)\tPrec 86.719% (86.719%)\n",
      "Epoch: [63][100/391]\tTime 0.044 (0.053)\tData 0.002 (0.010)\tLoss 0.2619 (0.2952)\tPrec 90.625% (89.720%)\n",
      "Epoch: [63][200/391]\tTime 0.044 (0.050)\tData 0.002 (0.006)\tLoss 0.2506 (0.3013)\tPrec 90.625% (89.486%)\n",
      "Epoch: [63][300/391]\tTime 0.051 (0.050)\tData 0.003 (0.005)\tLoss 0.2911 (0.3055)\tPrec 88.281% (89.351%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.406 (1.406)\tLoss 0.3286 (0.3286)\tPrec 87.500% (87.500%)\n",
      " * Prec 84.400% \n",
      "best acc: 85.510000\n",
      "Epoch: [64][0/391]\tTime 0.791 (0.791)\tData 0.723 (0.723)\tLoss 0.3554 (0.3554)\tPrec 88.281% (88.281%)\n",
      "Epoch: [64][100/391]\tTime 0.055 (0.057)\tData 0.002 (0.010)\tLoss 0.2840 (0.3038)\tPrec 89.844% (89.372%)\n",
      "Epoch: [64][200/391]\tTime 0.053 (0.054)\tData 0.002 (0.006)\tLoss 0.3025 (0.3067)\tPrec 89.844% (89.101%)\n",
      "Epoch: [64][300/391]\tTime 0.049 (0.052)\tData 0.002 (0.005)\tLoss 0.3112 (0.3116)\tPrec 90.625% (89.000%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.601 (0.601)\tLoss 0.4902 (0.4902)\tPrec 84.375% (84.375%)\n",
      " * Prec 82.980% \n",
      "best acc: 85.510000\n",
      "Epoch: [65][0/391]\tTime 0.831 (0.831)\tData 0.752 (0.752)\tLoss 0.2716 (0.2716)\tPrec 91.406% (91.406%)\n",
      "Epoch: [65][100/391]\tTime 0.051 (0.055)\tData 0.002 (0.010)\tLoss 0.2901 (0.3099)\tPrec 91.406% (89.093%)\n",
      "Epoch: [65][200/391]\tTime 0.049 (0.050)\tData 0.003 (0.006)\tLoss 0.2351 (0.3052)\tPrec 92.969% (89.164%)\n",
      "Epoch: [65][300/391]\tTime 0.042 (0.049)\tData 0.002 (0.005)\tLoss 0.2395 (0.3070)\tPrec 93.750% (89.177%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.426 (0.426)\tLoss 0.4739 (0.4739)\tPrec 87.500% (87.500%)\n",
      " * Prec 83.600% \n",
      "best acc: 85.510000\n",
      "Epoch: [66][0/391]\tTime 0.549 (0.549)\tData 0.488 (0.488)\tLoss 0.3742 (0.3742)\tPrec 89.844% (89.844%)\n",
      "Epoch: [66][100/391]\tTime 0.045 (0.049)\tData 0.002 (0.007)\tLoss 0.3101 (0.2998)\tPrec 87.500% (89.550%)\n",
      "Epoch: [66][200/391]\tTime 0.043 (0.048)\tData 0.002 (0.005)\tLoss 0.3916 (0.2991)\tPrec 88.281% (89.614%)\n",
      "Epoch: [66][300/391]\tTime 0.043 (0.048)\tData 0.002 (0.004)\tLoss 0.2400 (0.3028)\tPrec 90.625% (89.452%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.306 (0.306)\tLoss 0.5583 (0.5583)\tPrec 83.594% (83.594%)\n",
      " * Prec 82.010% \n",
      "best acc: 85.510000\n",
      "Epoch: [67][0/391]\tTime 0.666 (0.666)\tData 0.609 (0.609)\tLoss 0.3316 (0.3316)\tPrec 88.281% (88.281%)\n",
      "Epoch: [67][100/391]\tTime 0.037 (0.050)\tData 0.002 (0.008)\tLoss 0.3624 (0.3028)\tPrec 88.281% (89.248%)\n",
      "Epoch: [67][200/391]\tTime 0.040 (0.047)\tData 0.002 (0.005)\tLoss 0.4057 (0.3070)\tPrec 87.500% (89.051%)\n",
      "Epoch: [67][300/391]\tTime 0.040 (0.046)\tData 0.002 (0.004)\tLoss 0.2984 (0.3082)\tPrec 88.281% (88.977%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.511 (0.511)\tLoss 0.3406 (0.3406)\tPrec 90.625% (90.625%)\n",
      " * Prec 83.550% \n",
      "best acc: 85.510000\n",
      "Epoch: [68][0/391]\tTime 0.626 (0.626)\tData 0.570 (0.570)\tLoss 0.3710 (0.3710)\tPrec 86.719% (86.719%)\n",
      "Epoch: [68][100/391]\tTime 0.043 (0.053)\tData 0.003 (0.008)\tLoss 0.2902 (0.2911)\tPrec 86.719% (89.558%)\n",
      "Epoch: [68][200/391]\tTime 0.049 (0.050)\tData 0.002 (0.005)\tLoss 0.2174 (0.2907)\tPrec 90.625% (89.743%)\n",
      "Epoch: [68][300/391]\tTime 0.040 (0.049)\tData 0.002 (0.004)\tLoss 0.2812 (0.2997)\tPrec 89.062% (89.457%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.448 (0.448)\tLoss 0.4536 (0.4536)\tPrec 82.812% (82.812%)\n",
      " * Prec 80.730% \n",
      "best acc: 85.510000\n",
      "Epoch: [69][0/391]\tTime 0.539 (0.539)\tData 0.483 (0.483)\tLoss 0.3082 (0.3082)\tPrec 86.719% (86.719%)\n",
      "Epoch: [69][100/391]\tTime 0.053 (0.054)\tData 0.002 (0.007)\tLoss 0.2220 (0.2984)\tPrec 89.062% (89.256%)\n",
      "Epoch: [69][200/391]\tTime 0.037 (0.049)\tData 0.001 (0.005)\tLoss 0.2510 (0.2925)\tPrec 92.969% (89.700%)\n",
      "Epoch: [69][300/391]\tTime 0.050 (0.048)\tData 0.002 (0.004)\tLoss 0.2581 (0.2967)\tPrec 89.062% (89.605%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.412 (0.412)\tLoss 0.4253 (0.4253)\tPrec 87.500% (87.500%)\n",
      " * Prec 83.910% \n",
      "best acc: 85.510000\n",
      "Epoch: [70][0/391]\tTime 0.722 (0.722)\tData 0.667 (0.667)\tLoss 0.2560 (0.2560)\tPrec 89.844% (89.844%)\n",
      "Epoch: [70][100/391]\tTime 0.047 (0.056)\tData 0.002 (0.009)\tLoss 0.2322 (0.2816)\tPrec 92.188% (90.370%)\n",
      "Epoch: [70][200/391]\tTime 0.041 (0.051)\tData 0.002 (0.006)\tLoss 0.2810 (0.2949)\tPrec 89.062% (89.848%)\n",
      "Epoch: [70][300/391]\tTime 0.052 (0.049)\tData 0.002 (0.004)\tLoss 0.2752 (0.2963)\tPrec 88.281% (89.740%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.597 (0.597)\tLoss 0.7280 (0.7280)\tPrec 77.344% (77.344%)\n",
      " * Prec 79.140% \n",
      "best acc: 85.510000\n",
      "Epoch: [71][0/391]\tTime 0.715 (0.715)\tData 0.655 (0.655)\tLoss 0.3989 (0.3989)\tPrec 85.156% (85.156%)\n",
      "Epoch: [71][100/391]\tTime 0.048 (0.053)\tData 0.002 (0.009)\tLoss 0.3641 (0.3016)\tPrec 88.281% (89.364%)\n",
      "Epoch: [71][200/391]\tTime 0.042 (0.050)\tData 0.002 (0.005)\tLoss 0.2851 (0.3011)\tPrec 89.062% (89.455%)\n",
      "Epoch: [71][300/391]\tTime 0.044 (0.048)\tData 0.002 (0.004)\tLoss 0.2500 (0.3009)\tPrec 90.625% (89.400%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.542 (0.542)\tLoss 0.3181 (0.3181)\tPrec 88.281% (88.281%)\n",
      " * Prec 84.820% \n",
      "best acc: 85.510000\n",
      "Epoch: [72][0/391]\tTime 1.001 (1.001)\tData 0.940 (0.940)\tLoss 0.3465 (0.3465)\tPrec 87.500% (87.500%)\n",
      "Epoch: [72][100/391]\tTime 0.044 (0.056)\tData 0.002 (0.011)\tLoss 0.2614 (0.2869)\tPrec 92.188% (89.913%)\n",
      "Epoch: [72][200/391]\tTime 0.046 (0.051)\tData 0.002 (0.007)\tLoss 0.2222 (0.2884)\tPrec 92.188% (89.894%)\n",
      "Epoch: [72][300/391]\tTime 0.052 (0.049)\tData 0.003 (0.005)\tLoss 0.2551 (0.2939)\tPrec 91.406% (89.652%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.420 (0.420)\tLoss 0.4244 (0.4244)\tPrec 87.500% (87.500%)\n",
      " * Prec 83.790% \n",
      "best acc: 85.510000\n",
      "Epoch: [73][0/391]\tTime 0.661 (0.661)\tData 0.603 (0.603)\tLoss 0.3386 (0.3386)\tPrec 91.406% (91.406%)\n",
      "Epoch: [73][100/391]\tTime 0.050 (0.051)\tData 0.002 (0.008)\tLoss 0.2736 (0.3029)\tPrec 89.062% (89.209%)\n",
      "Epoch: [73][200/391]\tTime 0.046 (0.049)\tData 0.002 (0.005)\tLoss 0.3404 (0.3001)\tPrec 91.406% (89.424%)\n",
      "Epoch: [73][300/391]\tTime 0.053 (0.049)\tData 0.003 (0.004)\tLoss 0.2095 (0.2965)\tPrec 93.750% (89.535%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.415 (0.415)\tLoss 0.4080 (0.4080)\tPrec 89.844% (89.844%)\n",
      " * Prec 84.750% \n",
      "best acc: 85.510000\n",
      "Epoch: [74][0/391]\tTime 0.535 (0.535)\tData 0.479 (0.479)\tLoss 0.2227 (0.2227)\tPrec 94.531% (94.531%)\n",
      "Epoch: [74][100/391]\tTime 0.057 (0.053)\tData 0.003 (0.007)\tLoss 0.2739 (0.2931)\tPrec 89.844% (89.890%)\n",
      "Epoch: [74][200/391]\tTime 0.045 (0.050)\tData 0.002 (0.005)\tLoss 0.2766 (0.2885)\tPrec 88.281% (89.758%)\n",
      "Epoch: [74][300/391]\tTime 0.045 (0.049)\tData 0.002 (0.004)\tLoss 0.2483 (0.2885)\tPrec 91.406% (89.766%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.340 (0.340)\tLoss 0.4275 (0.4275)\tPrec 84.375% (84.375%)\n",
      " * Prec 84.850% \n",
      "best acc: 85.510000\n",
      "Epoch: [75][0/391]\tTime 0.689 (0.689)\tData 0.629 (0.629)\tLoss 0.2881 (0.2881)\tPrec 86.719% (86.719%)\n",
      "Epoch: [75][100/391]\tTime 0.049 (0.052)\tData 0.002 (0.008)\tLoss 0.3196 (0.2886)\tPrec 87.500% (90.114%)\n",
      "Epoch: [75][200/391]\tTime 0.062 (0.049)\tData 0.003 (0.005)\tLoss 0.2760 (0.2827)\tPrec 90.625% (90.213%)\n",
      "Epoch: [75][300/391]\tTime 0.043 (0.049)\tData 0.002 (0.004)\tLoss 0.2639 (0.2834)\tPrec 89.844% (90.038%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.402 (0.402)\tLoss 0.4012 (0.4012)\tPrec 86.719% (86.719%)\n",
      " * Prec 84.930% \n",
      "best acc: 85.510000\n",
      "Epoch: [76][0/391]\tTime 0.536 (0.536)\tData 0.475 (0.475)\tLoss 0.2370 (0.2370)\tPrec 95.312% (95.312%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [76][100/391]\tTime 0.050 (0.052)\tData 0.003 (0.007)\tLoss 0.2463 (0.2687)\tPrec 89.844% (90.733%)\n",
      "Epoch: [76][200/391]\tTime 0.058 (0.049)\tData 0.003 (0.005)\tLoss 0.3314 (0.2784)\tPrec 89.062% (90.314%)\n",
      "Epoch: [76][300/391]\tTime 0.043 (0.047)\tData 0.002 (0.004)\tLoss 0.2450 (0.2789)\tPrec 89.062% (90.207%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.509 (0.509)\tLoss 0.5306 (0.5306)\tPrec 85.938% (85.938%)\n",
      " * Prec 83.070% \n",
      "best acc: 85.510000\n",
      "Epoch: [77][0/391]\tTime 0.747 (0.747)\tData 0.682 (0.682)\tLoss 0.1254 (0.1254)\tPrec 98.438% (98.438%)\n",
      "Epoch: [77][100/391]\tTime 0.041 (0.050)\tData 0.002 (0.009)\tLoss 0.2512 (0.2830)\tPrec 95.312% (89.859%)\n",
      "Epoch: [77][200/391]\tTime 0.042 (0.047)\tData 0.002 (0.005)\tLoss 0.4202 (0.2913)\tPrec 85.156% (89.564%)\n",
      "Epoch: [77][300/391]\tTime 0.046 (0.046)\tData 0.002 (0.004)\tLoss 0.2912 (0.2918)\tPrec 90.625% (89.665%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.395 (0.395)\tLoss 0.3673 (0.3673)\tPrec 86.719% (86.719%)\n",
      " * Prec 84.760% \n",
      "best acc: 85.510000\n",
      "Epoch: [78][0/391]\tTime 0.783 (0.783)\tData 0.742 (0.742)\tLoss 0.3878 (0.3878)\tPrec 85.156% (85.156%)\n",
      "Epoch: [78][100/391]\tTime 0.046 (0.052)\tData 0.002 (0.010)\tLoss 0.3510 (0.2769)\tPrec 86.719% (90.277%)\n",
      "Epoch: [78][200/391]\tTime 0.048 (0.049)\tData 0.002 (0.006)\tLoss 0.3533 (0.2824)\tPrec 89.062% (90.081%)\n",
      "Epoch: [78][300/391]\tTime 0.044 (0.048)\tData 0.002 (0.005)\tLoss 0.3673 (0.2863)\tPrec 87.500% (89.974%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.305 (0.305)\tLoss 0.3759 (0.3759)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.240% \n",
      "best acc: 86.240000\n",
      "Epoch: [79][0/391]\tTime 0.864 (0.864)\tData 0.822 (0.822)\tLoss 0.2965 (0.2965)\tPrec 89.062% (89.062%)\n",
      "Epoch: [79][100/391]\tTime 0.044 (0.054)\tData 0.002 (0.010)\tLoss 0.2031 (0.2700)\tPrec 95.312% (90.470%)\n",
      "Epoch: [79][200/391]\tTime 0.053 (0.051)\tData 0.003 (0.006)\tLoss 0.3291 (0.2763)\tPrec 86.719% (90.159%)\n",
      "Epoch: [79][300/391]\tTime 0.047 (0.049)\tData 0.002 (0.005)\tLoss 0.3990 (0.2849)\tPrec 87.500% (89.883%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.526 (0.526)\tLoss 0.3380 (0.3380)\tPrec 89.844% (89.844%)\n",
      " * Prec 84.940% \n",
      "best acc: 86.240000\n",
      "Epoch: [80][0/391]\tTime 0.879 (0.879)\tData 0.817 (0.817)\tLoss 0.2146 (0.2146)\tPrec 92.969% (92.969%)\n",
      "Epoch: [80][100/391]\tTime 0.048 (0.055)\tData 0.002 (0.010)\tLoss 0.1866 (0.2169)\tPrec 94.531% (92.481%)\n",
      "Epoch: [80][200/391]\tTime 0.048 (0.051)\tData 0.002 (0.006)\tLoss 0.1869 (0.2136)\tPrec 92.188% (92.673%)\n",
      "Epoch: [80][300/391]\tTime 0.047 (0.049)\tData 0.002 (0.005)\tLoss 0.2242 (0.2098)\tPrec 93.750% (92.839%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.306 (0.306)\tLoss 0.2892 (0.2892)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.600% \n",
      "best acc: 88.600000\n",
      "Epoch: [81][0/391]\tTime 0.596 (0.596)\tData 0.536 (0.536)\tLoss 0.1780 (0.1780)\tPrec 95.312% (95.312%)\n",
      "Epoch: [81][100/391]\tTime 0.049 (0.051)\tData 0.002 (0.008)\tLoss 0.1882 (0.1876)\tPrec 93.750% (93.402%)\n",
      "Epoch: [81][200/391]\tTime 0.048 (0.049)\tData 0.002 (0.005)\tLoss 0.2598 (0.1914)\tPrec 89.062% (93.303%)\n",
      "Epoch: [81][300/391]\tTime 0.046 (0.049)\tData 0.002 (0.004)\tLoss 0.1360 (0.1892)\tPrec 94.531% (93.420%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.487 (0.487)\tLoss 0.2913 (0.2913)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.710% \n",
      "best acc: 88.710000\n",
      "Epoch: [82][0/391]\tTime 0.681 (0.681)\tData 0.621 (0.621)\tLoss 0.1243 (0.1243)\tPrec 96.875% (96.875%)\n",
      "Epoch: [82][100/391]\tTime 0.061 (0.054)\tData 0.003 (0.008)\tLoss 0.2488 (0.1748)\tPrec 89.844% (94.052%)\n",
      "Epoch: [82][200/391]\tTime 0.050 (0.050)\tData 0.003 (0.005)\tLoss 0.1624 (0.1737)\tPrec 96.094% (94.038%)\n",
      "Epoch: [82][300/391]\tTime 0.053 (0.050)\tData 0.003 (0.004)\tLoss 0.1328 (0.1720)\tPrec 96.094% (94.157%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.575 (0.575)\tLoss 0.3005 (0.3005)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.600% \n",
      "best acc: 88.710000\n",
      "Epoch: [83][0/391]\tTime 0.665 (0.665)\tData 0.603 (0.603)\tLoss 0.1850 (0.1850)\tPrec 93.750% (93.750%)\n",
      "Epoch: [83][100/391]\tTime 0.043 (0.053)\tData 0.002 (0.008)\tLoss 0.1257 (0.1765)\tPrec 97.656% (94.137%)\n",
      "Epoch: [83][200/391]\tTime 0.051 (0.050)\tData 0.002 (0.005)\tLoss 0.1478 (0.1751)\tPrec 94.531% (94.080%)\n",
      "Epoch: [83][300/391]\tTime 0.051 (0.050)\tData 0.002 (0.004)\tLoss 0.1725 (0.1718)\tPrec 94.531% (94.163%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.462 (0.462)\tLoss 0.2844 (0.2844)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.590% \n",
      "best acc: 88.710000\n",
      "Epoch: [84][0/391]\tTime 0.532 (0.532)\tData 0.485 (0.485)\tLoss 0.1505 (0.1505)\tPrec 96.094% (96.094%)\n",
      "Epoch: [84][100/391]\tTime 0.048 (0.052)\tData 0.002 (0.007)\tLoss 0.2356 (0.1626)\tPrec 93.750% (94.361%)\n",
      "Epoch: [84][200/391]\tTime 0.045 (0.049)\tData 0.002 (0.005)\tLoss 0.2004 (0.1695)\tPrec 92.188% (94.127%)\n",
      "Epoch: [84][300/391]\tTime 0.051 (0.049)\tData 0.002 (0.004)\tLoss 0.1382 (0.1674)\tPrec 95.312% (94.222%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.358 (0.358)\tLoss 0.3004 (0.3004)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.900% \n",
      "best acc: 88.900000\n",
      "Epoch: [85][0/391]\tTime 0.706 (0.706)\tData 0.650 (0.650)\tLoss 0.1440 (0.1440)\tPrec 95.312% (95.312%)\n",
      "Epoch: [85][100/391]\tTime 0.043 (0.051)\tData 0.002 (0.009)\tLoss 0.1377 (0.1563)\tPrec 95.312% (94.748%)\n",
      "Epoch: [85][200/391]\tTime 0.041 (0.049)\tData 0.002 (0.005)\tLoss 0.1734 (0.1604)\tPrec 93.750% (94.520%)\n",
      "Epoch: [85][300/391]\tTime 0.051 (0.048)\tData 0.002 (0.004)\tLoss 0.1838 (0.1608)\tPrec 92.188% (94.464%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.401 (0.401)\tLoss 0.2704 (0.2704)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.860% \n",
      "best acc: 88.900000\n",
      "Epoch: [86][0/391]\tTime 0.717 (0.717)\tData 0.658 (0.658)\tLoss 0.1245 (0.1245)\tPrec 95.312% (95.312%)\n",
      "Epoch: [86][100/391]\tTime 0.038 (0.051)\tData 0.002 (0.009)\tLoss 0.0952 (0.1507)\tPrec 97.656% (94.933%)\n",
      "Epoch: [86][200/391]\tTime 0.055 (0.050)\tData 0.002 (0.005)\tLoss 0.2116 (0.1546)\tPrec 94.531% (94.831%)\n",
      "Epoch: [86][300/391]\tTime 0.049 (0.049)\tData 0.002 (0.004)\tLoss 0.1290 (0.1587)\tPrec 95.312% (94.643%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.752 (0.752)\tLoss 0.2442 (0.2442)\tPrec 94.531% (94.531%)\n",
      " * Prec 88.800% \n",
      "best acc: 88.900000\n",
      "Epoch: [87][0/391]\tTime 0.955 (0.955)\tData 0.894 (0.894)\tLoss 0.1738 (0.1738)\tPrec 93.750% (93.750%)\n",
      "Epoch: [87][100/391]\tTime 0.049 (0.056)\tData 0.003 (0.011)\tLoss 0.1765 (0.1513)\tPrec 92.969% (94.670%)\n",
      "Epoch: [87][200/391]\tTime 0.047 (0.051)\tData 0.002 (0.007)\tLoss 0.1107 (0.1537)\tPrec 95.312% (94.652%)\n",
      "Epoch: [87][300/391]\tTime 0.046 (0.051)\tData 0.002 (0.005)\tLoss 0.1382 (0.1524)\tPrec 95.312% (94.726%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.571 (0.571)\tLoss 0.2910 (0.2910)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.860% \n",
      "best acc: 88.900000\n",
      "Epoch: [88][0/391]\tTime 0.601 (0.601)\tData 0.509 (0.509)\tLoss 0.1017 (0.1017)\tPrec 96.875% (96.875%)\n",
      "Epoch: [88][100/391]\tTime 0.047 (0.052)\tData 0.002 (0.007)\tLoss 0.1350 (0.1526)\tPrec 96.094% (94.787%)\n",
      "Epoch: [88][200/391]\tTime 0.048 (0.050)\tData 0.002 (0.005)\tLoss 0.1382 (0.1500)\tPrec 92.969% (94.932%)\n",
      "Epoch: [88][300/391]\tTime 0.044 (0.049)\tData 0.002 (0.004)\tLoss 0.1435 (0.1493)\tPrec 94.531% (94.923%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.448 (0.448)\tLoss 0.2677 (0.2677)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.870% \n",
      "best acc: 88.900000\n",
      "Epoch: [89][0/391]\tTime 0.823 (0.823)\tData 0.762 (0.762)\tLoss 0.0892 (0.0892)\tPrec 96.875% (96.875%)\n",
      "Epoch: [89][100/391]\tTime 0.050 (0.053)\tData 0.002 (0.010)\tLoss 0.1206 (0.1413)\tPrec 96.094% (95.150%)\n",
      "Epoch: [89][200/391]\tTime 0.048 (0.052)\tData 0.002 (0.006)\tLoss 0.1033 (0.1459)\tPrec 95.312% (95.009%)\n",
      "Epoch: [89][300/391]\tTime 0.043 (0.051)\tData 0.002 (0.005)\tLoss 0.2221 (0.1474)\tPrec 88.281% (94.908%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.648 (0.648)\tLoss 0.2293 (0.2293)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.730% \n",
      "best acc: 88.900000\n",
      "Epoch: [90][0/391]\tTime 0.585 (0.585)\tData 0.532 (0.532)\tLoss 0.1618 (0.1618)\tPrec 92.969% (92.969%)\n",
      "Epoch: [90][100/391]\tTime 0.047 (0.052)\tData 0.002 (0.008)\tLoss 0.1110 (0.1455)\tPrec 95.312% (94.856%)\n",
      "Epoch: [90][200/391]\tTime 0.054 (0.051)\tData 0.002 (0.005)\tLoss 0.1637 (0.1429)\tPrec 94.531% (95.099%)\n",
      "Epoch: [90][300/391]\tTime 0.037 (0.048)\tData 0.002 (0.004)\tLoss 0.1527 (0.1408)\tPrec 93.750% (95.159%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.355 (0.355)\tLoss 0.2489 (0.2489)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.880% \n",
      "best acc: 88.900000\n",
      "Epoch: [91][0/391]\tTime 0.588 (0.588)\tData 0.527 (0.527)\tLoss 0.1207 (0.1207)\tPrec 97.656% (97.656%)\n",
      "Epoch: [91][100/391]\tTime 0.053 (0.052)\tData 0.003 (0.007)\tLoss 0.1468 (0.1363)\tPrec 96.094% (95.467%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [91][200/391]\tTime 0.046 (0.049)\tData 0.002 (0.005)\tLoss 0.0951 (0.1391)\tPrec 95.312% (95.293%)\n",
      "Epoch: [91][300/391]\tTime 0.039 (0.045)\tData 0.002 (0.004)\tLoss 0.1328 (0.1375)\tPrec 96.875% (95.297%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.545 (0.545)\tLoss 0.2551 (0.2551)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.870% \n",
      "best acc: 88.900000\n",
      "Epoch: [92][0/391]\tTime 0.523 (0.523)\tData 0.474 (0.474)\tLoss 0.0858 (0.0858)\tPrec 97.656% (97.656%)\n",
      "Epoch: [92][100/391]\tTime 0.061 (0.052)\tData 0.002 (0.007)\tLoss 0.1292 (0.1348)\tPrec 95.312% (95.514%)\n",
      "Epoch: [92][200/391]\tTime 0.041 (0.050)\tData 0.002 (0.005)\tLoss 0.1656 (0.1361)\tPrec 93.750% (95.460%)\n",
      "Epoch: [92][300/391]\tTime 0.044 (0.049)\tData 0.002 (0.004)\tLoss 0.1911 (0.1356)\tPrec 95.312% (95.476%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.372 (0.372)\tLoss 0.2372 (0.2372)\tPrec 93.750% (93.750%)\n",
      " * Prec 89.000% \n",
      "best acc: 89.000000\n",
      "Epoch: [93][0/391]\tTime 1.364 (1.364)\tData 1.301 (1.301)\tLoss 0.1841 (0.1841)\tPrec 93.750% (93.750%)\n",
      "Epoch: [93][100/391]\tTime 0.048 (0.059)\tData 0.002 (0.015)\tLoss 0.0889 (0.1403)\tPrec 96.875% (95.320%)\n",
      "Epoch: [93][200/391]\tTime 0.044 (0.052)\tData 0.002 (0.009)\tLoss 0.1125 (0.1357)\tPrec 95.312% (95.398%)\n",
      "Epoch: [93][300/391]\tTime 0.045 (0.051)\tData 0.002 (0.007)\tLoss 0.1131 (0.1350)\tPrec 96.875% (95.427%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.758 (0.758)\tLoss 0.2183 (0.2183)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.960% \n",
      "best acc: 89.000000\n",
      "Epoch: [94][0/391]\tTime 0.645 (0.645)\tData 0.589 (0.589)\tLoss 0.1344 (0.1344)\tPrec 93.750% (93.750%)\n",
      "Epoch: [94][100/391]\tTime 0.049 (0.052)\tData 0.002 (0.008)\tLoss 0.1698 (0.1325)\tPrec 94.531% (95.382%)\n",
      "Epoch: [94][200/391]\tTime 0.052 (0.049)\tData 0.003 (0.005)\tLoss 0.1077 (0.1352)\tPrec 96.094% (95.336%)\n",
      "Epoch: [94][300/391]\tTime 0.046 (0.047)\tData 0.002 (0.004)\tLoss 0.2228 (0.1372)\tPrec 91.406% (95.255%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.449 (0.449)\tLoss 0.2117 (0.2117)\tPrec 94.531% (94.531%)\n",
      " * Prec 89.200% \n",
      "best acc: 89.200000\n",
      "Epoch: [95][0/391]\tTime 0.618 (0.618)\tData 0.556 (0.556)\tLoss 0.2114 (0.2114)\tPrec 91.406% (91.406%)\n",
      "Epoch: [95][100/391]\tTime 0.051 (0.053)\tData 0.002 (0.008)\tLoss 0.0914 (0.1385)\tPrec 96.875% (95.382%)\n",
      "Epoch: [95][200/391]\tTime 0.038 (0.049)\tData 0.002 (0.005)\tLoss 0.1407 (0.1330)\tPrec 94.531% (95.503%)\n",
      "Epoch: [95][300/391]\tTime 0.046 (0.048)\tData 0.002 (0.004)\tLoss 0.1021 (0.1341)\tPrec 94.531% (95.383%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.558 (0.558)\tLoss 0.2683 (0.2683)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.960% \n",
      "best acc: 89.200000\n",
      "Epoch: [96][0/391]\tTime 0.529 (0.529)\tData 0.480 (0.480)\tLoss 0.1394 (0.1394)\tPrec 96.875% (96.875%)\n",
      "Epoch: [96][100/391]\tTime 0.041 (0.050)\tData 0.002 (0.007)\tLoss 0.1416 (0.1274)\tPrec 95.312% (95.707%)\n",
      "Epoch: [96][200/391]\tTime 0.049 (0.048)\tData 0.002 (0.005)\tLoss 0.1888 (0.1294)\tPrec 93.750% (95.588%)\n",
      "Epoch: [96][300/391]\tTime 0.046 (0.048)\tData 0.002 (0.004)\tLoss 0.2807 (0.1316)\tPrec 87.500% (95.497%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.376 (0.376)\tLoss 0.2515 (0.2515)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.170% \n",
      "best acc: 89.200000\n",
      "Epoch: [97][0/391]\tTime 0.696 (0.696)\tData 0.636 (0.636)\tLoss 0.0994 (0.0994)\tPrec 96.094% (96.094%)\n",
      "Epoch: [97][100/391]\tTime 0.045 (0.053)\tData 0.002 (0.008)\tLoss 0.1235 (0.1278)\tPrec 94.531% (95.738%)\n",
      "Epoch: [97][200/391]\tTime 0.041 (0.050)\tData 0.002 (0.005)\tLoss 0.1084 (0.1287)\tPrec 96.875% (95.643%)\n",
      "Epoch: [97][300/391]\tTime 0.040 (0.049)\tData 0.002 (0.004)\tLoss 0.1064 (0.1315)\tPrec 96.875% (95.572%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.473 (0.473)\tLoss 0.2536 (0.2536)\tPrec 93.750% (93.750%)\n",
      " * Prec 89.210% \n",
      "best acc: 89.210000\n",
      "Epoch: [98][0/391]\tTime 0.573 (0.573)\tData 0.517 (0.517)\tLoss 0.1087 (0.1087)\tPrec 98.438% (98.438%)\n",
      "Epoch: [98][100/391]\tTime 0.055 (0.053)\tData 0.003 (0.007)\tLoss 0.2222 (0.1360)\tPrec 91.406% (95.591%)\n",
      "Epoch: [98][200/391]\tTime 0.051 (0.052)\tData 0.002 (0.005)\tLoss 0.0949 (0.1332)\tPrec 96.875% (95.546%)\n",
      "Epoch: [98][300/391]\tTime 0.040 (0.050)\tData 0.002 (0.004)\tLoss 0.0684 (0.1318)\tPrec 99.219% (95.564%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.622 (0.622)\tLoss 0.2355 (0.2355)\tPrec 94.531% (94.531%)\n",
      " * Prec 89.070% \n",
      "best acc: 89.210000\n",
      "Epoch: [99][0/391]\tTime 0.521 (0.521)\tData 0.464 (0.464)\tLoss 0.1042 (0.1042)\tPrec 96.875% (96.875%)\n",
      "Epoch: [99][100/391]\tTime 0.044 (0.052)\tData 0.002 (0.007)\tLoss 0.1587 (0.1318)\tPrec 94.531% (95.521%)\n",
      "Epoch: [99][200/391]\tTime 0.040 (0.049)\tData 0.002 (0.004)\tLoss 0.0695 (0.1324)\tPrec 98.438% (95.480%)\n",
      "Epoch: [99][300/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 0.1050 (0.1344)\tPrec 96.094% (95.414%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.324 (1.324)\tLoss 0.2383 (0.2383)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.180% \n",
      "best acc: 89.210000\n"
     ]
    }
   ],
   "source": [
    "lr = 4e-2\n",
    "weight_decay = 1e-4\n",
    "epochs = 100\n",
    "best_prec = 0\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9,weight_decay=weight_decay)\n",
    "\n",
    "if not os.path.exists('result'): \n",
    "    os.makedirs('result')\n",
    "\n",
    "fdir = 'result/'+str(model_name) \n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "\n",
    "adjust_list = [80,90]\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch,adjust_list)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6751af9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 8922/10000 (89%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/Resnet_20_quant_project/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c9deeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 -th layer prehooked\n",
      "9 -th layer prehooked\n",
      "13 -th layer prehooked\n",
      "15 -th layer prehooked\n",
      "21 -th layer prehooked\n",
      "25 -th layer prehooked\n",
      "27 -th layer prehooked\n",
      "34 -th layer prehooked\n",
      "36 -th layer prehooked\n",
      "42 -th layer prehooked\n",
      "46 -th layer prehooked\n",
      "48 -th layer prehooked\n",
      "54 -th layer prehooked\n",
      "56 -th layer prehooked\n",
      "63 -th layer prehooked\n",
      "65 -th layer prehooked\n",
      "71 -th layer prehooked\n",
      "75 -th layer prehooked\n",
      "77 -th layer prehooked\n",
      "83 -th layer prehooked\n",
      "85 -th layer prehooked\n"
     ]
    }
   ],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "i = 0\n",
    "\n",
    "for layer in model.modules():\n",
    "    i = i+1\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        print(i,\"-th layer prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)             \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.to(device)\n",
    "out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ba87f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(2.6745, device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Layer 9\n",
    "## Layer 13\n",
    "## save_outputs.output[1][0]\n",
    "## save_outputs.output[2][0]\n",
    "model.layer1[0].conv2.weight_quant.wgt_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfdc0c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference between psum original and psum recovered = -5.591659828496631e-07\n"
     ]
    }
   ],
   "source": [
    "w_bit = 4\n",
    "weight_q = model.layer1[0].conv2.weight_q\n",
    "w_alpha = model.layer1[0].conv2.weight_quant.wgt_alpha\n",
    "w_delta = w_alpha/(2**(w_bit-1)-1)\n",
    "weight_int = weight_q/w_delta\n",
    "\n",
    "x_bit = 4\n",
    "x = save_output.outputs[1][0]\n",
    "x_alpha = model.layer1[0].conv2.act_alpha\n",
    "x_delta = x_alpha/(2**x_bit-1)\n",
    "act_quant = act_quantization(x_bit)\n",
    "x_q = act_quant(x,x_alpha)\n",
    "x_int = x_q/x_delta\n",
    "\n",
    "conv_int = nn.Conv2d(8,8,kernel_size=3, padding=1, bias=False)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "output_int = conv_int(x_int)\n",
    "psum_recovered = output_int*w_delta*x_delta\n",
    "relu = nn.ReLU(inplace=True)\n",
    "psum_after_relu = relu(psum_recovered)\n",
    "\n",
    "difference = (save_output.outputs[2][0] - psum_after_relu).mean()\n",
    "\n",
    "print(\"The difference between psum original and psum recovered = {}\".format(difference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f23a7787",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_int = x_int[0,:,:,:]  # pick only one input out of batch\n",
    "# a_int.size() = [64, 32, 32]\n",
    "\n",
    "# conv_int.weight.size() = torch.Size([64, 64, 3, 3])  <- output_ch, input_ch, ki, kj\n",
    "w_int = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))  # merge ki, kj index to kij\n",
    "\n",
    "padding = 1\n",
    "stride = 1\n",
    "array_size = 8\n",
    "x_size = x_int.size()\n",
    "nig = range(x_size[2])\n",
    "njg = range(x_size[3])\n",
    "\n",
    "kijg = range(w_int.size(2))\n",
    "ki_dim = int(math.sqrt(w_int.size(2)))  ## Kernel's 1 dim size\n",
    "\n",
    "icg = range(int(w_int.size(1)))  ## input channel \n",
    "ocg = range(int(w_int.size(0)))  ## output channel\n",
    "\n",
    "a_pad = torch.zeros((x_size[1],x_size[2]+2*padding,x_size[3]+2*padding))\n",
    "\n",
    "a_pad[ :, padding:padding+len(nig), padding:padding+len(njg)] = act_int.cuda()\n",
    "a_pad = torch.reshape(a_pad, (a_pad.size(0), -1))\n",
    "\n",
    "ic_tile = range(int(int(act_int.size(0))/array_size))\n",
    "oc_tile = range(int(int(w_int.size(0))/array_size))\n",
    "\n",
    "a_tile = torch.zeros(len(ic_tile),array_size,len(nig)+padding*2,len(njg)+padding*2).cuda()\n",
    "a_tile = torch.reshape(a_tile,(a_tile.size(0),a_tile.size(1),-1))\n",
    "\n",
    "for ict in ic_tile:\n",
    "    a_tile[ict,:,:] = a_pad[(ict*array_size):((ict+1)*array_size),:]\n",
    "\n",
    "w_tile = torch.zeros(len(ic_tile),len(oc_tile),array_size,array_size,len(kijg)).cuda()\n",
    "\n",
    "for oct in oc_tile:\n",
    "    for ict in ic_tile:\n",
    "        w_tile[ict,oct,:,:,:] = w_int[(oct*array_size):((oct+1)*array_size),(ict*array_size):((ict+1)*array_size),:]\n",
    "\n",
    "p_nijg = range(a_pad.size(1)) ## paded activation's nij group\n",
    "\n",
    "psum = torch.zeros(len(ic_tile),len(oc_tile),array_size,len(p_nijg),len(kijg)).cuda() \n",
    "\n",
    "for kij in kijg:\n",
    "    for ict in ic_tile:\n",
    "        for oct in oc_tile:\n",
    "            for nij in p_nijg:     # time domain, sequentially given input\n",
    "                m = nn.Linear(array_size, array_size, bias=False)\n",
    "                m.weight = torch.nn.Parameter(w_tile[ict,oct,:,:,kij])\n",
    "                psum[ict,oct,:, nij, kij] = m(a_tile[ict,:,nij]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a32a1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "a_pad_ni_dim = int(math.sqrt(a_pad.size(1))) # 32 + 2*pad = 34\n",
    "\n",
    "o_ni_dim = int((a_pad_ni_dim - (ki_dim- 1) - 1)/stride + 1) #34 - 2 - 1 + 1 = 32\n",
    "o_nijg = range(o_ni_dim**2)    \n",
    "    \n",
    "out = torch.zeros(len(ocg), len(o_nijg)).cuda()\n",
    "  \n",
    "   \n",
    "### SFP accumulation ###\n",
    "for o_nij in o_nijg: \n",
    "    for kij in kijg:  \n",
    "        for ict in ic_tile:\n",
    "            for oct in oc_tile:\n",
    "                out[oct*array_size:(oct+1)*array_size,o_nij] = out[oct*array_size:(oct+1)*array_size,o_nij] + \\\n",
    "                psum[ict,oct,:, int(o_nij/o_ni_dim)*a_pad_ni_dim + o_nij%o_ni_dim + int(kij/ki_dim)*a_pad_ni_dim + kij%ki_dim, kij]\n",
    "                ## 2nd index = (int(o_nij/30)*32 + o_nij%30) + (int(kij/3)*32 + kij%3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5914aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dump all the files\n",
    "\n",
    "## Helper functions to dump files\n",
    "def dec_to_bin(arr,bit):\n",
    "    bin_arr = []\n",
    "    for a in arr:\n",
    "        a = int(a)\n",
    "        if a < 0:\n",
    "            a+=bit\n",
    "        b = '{0:04b}'.format(int(a))\n",
    "        bin_arr.append(b)\n",
    "    return bin_arr\n",
    "\n",
    "def dec_to_bin_psum(arr,bit):\n",
    "    bin_arr = []\n",
    "    for a in arr:\n",
    "        a = int(a)\n",
    "        sign = 0\n",
    "        if a < 0:\n",
    "            sign = 1\n",
    "            a+=bit\n",
    "        b = '{0:16b}'.format(int(a))\n",
    "        if sign == 1:\n",
    "            b = b.replace(\" \", \"1\")\n",
    "        else:\n",
    "            b = b.replace(\" \",\"0\")\n",
    "        bin_arr.append(b)\n",
    "    return bin_arr\n",
    "\n",
    "\n",
    "def convert_to_list(arr):\n",
    "    return arr.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "98061c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Activation dump\n",
    "\n",
    "fp_act = open('Renet_activation_project.txt','w')\n",
    "fp_act.write(\"#####\\n\")\n",
    "fp_act.write(\"#####\\n\")\n",
    "fp_act.write(\"#####\\n\")\n",
    "fp_act_dec = open('Resnet_activation_dec.txt','w')\n",
    "for i in range(a_pad.size()[1]):\n",
    "    act_line = a_pad[:,i]\n",
    "    act_arr = [int(j+0.001) for j in convert_to_list(act_line)]\n",
    "    for a in act_arr[::-1]:\n",
    "        #print(int(a))\n",
    "        fp_act_dec.write(str(int(a)))\n",
    "        fp_act_dec.write(\" \")\n",
    "    fp_act_dec.write(\"\\n\")\n",
    "    bin_act = dec_to_bin(act_arr,16)\n",
    "    for b in bin_act[::-1]:\n",
    "        #print(b)\n",
    "        fp_act.write(b)\n",
    "    fp_act.write('\\n')\n",
    "    \n",
    "\n",
    "fp_act.close()\n",
    "fp_act_dec.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9af62655",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weight dump\n",
    "fp_wgt = open('Resnet_weight_project.txt','w')\n",
    "fp_wgt.write(\"#####\\n\")\n",
    "fp_wgt.write(\"#####\\n\")\n",
    "fp_wgt.write(\"#####\\n\")\n",
    "fp_wgt_dec = open('Resnet_weight_dec.txt','w')\n",
    "\n",
    "for kij in range(9):\n",
    "    for w in range(8):\n",
    "        w_line = w_int[w,:,kij]\n",
    "        w_arr = []\n",
    "        for i in convert_to_list(w_line):\n",
    "            if i < 0:\n",
    "                w_arr.append(int(i-0.001))\n",
    "            else:\n",
    "                w_arr.append(int(i+0.001))\n",
    "        \n",
    "        for ww in w_arr[::-1]:\n",
    "            #print(int(ww))\n",
    "            fp_wgt_dec.write(str(int(ww)))\n",
    "            fp_wgt_dec.write(\" \")\n",
    "        fp_wgt_dec.write(\"\\n\")\n",
    "        bin_wgt = dec_to_bin(w_arr,16)\n",
    "        for b in bin_wgt[::-1]:\n",
    "            #print(\"Count = {} , b = {}\".format(count,b))\n",
    "            fp_wgt.write(b)\n",
    "        fp_wgt.write('\\n')\n",
    "\n",
    "fp_wgt.close()\n",
    "fp_wgt_dec.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "915168f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## psum dump and output.txt dump\n",
    "fp_psum = open('Resnet_psum_project.txt','w')\n",
    "fp_psum.write(\"#####\\n\")\n",
    "fp_psum.write(\"#####\\n\")\n",
    "fp_psum.write(\"#####\\n\")\n",
    "\n",
    "fp_psum_dec = open('Resnet_psum_dec.txt','w')\n",
    "fp_psum_relu = open('Resnet_output_project.txt','w')\n",
    "fp_psum_relu.write(\"#\\n\")\n",
    "fp_psum_relu.write(\"#\\n\")\n",
    "fp_psum_relu.write(\"#\\n\")\n",
    "for kij in range(o_ni_dim*o_ni_dim):\n",
    "    psum_line = out[:,kij]\n",
    "    psum_arr = []\n",
    "    out_arr = []\n",
    "    for i in convert_to_list(psum_line):\n",
    "        if i < 0:\n",
    "            psum_arr.append(int(i-0.001))\n",
    "            out_arr.append(0)\n",
    "        else:\n",
    "            psum_arr.append(int(i+0.001))\n",
    "            out_arr.append(int(i+0.001))\n",
    "    for p in psum_arr:\n",
    "        #print(int(a))\n",
    "        fp_psum_dec.write(str(int(p)))\n",
    "        fp_psum_dec.write(\" \")\n",
    "    fp_psum_dec.write(\"\\n\")\n",
    "    bin_act = dec_to_bin_psum(psum_arr,65536)\n",
    "    out_bin_act = dec_to_bin_psum(out_arr,65536)\n",
    "    for b in bin_act:\n",
    "        #print(b)\n",
    "        fp_psum.write(b)\n",
    "    fp_psum.write('\\n')\n",
    "    \n",
    "    for b in out_bin_act:\n",
    "        fp_psum_relu.write(b)\n",
    "    fp_psum_relu.write(\"\\n\")\n",
    "fp_psum.close()\n",
    "fp_psum_dec.close()\n",
    "fp_psum_relu.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "712736d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "## For input activations tiling. Handled in testbench. Written here just for reference logic\n",
    "our_hardware = 6\n",
    "hor_step = our_hardware-ki_dim+1 ## 4\n",
    "hor_step_mod = our_hardware\n",
    "ver_step = (our_hardware-ki_dim+1)*a_pad_ni_dim ## 136\n",
    "stop_point = (a_pad_ni_dim-our_hardware)*a_pad_ni_dim+1 ## \n",
    "group_count = 0\n",
    "act_group = []\n",
    "for v in range(0,stop_point,ver_step):\n",
    "    ## Now move horizontally\n",
    "    for h in range(v,v+34,hor_step):\n",
    "        if h+our_hardware>v+a_pad_ni_dim:\n",
    "            break\n",
    "        group = []\n",
    "        group_count+=1\n",
    "        for hh in range(h,h+(our_hardware)*a_pad_ni_dim,a_pad_ni_dim):\n",
    "            \n",
    "            for hhh in range(our_hardware):\n",
    "                group.append(hh+hhh)\n",
    "        act_group.append(group)       \n",
    "print(group_count)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "185c9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For output tiling. Handled in testbench. Written here just for reference logic\n",
    "our_out_hw = 4\n",
    "out_ni_dim = int(math.sqrt(out.size(1)))\n",
    "out_stop_point = (out_ni_dim-our_out_hw)*out_ni_dim+1\n",
    "out_ver_step = our_out_hw*out_ni_dim\n",
    "group_count = 0\n",
    "out_group = []\n",
    "for v in range(0,out_stop_point,out_ver_step):\n",
    "    ## Now move horizontally\n",
    "    for h in range(v,v+32,our_out_hw):\n",
    "        group = []\n",
    "        group_count+=1\n",
    "        for hh in range(h,h+our_out_hw*out_ni_dim,out_ni_dim):\n",
    "            for hhh in range(our_out_hw):\n",
    "                group.append(hh+hhh)\n",
    "        out_group.append(group)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
